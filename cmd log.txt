==============================
[2014-10][Epoch 4/20] | Time = 4.59 min
 - Total Loss : 1862316237.557726 | Recon Loss: 1862316237.389273 | Diff Loss: 0.958037
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2014-10 completed in 18.21 min
[1] 2014-11 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2014-11 | file : news_20141130.json

[ Building tensor ]
 - Saved 998 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=4.759110e+08 loss_diff=9.516842e-01 recon=4.759110e+08
obs_tick range: -1.0 397400.0  next_tick range: -1.0 406600.0
normed next range: -1000000.0 6735.5654296875
pred range: -226.04052734375 6.55589485168457
mask valid positions: 36852.0 / 65536

[batch 10] loss=2.078549e+08 loss_diff=9.698930e-01 recon=2.078549e+08
obs_tick range: -0.9961942434310913 417000.0  next_tick range: -0.9990479946136475 416300.0
normed next range: -1000000.0 1000000.0
pred range: -225.89759826660156 6.8336992263793945
mask valid positions: 57711.0 / 65536

>>> Gradient explosion detected, grad_norm= 18666730.997620247
>>> Gradient explosion detected, grad_norm= 7002698.6543486845
>>> Gradient explosion detected, grad_norm= 19746401.626264755
>>> Gradient explosion detected, grad_norm= 8833682.040948143
[batch 20] loss=5.969774e+09 loss_diff=9.467771e-01 recon=5.969774e+09
obs_tick range: -1.0 415394.0  next_tick range: -1.0 408300.0
normed next range: -1000000.0 2876.040771484375
pred range: -225.7001190185547 8.301185607910156
mask valid positions: 39698.0 / 65536

>>> Gradient explosion detected, grad_norm= 28846307.482287377
>>> Gradient explosion detected, grad_norm= 33888652.062482044
[batch 30] loss=3.618803e+08 loss_diff=9.882784e-01 recon=3.618803e+08
obs_tick range: -0.9990476965904236 450000.0  next_tick range: -0.9961944818496704 417900.0
normed next range: -1000000.0 6639.28515625
pred range: -224.74803161621094 5.61583948135376
mask valid positions: 55998.0 / 65536

>>> Gradient explosion detected, grad_norm= 27352245.686486915
[batch 40] loss=5.293608e+02 loss_diff=1.037672e+00 recon=5.283231e+02
obs_tick range: -0.9762958288192749 408000.0  next_tick range: -0.9659255743026733 408000.0
normed next range: -2.474870204925537 7316.5859375
pred range: -15.619135856628418 9.040167808532715
mask valid positions: 49846.0 / 65536

>>> Gradient explosion detected, grad_norm= 6884454.335884794
[batch 50] loss=2.252076e+08 loss_diff=9.024427e-01 recon=2.252076e+08
obs_tick range: -0.9961945414543152 470000.0  next_tick range: -0.9914447665214539 406900.0
normed next range: -1000000.0 7559.2734375
pred range: -227.13438415527344 41.572235107421875
mask valid positions: 41560.0 / 65536

>>> Gradient explosion detected, grad_norm= 1797121.8402987865
>>> Gradient explosion detected, grad_norm= 4775921.783976203
[batch 60] loss=5.324245e+08 loss_diff=8.971169e-01 recon=5.324245e+08
obs_tick range: -0.9990478157997131 406500.0  next_tick range: -1.0 404400.0
normed next range: -1000000.0 13605.576171875
pred range: -227.5830078125 6.0587310791015625
mask valid positions: 42497.0 / 65536

>>> Gradient explosion detected, grad_norm= 5304415.3543790495
>>> Gradient explosion detected, grad_norm= 3092592.5324263065
>>> Gradient explosion detected, grad_norm= 19956154.833667643
[batch 70] loss=5.221884e+08 loss_diff=9.675903e-01 recon=5.221884e+08
obs_tick range: -0.9914472103118896 409700.0  next_tick range: -1.0 409000.0
normed next range: -1000000.0 5399.53125
pred range: -227.9805450439453 23.673906326293945
mask valid positions: 45070.0 / 65536

>>> Gradient explosion detected, grad_norm= 7795850.740172036
[batch 80] loss=2.616392e+08 loss_diff=9.780862e-01 recon=2.616392e+08
obs_tick range: -0.9990480542182922 417300.0  next_tick range: -1.0 406500.0
normed next range: -1000000.0 12424.6513671875
pred range: -227.90745544433594 51.46756362915039
mask valid positions: 42719.0 / 65536

>>> Gradient explosion detected, grad_norm= 6711517.8177481275
>>> Gradient explosion detected, grad_norm= 24436640.733561933
>>> Gradient explosion detected, grad_norm= 37661347.73480826
[batch 90] loss=4.633553e+08 loss_diff=1.014528e+00 recon=4.633553e+08
obs_tick range: -1.0 416300.0  next_tick range: -1.0 416100.0
normed next range: -1000000.0 16370.6552734375
pred range: -228.02630615234375 16.217350006103516
mask valid positions: 38242.0 / 65536

>>> Gradient explosion detected, grad_norm= 11469487.20721635
>>> Gradient explosion detected, grad_norm= 9224340.37628823
[batch 100] loss=1.447581e+08 loss_diff=9.444811e-01 recon=1.447581e+08
obs_tick range: -0.99619460105896 420200.0  next_tick range: -0.991441547870636 419800.0
normed next range: -1000000.0 8181.7509765625
pred range: -228.0775146484375 47.0052490234375
mask valid positions: 49594.0 / 65536

>>> Gradient explosion detected, grad_norm= 6223040.304287061
>>> Gradient explosion detected, grad_norm= 1929076.6229080302
>>> Gradient explosion detected, grad_norm= 3791833.401708344
>>> Gradient explosion detected, grad_norm= 9342797.077969503
[batch 110] loss=1.746457e+08 loss_diff=9.561476e-01 recon=1.746457e+08
obs_tick range: -0.9914447665214539 500000.0  next_tick range: -0.9848073124885559 402000.0
normed next range: -1000000.0 22119.7421875
pred range: -227.84136962890625 7.981159210205078
mask valid positions: 29660.0 / 65536

>>> Gradient explosion detected, grad_norm= 29391255.807839163
>>> Gradient explosion detected, grad_norm= 8251250.801996694
[batch 120] loss=2.917825e+09 loss_diff=9.375883e-01 recon=2.917825e+09
obs_tick range: -0.9961941242218018 411400.0  next_tick range: -0.9914473295211792 411300.0
normed next range: -1000000.0 31697.685546875
pred range: -228.0002899169922 20.64129066467285
mask valid positions: 52075.0 / 65536

>>> Gradient explosion detected, grad_norm= 5833892.842802397
==============================
[2014-11][Epoch 1/20] | Time = 4.36 min
 - Total Loss : 1985586852.093218 | Recon Loss: 1985586851.936484 | Diff Loss: 0.960456
==============================
No improvement count: 1
[batch 0] loss=2.037803e+08 loss_diff=9.629629e-01 recon=2.037803e+08
obs_tick range: -1.0 286300.0  next_tick range: -1.0 290400.0
normed next range: -1000000.0 8880.275390625
pred range: -227.61276245117188 42.553043365478516
mask valid positions: 36566.0 / 65536

>>> Gradient explosion detected, grad_norm= 19410223.200289514
[batch 10] loss=3.674193e+09 loss_diff=9.602230e-01 recon=3.674193e+09
obs_tick range: -0.9914444088935852 389100.0  next_tick range: -0.9961929321289062 470133.0
normed next range: -1000000.0 2668.701171875
pred range: -228.3722381591797 49.923160552978516
mask valid positions: 59297.0 / 65536

>>> Gradient explosion detected, grad_norm= 10911723.90665534
>>> Gradient explosion detected, grad_norm= 8923904.576884717
>>> Gradient explosion detected, grad_norm= 4260166.002354029
[batch 20] loss=2.163316e+09 loss_diff=9.928086e-01 recon=2.163316e+09
obs_tick range: -0.9848067164421082 409500.0  next_tick range: -0.9762951731681824 410200.0
normed next range: -1000000.0 5536.56201171875
pred range: -227.54774475097656 78.6915283203125
mask valid positions: 50541.0 / 65536

>>> Gradient explosion detected, grad_norm= 2640729.777061051
>>> Gradient explosion detected, grad_norm= 10841389.99865939
>>> Gradient explosion detected, grad_norm= 2531692.4608540162
[batch 30] loss=2.248675e+09 loss_diff=9.783776e-01 recon=2.248675e+09
obs_tick range: -0.9914470911026001 417000.0  next_tick range: -1.0 416200.0
normed next range: -1000000.0 1641.8875732421875
pred range: -228.05445861816406 7.333552360534668
mask valid positions: 57261.0 / 65536

>>> Gradient explosion detected, grad_norm= 31480201.29093021
>>> Gradient explosion detected, grad_norm= 14413609.475193065
[batch 40] loss=4.470602e+01 loss_diff=8.971058e-01 recon=4.380891e+01
obs_tick range: -1.0 389100.0  next_tick range: -1.0 297600.0
normed next range: -18.502626419067383 2685.951904296875
pred range: -7.757532596588135 8.668061256408691
mask valid positions: 59350.0 / 65536

>>> Gradient explosion detected, grad_norm= 10281941.46583485
>>> Gradient explosion detected, grad_norm= 3178285.0632158066
>>> Gradient explosion detected, grad_norm= 17159582.361717716
[batch 50] loss=2.446422e+09 loss_diff=1.001366e+00 recon=2.446422e+09
obs_tick range: -1.0 407000.0  next_tick range: -0.9762958884239197 409300.0
normed next range: -1000000.0 3800.75390625
pred range: -229.1243438720703 57.98593521118164
mask valid positions: 50973.0 / 65536

>>> Gradient explosion detected, grad_norm= 5086937.053216153
>>> Gradient explosion detected, grad_norm= 10875121.77728068
>>> Gradient explosion detected, grad_norm= 50166830.08801339
[batch 60] loss=2.637595e+08 loss_diff=9.071257e-01 recon=2.637595e+08
obs_tick range: -0.9914447665214539 409200.0  next_tick range: -0.9914445877075195 409500.0
normed next range: -1000000.0 7800.5234375
pred range: -228.8961181640625 62.2055778503418
mask valid positions: 50646.0 / 65536

>>> Gradient explosion detected, grad_norm= 10328123.848377625
>>> Gradient explosion detected, grad_norm= 27458265.237902034
>>> Gradient explosion detected, grad_norm= 42549399.08222071
[batch 70] loss=2.664588e+09 loss_diff=9.866409e-01 recon=2.664588e+09
obs_tick range: -0.9990472793579102 278300.0  next_tick range: -1.0 416100.0
normed next range: -1000000.0 3351.28466796875
pred range: -229.10423278808594 52.611629486083984
mask valid positions: 59076.0 / 65536

>>> Gradient explosion detected, grad_norm= 21662374.14729855
>>> Gradient explosion detected, grad_norm= 23944834.09204819
>>> Gradient explosion detected, grad_norm= 1770326.925474184
>>> Gradient explosion detected, grad_norm= 68976558.34956668
[batch 80] loss=9.078940e+08 loss_diff=9.273570e-01 recon=9.078940e+08
obs_tick range: -1.0 409700.0  next_tick range: -0.9990476965904236 408700.0
normed next range: -1000000.0 3687.252197265625
pred range: -228.26866149902344 6.442847728729248
mask valid positions: 50946.0 / 65536

>>> Gradient explosion detected, grad_norm= 1878909.8277272645
>>> Gradient explosion detected, grad_norm= 1457480.4443141287
[batch 90] loss=2.037773e+08 loss_diff=8.998559e-01 recon=2.037773e+08
obs_tick range: -0.9990480542182922 412500.0  next_tick range: -1.0 412500.0
normed next range: -1000000.0 1980.35205078125
pred range: -229.0559539794922 5.851067543029785
mask valid positions: 55745.0 / 65536

>>> Gradient explosion detected, grad_norm= 7805793.4332708735
[batch 100] loss=4.220958e+08 loss_diff=1.021357e+00 recon=4.220958e+08
obs_tick range: -1.0 414000.0  next_tick range: -1.0 417200.0
normed next range: -1000000.0 10239.345703125
pred range: -229.31057739257812 4.925276279449463
mask valid positions: 38106.0 / 65536

[batch 110] loss=1.732470e+06 loss_diff=9.306943e-01 recon=1.732470e+06
obs_tick range: -0.9990478157997131 397000.0  next_tick range: -0.9961945414543152 412500.0
normed next range: -1000000.0 6084.283203125
pred range: -229.70858764648438 21.69331932067871
mask valid positions: 52519.0 / 65536

>>> Gradient explosion detected, grad_norm= 2665925.5621278426
>>> Gradient explosion detected, grad_norm= 15158278.361996703
>>> Gradient explosion detected, grad_norm= 14947706.923349915
>>> Gradient explosion detected, grad_norm= 10825993.485223077
[batch 120] loss=4.202132e+09 loss_diff=9.050590e-01 recon=4.202132e+09
obs_tick range: -1.0 430000.0  next_tick range: -1.0 424900.0
normed next range: -1000000.0 1000000.0
pred range: -230.05117797851562 7.192030429840088
mask valid positions: 50883.0 / 65536

==============================
[2014-11][Epoch 2/20] | Time = 4.58 min
 - Total Loss : 2074284573.127952 | Recon Loss: 2074284572.966882 | Diff Loss: 0.956163
==============================
No improvement count: 2
[batch 0] loss=4.614221e+02 loss_diff=9.853248e-01 recon=4.604368e+02
obs_tick range: -0.9991130232810974 417400.0  next_tick range: -1.0 416500.0
normed next range: -2.4748737812042236 13224.8232421875
pred range: -14.36458969116211 12.491917610168457
mask valid positions: 52068.0 / 65536

>>> Gradient explosion detected, grad_norm= 1032319.5540313646
>>> Gradient explosion detected, grad_norm= 3259661.3951600157
>>> Gradient explosion detected, grad_norm= 1219669.3826925205
>>> Gradient explosion detected, grad_norm= 2202055.40527142
[batch 10] loss=3.426299e+09 loss_diff=9.573109e-01 recon=3.426299e+09
obs_tick range: -0.9922101497650146 470133.0  next_tick range: -1.0 459137.0
normed next range: -1000000.0 10319.625
pred range: -230.19149780273438 6.819085597991943
mask valid positions: 51663.0 / 65536

[batch 20] loss=1.369356e+10 loss_diff=9.920230e-01 recon=1.369356e+10
obs_tick range: -0.9990480542182922 408100.0  next_tick range: -1.0 406500.0
normed next range: -1000000.0 1000000.0
pred range: -230.8928680419922 4.886157512664795
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 1169515.1250354385
[batch 30] loss=6.087452e+08 loss_diff=9.461364e-01 recon=6.087452e+08
obs_tick range: -1.0 415200.0  next_tick range: -0.9537164568901062 415000.0
normed next range: -1000000.0 7734.22265625
pred range: -231.59695434570312 7.123965263366699
mask valid positions: 34035.0 / 65536

[batch 40] loss=1.632180e+02 loss_diff=9.964778e-01 recon=1.622215e+02
obs_tick range: -1.0 413800.0  next_tick range: -0.9990478157997131 413600.0
normed next range: -4.1327595710754395 5296.82958984375
pred range: -11.26073169708252 7.314939975738525
mask valid positions: 49490.0 / 65536

[batch 50] loss=2.245032e+08 loss_diff=9.948831e-01 recon=2.245032e+08
obs_tick range: -1.0 395500.0  next_tick range: -1.0 397100.0
normed next range: -1000000.0 3654.35009765625
pred range: -233.59962463378906 5.160022735595703
mask valid positions: 57480.0 / 65536

[batch 60] loss=1.005262e+09 loss_diff=9.419241e-01 recon=1.005262e+09
obs_tick range: -0.9914447665214539 414300.0  next_tick range: -0.9848045110702515 430000.0
normed next range: -1000000.0 2697.055419921875
pred range: -234.1330108642578 4.774280071258545
mask valid positions: 65536.0 / 65536

[batch 70] loss=2.609727e+08 loss_diff=9.729269e-01 recon=2.609727e+08
obs_tick range: -0.9990479350090027 415700.0  next_tick range: -0.9961944222450256 415600.0
normed next range: -1000000.0 1000000.0
pred range: -235.23130798339844 4.774496078491211
mask valid positions: 49449.0 / 65536

[batch 80] loss=2.156133e+02 loss_diff=9.368021e-01 recon=2.146765e+02
obs_tick range: -0.9909657835960388 415000.0  next_tick range: -0.9955729246139526 409000.0
normed next range: -3.5182759761810303 3863.152099609375
pred range: -11.973465919494629 6.878942489624023
mask valid positions: 43770.0 / 65536

[batch 90] loss=2.324815e+08 loss_diff=9.420705e-01 recon=2.324815e+08
obs_tick range: -1.0 415000.0  next_tick range: -1.0 415000.0
normed next range: -1000000.0 1253.699462890625
pred range: -236.580322265625 12.869451522827148
mask valid positions: 40261.0 / 65536

[batch 100] loss=1.659526e+02 loss_diff=1.011049e+00 recon=1.649415e+02
obs_tick range: -1.0 419800.0  next_tick range: -0.9990473985671997 419600.0
normed next range: -3.6663858890533447 3971.765869140625
pred range: -5.386204242706299 17.048471450805664
mask valid positions: 44513.0 / 65536

[batch 110] loss=1.446245e+10 loss_diff=9.546976e-01 recon=1.446245e+10
obs_tick range: -0.9961919784545898 410000.0  next_tick range: -0.9990478754043579 412500.0
normed next range: -1000000.0 1000000.0
pred range: -238.32139587402344 4.9582743644714355
mask valid positions: 52645.0 / 65536

[batch 120] loss=7.120459e+02 loss_diff=1.007972e+00 recon=7.110379e+02
obs_tick range: -0.9238858222961426 415800.0  next_tick range: -0.9691409468650818 412200.0
normed next range: -24.788021087646484 19139.33984375
pred range: -30.524885177612305 20.126995086669922
mask valid positions: 50884.0 / 65536

==============================
[2014-11][Epoch 3/20] | Time = 4.71 min
 - Total Loss : 2499136577.213995 | Recon Loss: 2499136577.060804 | Diff Loss: 0.951509
==============================
No improvement count: 3
[batch 0] loss=2.484117e+08 loss_diff=9.539089e-01 recon=2.484117e+08
obs_tick range: -0.9961943626403809 408500.0  next_tick range: -0.9990479350090027 291800.0
normed next range: -1000000.0 4595.1318359375
pred range: -239.26065063476562 6.800309658050537
mask valid positions: 42435.0 / 65536

[batch 10] loss=5.320613e+09 loss_diff=9.949590e-01 recon=5.320613e+09
obs_tick range: -1.0 410100.0  next_tick range: -0.9537166953086853 410200.0
normed next range: -1000000.0 2803.431640625
pred range: -240.2213134765625 4.852339744567871
mask valid positions: 57605.0 / 65536

[batch 20] loss=4.680541e+08 loss_diff=9.639713e-01 recon=4.680541e+08
obs_tick range: -1.0 417400.0  next_tick range: -0.9537163972854614 411800.0
normed next range: -1000000.0 6342.20751953125
pred range: -241.0325927734375 5.435382843017578
mask valid positions: 41547.0 / 65536

[batch 30] loss=2.958986e+09 loss_diff=9.687566e-01 recon=2.958986e+09
obs_tick range: -1.0 407000.0  next_tick range: -1.0 402000.0
normed next range: -1000000.0 1000000.0
pred range: -241.8855743408203 4.844692707061768
mask valid positions: 57671.0 / 65536

[batch 40] loss=5.562488e+08 loss_diff=9.182490e-01 recon=5.562488e+08
obs_tick range: -1.0 405400.0  next_tick range: -0.999048113822937 405100.0
normed next range: -1000000.0 2600.20556640625
pred range: -242.83523559570312 4.641333103179932
mask valid positions: 49335.0 / 65536

[batch 50] loss=2.929964e+08 loss_diff=9.269429e-01 recon=2.929964e+08
obs_tick range: -0.9670490026473999 402000.0  next_tick range: -0.9925786256790161 293400.0
normed next range: -1000000.0 1000000.0
pred range: -243.4233856201172 14.255812644958496
mask valid positions: 16133.0 / 65536

>>> Gradient explosion detected, grad_norm= 1235510.0646197503
[batch 60] loss=1.431305e+10 loss_diff=9.334072e-01 recon=1.431305e+10
obs_tick range: -1.0 416200.0  next_tick range: -0.9990480542182922 416300.0
normed next range: -1000000.0 1000000.0
pred range: -244.22842407226562 4.708110332489014
mask valid positions: 65536.0 / 65536

[batch 70] loss=3.466766e+09 loss_diff=9.746289e-01 recon=3.466766e+09
obs_tick range: -0.9955729246139526 398800.0  next_tick range: -0.9986846446990967 398000.0
normed next range: -1000000.0 4409.49853515625
pred range: -244.726318359375 5.680599212646484
mask valid positions: 51006.0 / 65536

[batch 80] loss=5.630992e+08 loss_diff=9.323269e-01 recon=5.630992e+08
obs_tick range: -0.9914473295211792 389600.0  next_tick range: -1.0 419900.0
normed next range: -1000000.0 13580.5712890625
pred range: -245.15411376953125 7.1325812339782715
mask valid positions: 45023.0 / 65536

[batch 90] loss=2.208139e+08 loss_diff=9.737787e-01 recon=2.208139e+08
obs_tick range: -1.0 470133.0  next_tick range: -1.0 416200.0
normed next range: -1000000.0 2332.53857421875
pred range: -245.3733367919922 8.610811233520508
mask valid positions: 41565.0 / 65536

[batch 100] loss=4.583560e+08 loss_diff=9.154669e-01 recon=4.583560e+08
obs_tick range: -0.9990481734275818 397000.0  next_tick range: -1.0 389000.0
normed next range: -1000000.0 8295.0166015625
pred range: -246.32540893554688 6.419647693634033
mask valid positions: 52140.0 / 65536

[batch 110] loss=3.214379e+09 loss_diff=9.762828e-01 recon=3.214379e+09
obs_tick range: -0.9961919784545898 577449.0  next_tick range: -0.9990478754043579 419600.0
normed next range: -1000000.0 3516.68798828125
pred range: -246.95797729492188 4.915043830871582
mask valid positions: 56198.0 / 65536

[batch 120] loss=3.124581e+08 loss_diff=9.758303e-01 recon=3.124581e+08
obs_tick range: -1.0 419300.0  next_tick range: -1.0 417500.0
normed next range: -1000000.0 4229.080078125
pred range: -247.60870361328125 9.157197952270508
mask valid positions: 51476.0 / 65536

==============================
[2014-11][Epoch 4/20] | Time = 4.64 min
 - Total Loss : 2123465650.162071 | Recon Loss: 2123465650.016801 | Diff Loss: 0.943421
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2014-11 completed in 18.29 min
[1] 2014-12 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2014-12 | file : news_20141231.json

[ Building tensor ]
 - Saved 998 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.992495e+08 loss_diff=9.346787e-01 recon=1.992495e+08
obs_tick range: -0.9762956500053406 2007988.0  next_tick range: -0.9659258127212524 418200.0
normed next range: -1000000.0 1570.4443359375
pred range: -248.07852172851562 4.772464275360107
mask valid positions: 49259.0 / 65536

[batch 10] loss=2.141302e+03 loss_diff=9.746475e-01 recon=2.140327e+03
obs_tick range: -0.9914447665214539 450000.0  next_tick range: -0.9848069548606873 240000.0
normed next range: -4.54781436920166 16967.603515625
pred range: -6.0431952476501465 16.983768463134766
mask valid positions: 43060.0 / 65536

[batch 20] loss=2.474324e+03 loss_diff=9.730879e-01 recon=2.473351e+03
obs_tick range: -0.9986846446990967 410100.0  next_tick range: -1.0 410200.0
normed next range: -4.861863136291504 18707.31640625
pred range: -247.0653076171875 15.449156761169434
mask valid positions: 35756.0 / 65536

[batch 30] loss=1.488705e+09 loss_diff=9.579211e-01 recon=1.488705e+09
obs_tick range: -1.0 413500.0  next_tick range: -1.0 413300.0
normed next range: -1000000.0 2692.676513671875
pred range: -250.4744110107422 4.783425807952881
mask valid positions: 59206.0 / 65536

[batch 40] loss=2.773734e+08 loss_diff=9.154972e-01 recon=2.773734e+08
obs_tick range: -1.0 407900.0  next_tick range: -1.0 407400.0
normed next range: -1000000.0 5631.0966796875
pred range: -250.97799682617188 6.40969181060791
mask valid positions: 41607.0 / 65536

[batch 50] loss=3.046504e+09 loss_diff=1.005313e+00 recon=3.046504e+09
obs_tick range: -0.9848073124885559 413300.0  next_tick range: -0.9914419054985046 415300.0
normed next range: -1000000.0 2035.447265625
pred range: -251.85971069335938 4.774580478668213
mask valid positions: 45783.0 / 65536

[batch 60] loss=9.983378e+08 loss_diff=9.323872e-01 recon=9.983378e+08
obs_tick range: -0.9914470911026001 419800.0  next_tick range: -1.0 419600.0
normed next range: -1000000.0 2924.340576171875
pred range: -252.65858459472656 9.250916481018066
mask valid positions: 51607.0 / 65536

[batch 70] loss=3.841263e+09 loss_diff=9.518842e-01 recon=3.841263e+09
obs_tick range: -1.0 416100.0  next_tick range: -1.0 415700.0
normed next range: -1000000.0 4039.73046875
pred range: -253.44100952148438 4.982880115509033
mask valid positions: 60178.0 / 65536

[batch 80] loss=6.938412e+06 loss_diff=9.416771e-01 recon=6.938411e+06
obs_tick range: -0.9961936473846436 419600.0  next_tick range: -0.9990480542182922 420000.0
normed next range: -1000000.0 5185.341796875
pred range: -253.44253540039062 8.345209121704102
mask valid positions: 65536.0 / 65536

[batch 90] loss=5.713182e+08 loss_diff=9.163325e-01 recon=5.713182e+08
obs_tick range: -0.9990479350090027 394200.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 13094.8408203125
pred range: -254.33865356445312 6.700713634490967
mask valid positions: 35945.0 / 65536

>>> Gradient explosion detected, grad_norm= 1031598.3122133557
[batch 100] loss=1.180108e+10 loss_diff=9.342035e-01 recon=1.180108e+10
obs_tick range: -0.9848070740699768 415200.0  next_tick range: -0.9762927293777466 413500.0
normed next range: -1000000.0 1000000.0
pred range: -255.2056427001953 4.963780403137207
mask valid positions: 59218.0 / 65536

[batch 110] loss=2.567568e+09 loss_diff=1.022762e+00 recon=2.567568e+09
obs_tick range: -1.0 413800.0  next_tick range: -0.9990476965904236 413600.0
normed next range: -1000000.0 6094.14404296875
pred range: -255.73416137695312 7.718619346618652
mask valid positions: 52553.0 / 65536

[batch 120] loss=2.648110e+02 loss_diff=9.873662e-01 recon=2.638237e+02
obs_tick range: -0.9961939454078674 309100.0  next_tick range: -0.9990479350090027 396900.0
normed next range: -2.5325968265533447 6264.90380859375
pred range: -17.647260665893555 10.171151161193848
mask valid positions: 41215.0 / 65536

==============================
[2014-12][Epoch 1/20] | Time = 4.48 min
 - Total Loss : 1971704381.630543 | Recon Loss: 1971704381.496934 | Diff Loss: 0.953302
==============================
No improvement count: 1
[batch 0] loss=1.105659e+09 loss_diff=9.302429e-01 recon=1.105659e+09
obs_tick range: -1.0 401800.0  next_tick range: -1.0 408100.0
normed next range: -1000000.0 26323.20703125
pred range: -256.8101501464844 12.112466812133789
mask valid positions: 38379.0 / 65536

[batch 10] loss=2.231913e+08 loss_diff=9.646882e-01 recon=2.231913e+08
obs_tick range: -1.0 282000.0  next_tick range: -1.0 417400.0
normed next range: -1000000.0 12628.158203125
pred range: -257.6573486328125 8.912046432495117
mask valid positions: 35422.0 / 65536

[batch 20] loss=1.109059e+09 loss_diff=9.822574e-01 recon=1.109059e+09
obs_tick range: -0.9914473295211792 408800.0  next_tick range: -1.0 292600.0
normed next range: -1000000.0 1000000.0
pred range: -258.4019775390625 6.0293288230896
mask valid positions: 45144.0 / 65536

[batch 30] loss=4.030951e+02 loss_diff=9.496680e-01 recon=4.021454e+02
obs_tick range: -0.9974955916404724 412200.0  next_tick range: -1.0 413800.0
normed next range: -19.445436477661133 6471.83642578125
pred range: -16.253219604492188 9.12660026550293
mask valid positions: 46200.0 / 65536

[batch 40] loss=1.799090e+08 loss_diff=9.896553e-01 recon=1.799090e+08
obs_tick range: -1.0 405100.0  next_tick range: -1.0 406500.0
normed next range: -1000000.0 1556.372802734375
pred range: -259.96856689453125 12.035737991333008
mask valid positions: 57583.0 / 65536

[batch 50] loss=2.910356e+08 loss_diff=9.253079e-01 recon=2.910356e+08
obs_tick range: -0.9961945414543152 419300.0  next_tick range: -0.9914473295211792 417500.0
normed next range: -1000000.0 37415.56640625
pred range: -260.72998046875 4.992309093475342
mask valid positions: 36219.0 / 65536

[batch 60] loss=3.239730e+08 loss_diff=9.486055e-01 recon=3.239730e+08
obs_tick range: -1.0 415000.0  next_tick range: -0.9990473985671997 415000.0
normed next range: -1000000.0 6829.81396484375
pred range: -261.4998474121094 10.278525352478027
mask valid positions: 58340.0 / 65536

[batch 70] loss=6.389342e+08 loss_diff=9.645888e-01 recon=6.389342e+08
obs_tick range: -0.9914473295211792 283600.0  next_tick range: -1.0 419900.0
normed next range: -1000000.0 26207.94921875
pred range: -262.1001281738281 10.367498397827148
mask valid positions: 20906.0 / 65536

[batch 80] loss=6.360903e+08 loss_diff=9.386429e-01 recon=6.360903e+08
obs_tick range: -1.0 396000.0  next_tick range: -1.0 398800.0
normed next range: -1000000.0 18707.31640625
pred range: -262.77264404296875 7.722783088684082
mask valid positions: 35570.0 / 65536

>>> Gradient explosion detected, grad_norm= 1055465.751111848
[batch 90] loss=1.577072e+02 loss_diff=9.422979e-01 recon=1.567649e+02
obs_tick range: -0.9990477561950684 416900.0  next_tick range: -1.0 415000.0
normed next range: -4.20013427734375 3043.92724609375
pred range: -36.60359191894531 16.395889282226562
mask valid positions: 50793.0 / 65536

[batch 100] loss=3.151878e+08 loss_diff=9.391843e-01 recon=3.151878e+08
obs_tick range: -1.0 416300.0  next_tick range: -1.0 416100.0
normed next range: -1000000.0 6073.56591796875
pred range: -264.1871032714844 7.38175630569458
mask valid positions: 44110.0 / 65536

[batch 110] loss=6.577747e+08 loss_diff=9.631156e-01 recon=6.577747e+08
obs_tick range: -0.9847996234893799 413600.0  next_tick range: -0.9762952923774719 412100.0
normed next range: -1000000.0 12546.689453125
pred range: -264.704345703125 9.808576583862305
mask valid positions: 35502.0 / 65536

[batch 120] loss=1.833714e+08 loss_diff=9.450898e-01 recon=1.833714e+08
obs_tick range: -1.0 294400.0  next_tick range: -1.0 417400.0
normed next range: -1000000.0 1549.0484619140625
pred range: -265.4937744140625 5.77499532699585
mask valid positions: 46584.0 / 65536

==============================
[2014-12][Epoch 2/20] | Time = 4.58 min
 - Total Loss : 2513827909.581053 | Recon Loss: 2513827909.435287 | Diff Loss: 0.960504
==============================
No improvement count: 2
[batch 0] loss=8.845372e+08 loss_diff=1.005076e+00 recon=8.845372e+08
obs_tick range: -0.9914444088935852 408485.0  next_tick range: -0.9961939454078674 396600.0
normed next range: -1000000.0 3410.37255859375
pred range: -266.0331115722656 4.921557903289795
mask valid positions: 51158.0 / 65536

[batch 10] loss=3.455288e+09 loss_diff=9.642410e-01 recon=3.455288e+09
obs_tick range: -0.9961946606636047 287000.0  next_tick range: -0.9990478754043579 286200.0
normed next range: -1000000.0 1000000.0
pred range: -266.6075134277344 5.503747463226318
mask valid positions: 58407.0 / 65536

>>> Gradient explosion detected, grad_norm= 1018920.9206355974
[batch 20] loss=6.481977e+08 loss_diff=9.199519e-01 recon=6.481977e+08
obs_tick range: -1.0 307800.0  next_tick range: -0.9990479350090027 307800.0
normed next range: -1000000.0 5770.546875
pred range: -267.4949035644531 8.086138725280762
mask valid positions: 42895.0 / 65536

[batch 30] loss=3.172725e+09 loss_diff=9.796075e-01 recon=3.172725e+09
obs_tick range: -1.0 406500.0  next_tick range: -1.0 402900.0
normed next range: -1000000.0 1000000.0
pred range: -268.221435546875 7.746028900146484
mask valid positions: 40409.0 / 65536

[batch 40] loss=4.695449e+08 loss_diff=9.585840e-01 recon=4.695449e+08
obs_tick range: -1.0 410100.0  next_tick range: -0.9990478157997131 408800.0
normed next range: -1000000.0 1000000.0
pred range: -269.1441955566406 4.951914310455322
mask valid positions: 57476.0 / 65536

[batch 50] loss=6.477285e+08 loss_diff=9.490608e-01 recon=6.477285e+08
obs_tick range: -1.0 284000.0  next_tick range: -0.9990481734275818 407000.0
normed next range: -1000000.0 9660.1845703125
pred range: -269.77484130859375 7.983366012573242
mask valid positions: 37876.0 / 65536

[batch 60] loss=7.447270e+08 loss_diff=9.426442e-01 recon=7.447270e+08
obs_tick range: -1.0 408600.0  next_tick range: -1.0 408300.0
normed next range: -1000000.0 1000000.0
pred range: -270.57147216796875 8.491127014160156
mask valid positions: 57713.0 / 65536

[batch 70] loss=2.922469e+08 loss_diff=9.528919e-01 recon=2.922469e+08
obs_tick range: -1.0 410100.0  next_tick range: -1.0 410200.0
normed next range: -1000000.0 7219.751953125
pred range: -271.2107238769531 14.899027824401855
mask valid positions: 44152.0 / 65536

[batch 80] loss=2.932529e+09 loss_diff=9.804402e-01 recon=2.932529e+09
obs_tick range: -0.9990478754043579 412500.0  next_tick range: -1.0 411100.0
normed next range: -1000000.0 4241.57421875
pred range: -272.09466552734375 5.098694324493408
mask valid positions: 44276.0 / 65536

[batch 90] loss=8.524595e+08 loss_diff=9.565138e-01 recon=8.524595e+08
obs_tick range: -0.9961944222450256 416500.0  next_tick range: -0.999048113822937 415800.0
normed next range: -1000000.0 1000000.0
pred range: -272.7595520019531 5.875881195068359
mask valid positions: 57879.0 / 65536

[batch 100] loss=1.491170e+08 loss_diff=9.310694e-01 recon=1.491170e+08
obs_tick range: -0.9256656765937805 189000.0  next_tick range: -0.9669148325920105 186400.0
normed next range: -1000000.0 29342.029296875
pred range: -273.4061584472656 14.495522499084473
mask valid positions: 27425.0 / 65536

[batch 110] loss=1.638627e+10 loss_diff=9.277560e-01 recon=1.638627e+10
obs_tick range: -1.0 416200.0  next_tick range: -0.999048113822937 416200.0
normed next range: -1000000.0 1000000.0
pred range: -274.4801940917969 5.1184892654418945
mask valid positions: 65536.0 / 65536

[batch 120] loss=3.248626e+09 loss_diff=9.750463e-01 recon=3.248626e+09
obs_tick range: -0.9990480542182922 394200.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 1000000.0
pred range: -275.1172180175781 5.097423553466797
mask valid positions: 57365.0 / 65536

==============================
[2014-12][Epoch 3/20] | Time = 4.58 min
 - Total Loss : 2184085051.653414 | Recon Loss: 2184085051.506922 | Diff Loss: 0.957842
==============================
No improvement count: 3
[batch 0] loss=9.684783e+08 loss_diff=9.861207e-01 recon=9.684783e+08
obs_tick range: -1.0 577449.0  next_tick range: -1.0 409700.0
normed next range: -1000000.0 6994.75634765625
pred range: -275.6795654296875 5.21934175491333
mask valid positions: 57887.0 / 65536

[batch 10] loss=8.342436e+08 loss_diff=9.520512e-01 recon=8.342436e+08
obs_tick range: -0.9848024249076843 416200.0  next_tick range: -0.9928493499755859 415700.0
normed next range: -1000000.0 10703.337890625
pred range: -276.3761901855469 8.238910675048828
mask valid positions: 35289.0 / 65536

[batch 20] loss=7.781311e+08 loss_diff=9.684715e-01 recon=7.781311e+08
obs_tick range: -0.9659256339073181 412100.0  next_tick range: -0.967673659324646 411800.0
normed next range: -1000000.0 6132.6767578125
pred range: -277.4963073730469 5.215499401092529
mask valid positions: 50912.0 / 65536

[batch 30] loss=9.652045e+02 loss_diff=9.422893e-01 recon=9.642623e+02
obs_tick range: -1.0 401800.0  next_tick range: -1.0 298400.0
normed next range: -21.645322799682617 17637.662109375
pred range: -6.7385663986206055 14.91566276550293
mask valid positions: 52392.0 / 65536

>>> Gradient explosion detected, grad_norm= 2377493.1780310567
>>> Gradient explosion detected, grad_norm= 1019024.4870686191
[batch 40] loss=3.930907e+08 loss_diff=9.656768e-01 recon=3.930907e+08
obs_tick range: -1.0 407000.0  next_tick range: -1.0 406900.0
normed next range: -1000000.0 25670.34765625
pred range: -278.9371337890625 11.093728065490723
mask valid positions: 27970.0 / 65536

[batch 50] loss=4.535588e+08 loss_diff=9.184895e-01 recon=4.535588e+08
obs_tick range: -0.9990477561950684 409800.0  next_tick range: -1.0 409600.0
normed next range: -1000000.0 7913.5068359375
pred range: -279.7247314453125 5.718866348266602
mask valid positions: 49884.0 / 65536

[batch 60] loss=2.193573e+08 loss_diff=9.295210e-01 recon=2.193573e+08
obs_tick range: -1.0 300500.0  next_tick range: -1.0 389300.0
normed next range: -1000000.0 5134.5263671875
pred range: -280.3981018066406 8.354698181152344
mask valid positions: 41840.0 / 65536

[batch 70] loss=2.209665e+08 loss_diff=9.284078e-01 recon=2.209665e+08
obs_tick range: -0.9914443492889404 299000.0  next_tick range: -0.9961932301521301 299000.0
normed next range: -1000000.0 4121.76123046875
pred range: -281.2100524902344 5.186622619628906
mask valid positions: 57575.0 / 65536

[batch 80] loss=2.242168e+08 loss_diff=9.536481e-01 recon=2.242168e+08
obs_tick range: -0.999048113822937 398200.0  next_tick range: -0.9990480542182922 397400.0
normed next range: -1000000.0 6820.0400390625
pred range: -281.98681640625 5.444037914276123
mask valid positions: 55523.0 / 65536

[batch 90] loss=3.931569e+08 loss_diff=9.319265e-01 recon=3.931569e+08
obs_tick range: -0.9762958884239197 411300.0  next_tick range: -0.9848065376281738 410100.0
normed next range: -1000000.0 1000000.0
pred range: -282.9767150878906 6.411620140075684
mask valid positions: 57781.0 / 65536

[batch 100] loss=2.854157e+02 loss_diff=9.289106e-01 recon=2.844868e+02
obs_tick range: -0.9974955916404724 409200.0  next_tick range: -1.0 409500.0
normed next range: -1000000.0 6242.36279296875
pred range: -282.95556640625 9.880054473876953
mask valid positions: 45070.0 / 65536

[batch 110] loss=6.793626e+08 loss_diff=9.369631e-01 recon=6.793626e+08
obs_tick range: -0.9961941242218018 415600.0  next_tick range: -1.0 415900.0
normed next range: -1000000.0 9634.5830078125
pred range: -284.4410095214844 4.971757411956787
mask valid positions: 52161.0 / 65536

[batch 120] loss=9.842883e+08 loss_diff=9.069234e-01 recon=9.842883e+08
obs_tick range: -0.9990480542182922 417900.0  next_tick range: -1.0 409654.0
normed next range: -1000000.0 5990.09130859375
pred range: -284.6424560546875 8.454584121704102
mask valid positions: 59079.0 / 65536

==============================
[2014-12][Epoch 4/20] | Time = 4.58 min
 - Total Loss : 2192546849.538978 | Recon Loss: 2192546849.377215 | Diff Loss: 0.950704
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2014-12 completed in 18.22 min
[1] 2015-01 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-01 | file : news_20150131.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.604591e+10 loss_diff=9.584143e-01 recon=1.604591e+10
obs_tick range: -0.9961943030357361 395700.0  next_tick range: -0.999048113822937 393300.0
normed next range: -1000000.0 2314.775634765625
pred range: -285.2421569824219 5.558949947357178
mask valid positions: 64195.0 / 65536

[batch 10] loss=9.979123e+08 loss_diff=9.330766e-01 recon=9.979123e+08
obs_tick range: -0.996194064617157 374600.0  next_tick range: -0.999048113822937 375000.0
normed next range: -1000000.0 4989.5849609375
pred range: -286.0732421875 6.755278587341309
mask valid positions: 35692.0 / 65536

[batch 20] loss=6.433541e+08 loss_diff=9.517988e-01 recon=6.433541e+08
obs_tick range: -1.0 392500.0  next_tick range: -1.0 392600.0
normed next range: -1000000.0 6617.62109375
pred range: -286.97412109375 19.02554702758789
mask valid positions: 42652.0 / 65536

[batch 30] loss=2.243098e+09 loss_diff=1.018765e+00 recon=2.243098e+09
obs_tick range: -0.9990481734275818 375000.0  next_tick range: -0.9994696378707886 364100.0
normed next range: -1000000.0 4883.69140625
pred range: -288.0244140625 11.551970481872559
mask valid positions: 30744.0 / 65536

[batch 40] loss=5.455847e+08 loss_diff=9.136037e-01 recon=5.455847e+08
obs_tick range: -0.9914442300796509 373700.0  next_tick range: -0.9848071932792664 375000.0
normed next range: -1000000.0 7816.45849609375
pred range: -289.03643798828125 9.644603729248047
mask valid positions: 50295.0 / 65536

[batch 50] loss=8.338711e+08 loss_diff=1.035644e+00 recon=8.338711e+08
obs_tick range: -1.0 393300.0  next_tick range: -1.0 393900.0
normed next range: -1000000.0 7111.94189453125
pred range: -290.05517578125 15.072961807250977
mask valid positions: 43694.0 / 65536

[batch 60] loss=7.291807e+08 loss_diff=9.686905e-01 recon=7.291807e+08
obs_tick range: -0.9762945771217346 354700.0  next_tick range: -0.984803318977356 354800.0
normed next range: -1000000.0 2581.0576171875
pred range: -291.08740234375 5.065548419952393
mask valid positions: 50092.0 / 65536

[batch 70] loss=3.954448e+02 loss_diff=8.903878e-01 recon=3.945544e+02
obs_tick range: -1.0 387100.0  next_tick range: -1.0 386200.0
normed next range: -19.445436477661133 6338.51806640625
pred range: -19.02771759033203 12.636841773986816
mask valid positions: 44255.0 / 65536

[batch 80] loss=2.357060e+09 loss_diff=9.782760e-01 recon=2.357060e+09
obs_tick range: -0.99619460105896 376800.0  next_tick range: -0.999048113822937 375100.0
normed next range: -1000000.0 26879.984375
pred range: -293.02215576171875 10.902310371398926
mask valid positions: 36350.0 / 65536

[batch 90] loss=3.072387e+09 loss_diff=9.411368e-01 recon=3.072387e+09
obs_tick range: -0.9993684887886047 378000.0  next_tick range: -1.0 376600.0
normed next range: -1000000.0 5795.81494140625
pred range: -293.990966796875 5.140111446380615
mask valid positions: 30785.0 / 65536

[batch 100] loss=9.135754e+08 loss_diff=9.273328e-01 recon=9.135754e+08
obs_tick range: -1.0 351300.0  next_tick range: -1.0 357500.0
normed next range: -1000000.0 33524.30859375
pred range: -295.0216064453125 16.49519920349121
mask valid positions: 28643.0 / 65536

[batch 110] loss=1.737072e+09 loss_diff=9.363647e-01 recon=1.737072e+09
obs_tick range: -0.9990484118461609 375000.0  next_tick range: -1.0 1692079.0
normed next range: -1000000.0 29729.439453125
pred range: -296.0167236328125 5.369291305541992
mask valid positions: 30651.0 / 65536

[batch 120] loss=2.103110e+09 loss_diff=9.688032e-01 recon=2.103110e+09
obs_tick range: -0.999048113822937 368500.0  next_tick range: -0.9961944222450256 367400.0
normed next range: -1000000.0 3339.024169921875
pred range: -297.0831298828125 7.698695659637451
mask valid positions: 45189.0 / 65536

[batch 130] loss=1.085283e+09 loss_diff=9.609789e-01 recon=1.085283e+09
obs_tick range: -0.9993930459022522 394500.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 2625.8740234375
pred range: -298.2458801269531 7.967373847961426
mask valid positions: 44622.0 / 65536

[batch 140] loss=1.048046e+09 loss_diff=9.460326e-01 recon=1.048046e+09
obs_tick range: -0.9990478157997131 393600.0  next_tick range: -0.9993915557861328 395800.0
normed next range: -1000000.0 25973.568359375
pred range: -299.3009033203125 5.176781177520752
mask valid positions: 36758.0 / 65536

[batch 150] loss=5.732845e+02 loss_diff=9.473355e-01 recon=5.723372e+02
obs_tick range: -0.976296067237854 324100.0  next_tick range: -0.9862925410270691 216800.0
normed next range: -5.0430707931518555 4837.45361328125
pred range: -14.89200210571289 7.8437886238098145
mask valid positions: 35562.0 / 65536

==============================
[2015-01][Epoch 1/20] | Time = 23.99 min
 - Total Loss : 1625439072.026375 | Recon Loss: 1625439071.959360 | Diff Loss: 0.944438
==============================
>>> Saved best checkpoint: ./wm_ckpt\wm_2015-01_best.pt, loss=1625439072.026375
[batch 0] loss=5.341366e+08 loss_diff=9.541723e-01 recon=5.341366e+08
obs_tick range: -0.9848044514656067 390400.0  next_tick range: -0.9914443492889404 393000.0
normed next range: -1000000.0 4035.312744140625
pred range: -301.0257873535156 9.318732261657715
mask valid positions: 34872.0 / 65536

[batch 10] loss=1.499427e+09 loss_diff=9.434639e-01 recon=1.499427e+09
obs_tick range: -1.0 369000.0  next_tick range: -1.0 387100.0
normed next range: -1000000.0 4573.17919921875
pred range: -302.1255187988281 5.233530044555664
mask valid positions: 41871.0 / 65536

[batch 20] loss=1.549050e+09 loss_diff=8.953116e-01 recon=1.549050e+09
obs_tick range: -1.0 750000.0  next_tick range: -0.9659256935119629 376400.0
normed next range: -1000000.0 3271.767578125
pred range: -303.2312927246094 12.279882431030273
mask valid positions: 35368.0 / 65536

[batch 30] loss=4.434209e+08 loss_diff=9.126936e-01 recon=4.434209e+08
obs_tick range: -0.996194064617157 370000.0  next_tick range: -0.999048113822937 372600.0
normed next range: -1000000.0 1625.7041015625
pred range: -304.119384765625 5.151301383972168
mask valid positions: 49998.0 / 65536

[batch 40] loss=9.676683e+08 loss_diff=9.615535e-01 recon=9.676683e+08
obs_tick range: -0.9995337724685669 343000.0  next_tick range: -1.0 365600.0
normed next range: -1000000.0 5944.30126953125
pred range: -304.9506530761719 17.417457580566406
mask valid positions: 44318.0 / 65536

[batch 50] loss=1.237482e+09 loss_diff=9.402955e-01 recon=1.237482e+09
obs_tick range: -0.996190071105957 369000.0  next_tick range: -0.9972502589225769 370000.0
normed next range: -1000000.0 4642.5771484375
pred range: -306.0124816894531 5.576149940490723
mask valid positions: 35609.0 / 65536

[batch 60] loss=5.769036e+08 loss_diff=8.978522e-01 recon=5.769036e+08
obs_tick range: -1.0 374000.0  next_tick range: -1.0 374400.0
normed next range: -1000000.0 4261.625
pred range: -306.9378356933594 7.3234100341796875
mask valid positions: 50556.0 / 65536

[batch 70] loss=7.600433e+08 loss_diff=9.282436e-01 recon=7.600433e+08
obs_tick range: -0.9762961268424988 363900.0  next_tick range: -0.9848081469535828 375000.0
normed next range: -1000000.0 1471.1134033203125
pred range: -307.998291015625 7.192817687988281
mask valid positions: 42916.0 / 65536

[batch 80] loss=1.795021e+09 loss_diff=9.009861e-01 recon=1.795021e+09
obs_tick range: -1.0 367900.0  next_tick range: -0.9969472289085388 565000.0
normed next range: -1000000.0 7241.83544921875
pred range: -309.0146484375 5.276269435882568
mask valid positions: 41454.0 / 65536

[batch 90] loss=5.206347e+01 loss_diff=9.021975e-01 recon=5.116127e+01
obs_tick range: -0.9961910843849182 330600.0  next_tick range: -0.9961931705474854 351900.0
normed next range: -2.8187990188598633 2849.06005859375
pred range: -19.38709259033203 10.889612197875977
mask valid positions: 51638.0 / 65536

[batch 100] loss=1.483162e+09 loss_diff=8.925600e-01 recon=1.483162e+09
obs_tick range: -0.9993933439254761 378000.0  next_tick range: -1.0 376600.0
normed next range: -1000000.0 4947.57080078125
pred range: -310.97174072265625 6.0215325355529785
mask valid positions: 44596.0 / 65536

[batch 110] loss=1.453784e+09 loss_diff=9.520530e-01 recon=1.453784e+09
obs_tick range: -1.0 371400.0  next_tick range: -1.0 373300.0
normed next range: -1000000.0 2945.451416015625
pred range: -312.0322265625 5.313284873962402
mask valid positions: 58184.0 / 65536

[batch 120] loss=5.442786e+08 loss_diff=8.866376e-01 recon=5.442786e+08
obs_tick range: -0.991443395614624 362700.0  next_tick range: -0.99619460105896 375000.0
normed next range: -1000000.0 2926.17578125
pred range: -312.994384765625 5.3520402908325195
mask valid positions: 40565.0 / 65536

[batch 130] loss=1.696302e+09 loss_diff=8.979341e-01 recon=1.696302e+09
obs_tick range: -1.0 393000.0  next_tick range: -0.9990481734275818 392900.0
normed next range: -1000000.0 2344.51171875
pred range: -313.7867126464844 5.497148036956787
mask valid positions: 50615.0 / 65536

[batch 140] loss=1.873808e+09 loss_diff=9.494918e-01 recon=1.873808e+09
obs_tick range: -1.0 378000.0  next_tick range: -0.9990481734275818 375000.0
normed next range: -1000000.0 4678.6494140625
pred range: -314.92095947265625 5.96278190612793
mask valid positions: 36074.0 / 65536

[batch 150] loss=1.773256e+09 loss_diff=9.502801e-01 recon=1.773256e+09
obs_tick range: -0.9993932247161865 325000.0  next_tick range: -1.0 361000.0
normed next range: -1000000.0 6235.46826171875
pred range: -315.8727111816406 15.58325481414795
mask valid positions: 30998.0 / 65536

>>> Gradient explosion detected, grad_norm= 1225018.212641403
==============================
[2015-01][Epoch 2/20] | Time = 24.44 min
 - Total Loss : 1779704175.977665 | Recon Loss: 1779704175.905098 | Diff Loss: 0.939866
==============================
No improvement count: 1
[batch 0] loss=7.417636e+08 loss_diff=9.492941e-01 recon=7.417636e+08
obs_tick range: -0.9659275412559509 354800.0  next_tick range: -0.9781534671783447 586459.0
normed next range: -1000000.0 12564.2412109375
pred range: -316.4960632324219 7.2426910400390625
mask valid positions: 28907.0 / 65536

[batch 10] loss=2.104441e+08 loss_diff=9.441500e-01 recon=2.104441e+08
obs_tick range: -1.0 338600.0  next_tick range: -1.0 373300.0
normed next range: -1000000.0 3053.222900390625
pred range: -317.4559326171875 5.594812870025635
mask valid positions: 49656.0 / 65536

[batch 20] loss=1.092167e+10 loss_diff=9.790829e-01 recon=1.092167e+10
obs_tick range: -1.0 393600.0  next_tick range: -1.0 395800.0
normed next range: -1000000.0 2323.282958984375
pred range: -318.4827880859375 5.5129876136779785
mask valid positions: 63712.0 / 65536

[batch 30] loss=1.501041e+09 loss_diff=9.437889e-01 recon=1.501041e+09
obs_tick range: -1.0 379500.0  next_tick range: -0.9990479350090027 379200.0
normed next range: -1000000.0 2362.340087890625
pred range: -319.4283447265625 5.602187633514404
mask valid positions: 50480.0 / 65536

[batch 40] loss=7.053583e+08 loss_diff=9.733840e-01 recon=7.053583e+08
obs_tick range: -1.0 394400.0  next_tick range: -0.9972502589225769 565000.0
normed next range: -1000000.0 10581.3974609375
pred range: -320.26751708984375 9.563868522644043
mask valid positions: 42507.0 / 65536

[batch 50] loss=6.766913e+08 loss_diff=9.779224e-01 recon=6.766913e+08
obs_tick range: -0.9537127614021301 361600.0  next_tick range: -0.9396884441375732 362300.0
normed next range: -1000000.0 8130.65576171875
pred range: -321.22833251953125 8.767094612121582
mask valid positions: 41623.0 / 65536

[batch 60] loss=2.118345e+09 loss_diff=9.556432e-01 recon=2.118345e+09
obs_tick range: -0.9990479350090027 351000.0  next_tick range: -0.9961943626403809 321000.0
normed next range: -1000000.0 8347.0
pred range: -322.1761169433594 10.255499839782715
mask valid positions: 35512.0 / 65536

[batch 70] loss=8.129647e+08 loss_diff=9.869202e-01 recon=8.129647e+08
obs_tick range: -0.9914445281028748 368000.0  next_tick range: -0.991442084312439 367400.0
normed next range: -1000000.0 17261.16796875
pred range: -323.1473693847656 10.010497093200684
mask valid positions: 36433.0 / 65536

[batch 80] loss=1.533623e+09 loss_diff=1.008024e+00 recon=1.533623e+09
obs_tick range: -0.9990479946136475 365800.0  next_tick range: -0.9961941242218018 367500.0
normed next range: -1000000.0 1693.634033203125
pred range: -324.1258239746094 13.084907531738281
mask valid positions: 40817.0 / 65536

[batch 90] loss=1.603941e+09 loss_diff=9.785663e-01 recon=1.603941e+09
obs_tick range: -1.0 392200.0  next_tick range: -0.9990479350090027 392000.0
normed next range: -1000000.0 13614.2080078125
pred range: -325.1492614746094 9.78335189819336
mask valid positions: 43559.0 / 65536

[batch 100] loss=2.646272e+09 loss_diff=9.194756e-01 recon=2.646272e+09
obs_tick range: -0.9994696378707886 392000.0  next_tick range: -1.0 393600.0
normed next range: -1000000.0 9146.70703125
pred range: -326.11529541015625 7.4237847328186035
mask valid positions: 37834.0 / 65536

[batch 110] loss=2.543587e+08 loss_diff=9.625766e-01 recon=2.543587e+08
obs_tick range: -1.0 382400.0  next_tick range: -0.9990481734275818 381500.0
normed next range: -1000000.0 5044.109375
pred range: -327.0978088378906 7.228554725646973
mask valid positions: 50368.0 / 65536

[batch 120] loss=2.115739e+09 loss_diff=9.382583e-01 recon=2.115739e+09
obs_tick range: -1.0 368000.0  next_tick range: -0.9961943030357361 326200.0
normed next range: -1000000.0 3567.5693359375
pred range: -328.1825256347656 5.793105602264404
mask valid positions: 36586.0 / 65536

[batch 130] loss=1.596678e+09 loss_diff=9.449063e-01 recon=1.596678e+09
obs_tick range: -0.953707218170166 378000.0  next_tick range: -0.9659252166748047 371400.0
normed next range: -1000000.0 2165.487060546875
pred range: -329.2835998535156 6.060153484344482
mask valid positions: 58267.0 / 65536

[batch 140] loss=6.691623e+08 loss_diff=8.608604e-01 recon=6.691623e+08
obs_tick range: -0.9990478754043579 368000.0  next_tick range: -1.0 370000.0
normed next range: -1000000.0 7082.65380859375
pred range: -330.01336669921875 12.18471622467041
mask valid positions: 27834.0 / 65536

[batch 150] loss=1.363732e+09 loss_diff=8.921350e-01 recon=1.363732e+09
obs_tick range: -1.0 329800.0  next_tick range: -0.9990478157997131 351500.0
normed next range: -1000000.0 5233.76416015625
pred range: -331.26318359375 11.111133575439453
mask valid positions: 41971.0 / 65536

==============================
[2015-01][Epoch 3/20] | Time = 24.60 min
 - Total Loss : 1575294166.203582 | Recon Loss: 1575294166.132576 | Diff Loss: 0.942869
==============================
>>> Saved best checkpoint: ./wm_ckpt\wm_2015-01_best.pt, loss=1575294166.203582
[batch 0] loss=6.692986e+08 loss_diff=9.178149e-01 recon=6.692986e+08
obs_tick range: -0.9787248969078064 376600.0  next_tick range: -0.986998438835144 375000.0
normed next range: -1000000.0 6282.73095703125
pred range: -331.86346435546875 12.849157333374023
mask valid positions: 35973.0 / 65536

[batch 10] loss=1.074287e+09 loss_diff=9.599031e-01 recon=1.074287e+09
obs_tick range: -1.0 368500.0  next_tick range: -0.9914447665214539 365600.0
normed next range: -1000000.0 2809.26513671875
pred range: -332.83135986328125 10.74110221862793
mask valid positions: 43131.0 / 65536

[batch 20] loss=1.165906e+09 loss_diff=8.820885e-01 recon=1.165906e+09
obs_tick range: -0.9659201502799988 369000.0  next_tick range: -0.9762955904006958 333000.0
normed next range: -1000000.0 2745.4404296875
pred range: -333.8330078125 6.807084560394287
mask valid positions: 43404.0 / 65536

[batch 30] loss=1.104926e+10 loss_diff=1.003349e+00 recon=1.104926e+10
obs_tick range: -0.9961943030357361 395700.0  next_tick range: -0.999048113822937 392500.0
normed next range: -1000000.0 3894.30419921875
pred range: -334.9155578613281 6.1556878089904785
mask valid positions: 63887.0 / 65536

[batch 40] loss=5.093464e+08 loss_diff=9.137281e-01 recon=5.093464e+08
obs_tick range: -0.9914442896842957 388500.0  next_tick range: -0.984804630279541 390800.0
normed next range: -1000000.0 2302.683349609375
pred range: -335.8488464355469 15.499798774719238
mask valid positions: 50481.0 / 65536

[batch 50] loss=1.995866e+09 loss_diff=9.385009e-01 recon=1.995866e+09
obs_tick range: -1.0 392600.0  next_tick range: -1.0 391500.0
normed next range: -1000000.0 5457.0830078125
pred range: -336.94781494140625 13.315350532531738
mask valid positions: 35915.0 / 65536

[batch 60] loss=1.145614e+09 loss_diff=9.195457e-01 recon=1.145614e+09
obs_tick range: -0.9990478157997131 367100.0  next_tick range: -1.0 371500.0
normed next range: -1000000.0 2478.8447265625
pred range: -337.7880554199219 6.598341941833496
mask valid positions: 43776.0 / 65536

[batch 70] loss=4.421594e+08 loss_diff=8.831231e-01 recon=4.421594e+08
obs_tick range: -1.0 375000.0  next_tick range: -1.0 378400.0
normed next range: -1000000.0 13450.1513671875
pred range: -338.7636413574219 6.831910133361816
mask valid positions: 48905.0 / 65536

[batch 80] loss=1.692807e+09 loss_diff=9.603925e-01 recon=1.692807e+09
obs_tick range: -0.9990478754043579 395000.0  next_tick range: -1.0 395000.0
normed next range: -1000000.0 2431.1396484375
pred range: -339.62030029296875 10.057260513305664
mask valid positions: 45565.0 / 65536

[batch 90] loss=2.045971e+09 loss_diff=9.603499e-01 recon=2.045971e+09
obs_tick range: -0.9969200491905212 392000.0  next_tick range: -0.9992408752441406 393600.0
normed next range: -1000000.0 2605.9150390625
pred range: -340.57501220703125 6.105570316314697
mask valid positions: 51687.0 / 65536

[batch 100] loss=9.410564e+08 loss_diff=9.694607e-01 recon=9.410564e+08
obs_tick range: -1.0 375000.0  next_tick range: -0.9848085641860962 375000.0
normed next range: -1000000.0 15034.7451171875
pred range: -341.4833679199219 9.020368576049805
mask valid positions: 19405.0 / 65536

>>> Gradient explosion detected, grad_norm= 1500758.6638423125
[batch 110] loss=2.127433e+09 loss_diff=9.279424e-01 recon=2.127433e+09
obs_tick range: -1.0 367300.0  next_tick range: -1.0 369500.0
normed next range: -1000000.0 7800.91357421875
pred range: -342.53997802734375 10.221898078918457
mask valid positions: 43772.0 / 65536

[batch 120] loss=1.245712e+09 loss_diff=9.598373e-01 recon=1.245712e+09
obs_tick range: -0.9659268856048584 378000.0  next_tick range: -0.9781553149223328 243400.0
normed next range: -1000000.0 10267.3115234375
pred range: -343.4000244140625 8.261558532714844
mask valid positions: 28662.0 / 65536

[batch 130] loss=1.404178e+10 loss_diff=9.418352e-01 recon=1.404178e+10
obs_tick range: -0.999048113822937 379100.0  next_tick range: -1.0 379300.0
normed next range: -1000000.0 1000000.0
pred range: -344.314208984375 6.23207426071167
mask valid positions: 59394.0 / 65536

>>> Gradient explosion detected, grad_norm= 1044323.0831677218
[batch 140] loss=1.657472e+09 loss_diff=9.693164e-01 recon=1.657472e+09
obs_tick range: -0.999048113822937 395000.0  next_tick range: -1.0 392200.0
normed next range: -1000000.0 4800.7763671875
pred range: -345.4182434082031 10.514564514160156
mask valid positions: 35628.0 / 65536

[batch 150] loss=3.406192e+08 loss_diff=1.013880e+00 recon=3.406192e+08
obs_tick range: -0.9781502485275269 394500.0  next_tick range: -0.9862877130508423 393300.0
normed next range: -1000000.0 2893.079345703125
pred range: -346.277099609375 10.605422019958496
mask valid positions: 35477.0 / 65536

>>> Gradient explosion detected, grad_norm= 1289185.9162223616
>>> Gradient explosion detected, grad_norm= 1219944.9958135094
==============================
[2015-01][Epoch 4/20] | Time = 24.34 min
 - Total Loss : 1884707599.100116 | Recon Loss: 1884707599.027538 | Diff Loss: 0.943569
==============================
No improvement count: 1
[batch 0] loss=8.217503e+08 loss_diff=9.611478e-01 recon=8.217503e+08
obs_tick range: -0.9914445281028748 363900.0  next_tick range: -0.9914395213127136 330000.0
normed next range: -1000000.0 5727.45361328125
pred range: -346.79327392578125 7.452802658081055
mask valid positions: 50415.0 / 65536

[batch 10] loss=5.511123e+08 loss_diff=9.768566e-01 recon=5.511123e+08
obs_tick range: -0.9990479350090027 379100.0  next_tick range: -1.0 379300.0
normed next range: -1000000.0 3704.440673828125
pred range: -347.54010009765625 10.503063201904297
mask valid positions: 48632.0 / 65536

[batch 20] loss=1.768589e+03 loss_diff=1.002228e+00 recon=1.767587e+03
obs_tick range: -1.0 386200.0  next_tick range: -0.9969229698181152 565000.0
normed next range: -2.4748737812042236 12099.12890625
pred range: -10.041154861450195 14.339004516601562
mask valid positions: 36482.0 / 65536

[batch 30] loss=5.274614e+08 loss_diff=9.376077e-01 recon=5.274614e+08
obs_tick range: -1.0 365500.0  next_tick range: -1.0 365000.0
normed next range: -1000000.0 8208.6240234375
pred range: -349.1741027832031 7.277607440948486
mask valid positions: 40995.0 / 65536

>>> Gradient explosion detected, grad_norm= 2440323.708438011
[batch 40] loss=1.563541e+09 loss_diff=9.730247e-01 recon=1.563541e+09
obs_tick range: -1.0 750000.0  next_tick range: -0.9914414286613464 330600.0
normed next range: -1000000.0 2709.890380859375
pred range: -350.0212097167969 9.39047908782959
mask valid positions: 34398.0 / 65536

[batch 50] loss=2.363676e+09 loss_diff=9.353748e-01 recon=2.363676e+09
obs_tick range: -0.9961949586868286 371500.0  next_tick range: -0.9993934631347656 376800.0
normed next range: -1000000.0 1000000.0
pred range: -350.97479248046875 7.713778495788574
mask valid positions: 14913.0 / 65536

[batch 60] loss=8.591625e+02 loss_diff=9.674693e-01 recon=8.581951e+02
obs_tick range: -0.99619460105896 376600.0  next_tick range: -0.9914447069168091 374600.0
normed next range: -19.445436477661133 9828.9912109375
pred range: -14.102583885192871 9.623320579528809
mask valid positions: 51092.0 / 65536

>>> Gradient explosion detected, grad_norm= 5231917.591328075
>>> Gradient explosion detected, grad_norm= 4518446.680370829
[batch 70] loss=1.491965e+09 loss_diff=9.565816e-01 recon=1.491965e+09
obs_tick range: -1.0 379600.0  next_tick range: -0.9993915557861328 379500.0
normed next range: -1000000.0 7126.9248046875
pred range: -350.7604675292969 96.77483367919922
mask valid positions: 35865.0 / 65536

>>> Gradient explosion detected, grad_norm= 1060049.387965272
>>> Gradient explosion detected, grad_norm= 3280349.4645942505
>>> Gradient explosion detected, grad_norm= 3867938.580183765
>>> Gradient explosion detected, grad_norm= 3629318.773418989
>>> Gradient explosion detected, grad_norm= 8457112.599257704
[batch 80] loss=7.825983e+08 loss_diff=1.000091e+00 recon=7.825983e+08
obs_tick range: -0.9995337724685669 380000.0  next_tick range: -1.0 379900.0
normed next range: -1000000.0 20694.376953125
pred range: -351.5624084472656 11.513872146606445
mask valid positions: 30067.0 / 65536

>>> Gradient explosion detected, grad_norm= 38734520.317389496
[batch 90] loss=8.739991e+08 loss_diff=9.647484e-01 recon=8.739991e+08
obs_tick range: -0.9993684887886047 366100.0  next_tick range: -1.0 365500.0
normed next range: -1000000.0 11354.6962890625
pred range: -351.5755615234375 55.2327995300293
mask valid positions: 38876.0 / 65536

>>> Gradient explosion detected, grad_norm= 4825564.754962848
>>> Gradient explosion detected, grad_norm= 4929869.003346509
>>> Gradient explosion detected, grad_norm= 1381977.3459925617
[batch 100] loss=7.647583e+08 loss_diff=9.744241e-01 recon=7.647583e+08
obs_tick range: -0.9272217750549316 368700.0  next_tick range: -0.9427904486656189 367900.0
normed next range: -1000000.0 11206.2548828125
pred range: -350.7857666015625 8.906437873840332
mask valid positions: 35045.0 / 65536

>>> Gradient explosion detected, grad_norm= 4902230.76578549
[batch 110] loss=6.550877e+08 loss_diff=9.445039e-01 recon=6.550877e+08
obs_tick range: -0.9396912455558777 392900.0  next_tick range: -0.9238758087158203 391500.0
normed next range: -1000000.0 1000000.0
pred range: -352.22076416015625 72.56517028808594
mask valid positions: 49787.0 / 65536

>>> Gradient explosion detected, grad_norm= 2275683.022467831
>>> Gradient explosion detected, grad_norm= 1003245.9057469015
[batch 120] loss=7.375676e+08 loss_diff=9.040673e-01 recon=7.375676e+08
obs_tick range: -1.0 329800.0  next_tick range: -0.9990478157997131 500000.0
normed next range: -1000000.0 35068.33984375
pred range: -353.1654968261719 70.0812759399414
mask valid positions: 26975.0 / 65536

[batch 130] loss=3.582915e+08 loss_diff=9.941411e-01 recon=3.582915e+08
obs_tick range: -1.0 363400.0  next_tick range: -1.0 350700.0
normed next range: -1000000.0 2471.41259765625
pred range: -353.7313537597656 63.58905792236328
mask valid positions: 49951.0 / 65536

>>> Gradient explosion detected, grad_norm= 4634860.030545203
>>> Gradient explosion detected, grad_norm= 4924327.400455898
>>> Gradient explosion detected, grad_norm= 3755900.2995793554
>>> Gradient explosion detected, grad_norm= 3886015.7050058804
>>> Gradient explosion detected, grad_norm= 2892426.4903685367
[batch 140] loss=1.488668e+09 loss_diff=9.302949e-01 recon=1.488668e+09
obs_tick range: -1.0 367100.0  next_tick range: -0.9990472793579102 367900.0
normed next range: -1000000.0 3383.04248046875
pred range: -353.2394714355469 11.740118026733398
mask valid positions: 58342.0 / 65536

[batch 150] loss=2.078913e+09 loss_diff=9.950769e-01 recon=2.078913e+09
obs_tick range: -0.9993920922279358 365800.0  next_tick range: -1.0 366100.0
normed next range: -1000000.0 8444.033203125
pred range: -354.98480224609375 10.212542533874512
mask valid positions: 44399.0 / 65536

==============================
[2015-01][Epoch 5/20] | Time = 23.86 min
 - Total Loss : 1411389600.045338 | Recon Loss: 1411389599.972235 | Diff Loss: 0.948037
==============================
>>> Saved best checkpoint: ./wm_ckpt\wm_2015-01_best.pt, loss=1411389600.045338
[batch 0] loss=1.244637e+09 loss_diff=9.354937e-01 recon=1.244637e+09
obs_tick range: -0.9537165760993958 375500.0  next_tick range: -0.9659193158149719 384100.0
normed next range: -1000000.0 6150.47607421875
pred range: -355.59552001953125 9.924718856811523
mask valid positions: 35839.0 / 65536

[batch 10] loss=5.518987e+08 loss_diff=9.569894e-01 recon=5.518987e+08
obs_tick range: -0.9659199118614197 393000.0  next_tick range: -0.9762876033782959 393600.0
normed next range: -1000000.0 5056.21240234375
pred range: -356.6832580566406 12.987686157226562
mask valid positions: 34570.0 / 65536

[batch 20] loss=1.580940e+09 loss_diff=8.978953e-01 recon=1.580940e+09
obs_tick range: -0.9995337724685669 367300.0  next_tick range: -1.0 367300.0
normed next range: -1000000.0 28203.224609375
pred range: -357.70941162109375 13.961225509643555
mask valid positions: 30399.0 / 65536

[batch 30] loss=6.774601e+08 loss_diff=9.207373e-01 recon=6.774601e+08
obs_tick range: -1.0 374000.0  next_tick range: -1.0 374400.0
normed next range: -1000000.0 1221.204345703125
pred range: -358.57940673828125 9.983839988708496
mask valid positions: 58202.0 / 65536

[batch 40] loss=1.724862e+09 loss_diff=8.725851e-01 recon=1.724862e+09
obs_tick range: -0.9990478157997131 650000.0  next_tick range: -0.9990479350090027 368700.0
normed next range: -1000000.0 2710.939208984375
pred range: -359.595458984375 6.67087984085083
mask valid positions: 56620.0 / 65536

[batch 50] loss=1.349439e+09 loss_diff=9.666889e-01 recon=1.349439e+09
obs_tick range: -1.0 371400.0  next_tick range: -0.9990479946136475 375000.0
normed next range: -1000000.0 7028.5869140625
pred range: -360.64739990234375 6.566170692443848
mask valid positions: 48405.0 / 65536

[batch 60] loss=1.804756e+09 loss_diff=9.073678e-01 recon=1.804756e+09
obs_tick range: -0.9762871265411377 375000.0  next_tick range: -0.9848047494888306 352700.0
normed next range: -1000000.0 1518.046142578125
pred range: -361.67486572265625 6.511514663696289
mask valid positions: 58191.0 / 65536

[batch 70] loss=1.543382e+09 loss_diff=9.883842e-01 recon=1.543382e+09
obs_tick range: -0.9969472289085388 392300.0  next_tick range: -0.9990483522415161 392200.0
normed next range: -1000000.0 7759.24755859375
pred range: -362.61163330078125 9.285293579101562
mask valid positions: 36789.0 / 65536

[batch 80] loss=1.874647e+09 loss_diff=9.224000e-01 recon=1.874647e+09
obs_tick range: -0.976296067237854 1750000.0  next_tick range: -0.9862925410270691 394800.0
normed next range: -1000000.0 6114.22998046875
pred range: -363.61993408203125 15.10077953338623
mask valid positions: 37218.0 / 65536

[batch 90] loss=1.918815e+09 loss_diff=9.128654e-01 recon=1.918815e+09
obs_tick range: -1.0 364000.0  next_tick range: -1.0 363200.0
normed next range: -1000000.0 3802.614501953125
pred range: -364.7029724121094 9.357281684875488
mask valid positions: 51133.0 / 65536

[batch 100] loss=1.046770e+09 loss_diff=9.383474e-01 recon=1.046770e+09
obs_tick range: -1.0 395000.0  next_tick range: -1.0 394800.0
normed next range: -1000000.0 77330.90625
pred range: -365.6269226074219 14.270730972290039
mask valid positions: 28728.0 / 65536

[batch 110] loss=2.121809e+09 loss_diff=9.989448e-01 recon=2.121809e+09
obs_tick range: -1.0 371500.0  next_tick range: -0.9990481734275818 370400.0
normed next range: -1000000.0 5843.9951171875
pred range: -365.5252685546875 76.2509765625
mask valid positions: 50950.0 / 65536

>>> Gradient explosion detected, grad_norm= 3158183.771026439
[batch 120] loss=5.601867e+08 loss_diff=9.428880e-01 recon=5.601867e+08
obs_tick range: -0.9993917942047119 363900.0  next_tick range: -1.0 327000.0
normed next range: -1000000.0 2366.087158203125
pred range: -366.2841491699219 58.0583610534668
mask valid positions: 44110.0 / 65536

>>> Gradient explosion detected, grad_norm= 1248700.625986913
>>> Gradient explosion detected, grad_norm= 1982889.2926261013
>>> Gradient explosion detected, grad_norm= 1946519.26253327
[batch 130] loss=6.203667e+03 loss_diff=9.586343e-01 recon=6.202708e+03
obs_tick range: -0.9990480542182922 369000.0  next_tick range: -1.0 871959.0
normed next range: -10.960155487060547 26317.50390625
pred range: -362.29510498046875 18.85670280456543
mask valid positions: 27837.0 / 65536

>>> Gradient explosion detected, grad_norm= 27682988.33636334
>>> Gradient explosion detected, grad_norm= 1471697.427361487
[batch 140] loss=1.254053e+09 loss_diff=9.085152e-01 recon=1.254053e+09
obs_tick range: -0.9848081469535828 371700.0  next_tick range: -0.992336630821228 373300.0
normed next range: -1000000.0 2044.1322021484375
pred range: -367.43927001953125 62.02909851074219
mask valid positions: 51216.0 / 65536

>>> Gradient explosion detected, grad_norm= 1884884.7023840342
>>> Gradient explosion detected, grad_norm= 8859144.198976846
[batch 150] loss=1.709944e+02 loss_diff=9.364744e-01 recon=1.700579e+02
obs_tick range: -0.9914447069168091 363900.0  next_tick range: -0.9961932897567749 363900.0
normed next range: -2.474870204925537 3633.549072265625
pred range: -12.740012168884277 10.219396591186523
mask valid positions: 51014.0 / 65536

>>> Gradient explosion detected, grad_norm= 2303267.155858844
>>> Gradient explosion detected, grad_norm= 6971024.739531962
==============================
[2015-01][Epoch 6/20] | Time = 23.80 min
 - Total Loss : 1415566120.778598 | Recon Loss: 1415566120.712080 | Diff Loss: 0.944799
==============================
No improvement count: 1
[batch 0] loss=4.711315e+08 loss_diff=8.716961e-01 recon=4.711315e+08
obs_tick range: -1.0 373700.0  next_tick range: -0.9990481734275818 375000.0
normed next range: -1000000.0 5017.0283203125
pred range: -367.9175720214844 66.81265258789062
mask valid positions: 42807.0 / 65536

[batch 10] loss=8.348651e+08 loss_diff=9.582663e-01 recon=8.348651e+08
obs_tick range: -0.9848082065582275 206900.0  next_tick range: -0.9918777942657471 387100.0
normed next range: -1000000.0 28867.072265625
pred range: -368.4455261230469 70.527099609375
mask valid positions: 29815.0 / 65536

>>> Gradient explosion detected, grad_norm= 1080380.3568864127
[batch 20] loss=2.424358e+09 loss_diff=9.496765e-01 recon=2.424358e+09
obs_tick range: -1.0 379200.0  next_tick range: -0.9990481734275818 380300.0
normed next range: -1000000.0 3651.447998046875
pred range: -369.1209716796875 64.39517211914062
mask valid positions: 51114.0 / 65536

>>> Gradient explosion detected, grad_norm= 1515268.5481957004
>>> Gradient explosion detected, grad_norm= 5015482.4074166
[batch 30] loss=4.991767e+08 loss_diff=9.155539e-01 recon=4.991767e+08
obs_tick range: -0.9961944222450256 364700.0  next_tick range: -0.9914445281028748 368500.0
normed next range: -1000000.0 2771.14990234375
pred range: -369.3785705566406 85.00431823730469
mask valid positions: 36034.0 / 65536

>>> Gradient explosion detected, grad_norm= 1344014.6782615755
>>> Gradient explosion detected, grad_norm= 5386557.577479366
[batch 40] loss=4.672525e+08 loss_diff=9.186336e-01 recon=4.672525e+08
obs_tick range: -0.996920645236969 361000.0  next_tick range: -0.99921715259552 361000.0
normed next range: -1000000.0 4541.15576171875
pred range: -369.7313232421875 64.34173583984375
mask valid positions: 43162.0 / 65536

>>> Gradient explosion detected, grad_norm= 2558963.9726899806
[batch 50] loss=3.494676e+08 loss_diff=9.894262e-01 recon=3.494676e+08
obs_tick range: -0.9925495982170105 327600.0  next_tick range: -0.9972280859947205 330000.0
normed next range: -1000000.0 4053.546142578125
pred range: -370.276611328125 89.00586700439453
mask valid positions: 50691.0 / 65536

>>> Gradient explosion detected, grad_norm= 4953985.750748391
>>> Gradient explosion detected, grad_norm= 1415698.407796683
[batch 60] loss=1.063092e+09 loss_diff=9.687340e-01 recon=1.063092e+09
obs_tick range: -0.9787248969078064 395000.0  next_tick range: -0.986998438835144 395000.0
normed next range: -1000000.0 1000000.0
pred range: -371.1751708984375 51.97047424316406
mask valid positions: 15211.0 / 65536

>>> Gradient explosion detected, grad_norm= 1660634.895665854
[batch 70] loss=1.712982e+09 loss_diff=9.232857e-01 recon=1.712982e+09
obs_tick range: -0.999048113822937 391500.0  next_tick range: -1.0 390400.0
normed next range: -1000000.0 13227.416015625
pred range: -371.5389709472656 67.06324768066406
mask valid positions: 50752.0 / 65536

>>> Gradient explosion detected, grad_norm= 3344742.6853080937
>>> Gradient explosion detected, grad_norm= 2569373.0909079695
>>> Gradient explosion detected, grad_norm= 3224316.4303722647
[batch 80] loss=2.195813e+09 loss_diff=9.462743e-01 recon=2.195813e+09
obs_tick range: -0.9961946606636047 367900.0  next_tick range: -0.9990478157997131 329700.0
normed next range: -1000000.0 162017.625
pred range: -372.3817138671875 54.89909362792969
mask valid positions: 20853.0 / 65536

[batch 90] loss=1.677566e+09 loss_diff=9.529445e-01 recon=1.677566e+09
obs_tick range: -0.9914447069168091 375100.0  next_tick range: -0.9848074316978455 371500.0
normed next range: -1000000.0 2526.62744140625
pred range: -373.17462158203125 70.16656494140625
mask valid positions: 49603.0 / 65536

>>> Gradient explosion detected, grad_norm= 2697336.991521514
[batch 100] loss=6.423810e+08 loss_diff=9.259233e-01 recon=6.423810e+08
obs_tick range: -0.9862902164459229 365500.0  next_tick range: -0.9930831789970398 362700.0
normed next range: -1000000.0 3133.15869140625
pred range: -374.03546142578125 72.3483657836914
mask valid positions: 50486.0 / 65536

>>> Gradient explosion detected, grad_norm= 1381279.5570455557
[batch 110] loss=7.850944e+08 loss_diff=9.002124e-01 recon=7.850944e+08
obs_tick range: -1.0 393600.0  next_tick range: -1.0 395800.0
normed next range: -1000000.0 3922.087646484375
pred range: -374.78717041015625 70.5206298828125
mask valid positions: 49641.0 / 65536

[batch 120] loss=1.700565e+09 loss_diff=1.004633e+00 recon=1.700565e+09
obs_tick range: -0.9990478157997131 330000.0  next_tick range: -0.9990478754043579 330000.0
normed next range: -1000000.0 5734.71875
pred range: -375.9834289550781 64.17223358154297
mask valid positions: 50749.0 / 65536

[batch 130] loss=3.916970e+08 loss_diff=9.353526e-01 recon=3.916970e+08
obs_tick range: -0.9914456605911255 387100.0  next_tick range: -0.9972506761550903 386200.0
normed next range: -1000000.0 5521.6533203125
pred range: -376.93310546875 66.77205657958984
mask valid positions: 49400.0 / 65536

[batch 140] loss=1.386660e+09 loss_diff=9.550220e-01 recon=1.386660e+09
obs_tick range: -1.0 368700.0  next_tick range: -1.0 367900.0
normed next range: -1000000.0 3740.90771484375
pred range: -377.7999267578125 66.87836456298828
mask valid positions: 35704.0 / 65536

[batch 150] loss=2.534362e+09 loss_diff=9.184107e-01 recon=2.534362e+09
obs_tick range: -0.9993933439254761 371200.0  next_tick range: -1.0 366100.0
normed next range: -1000000.0 2353.98828125
pred range: -378.7404479980469 67.28400421142578
mask valid positions: 52483.0 / 65536

>>> Gradient explosion detected, grad_norm= 1031411.5584067473
==============================
[2015-01][Epoch 7/20] | Time = 23.93 min
 - Total Loss : 1263629424.189481 | Recon Loss: 1263629424.115962 | Diff Loss: 0.941258
==============================
>>> Saved best checkpoint: ./wm_ckpt\wm_2015-01_best.pt, loss=1263629424.189481
[batch 0] loss=2.335095e+09 loss_diff=9.554759e-01 recon=2.335095e+09
obs_tick range: -1.0 379500.0  next_tick range: -0.9914447069168091 379200.0
normed next range: -1000000.0 9353.2001953125
pred range: -379.263916015625 62.91531753540039
mask valid positions: 43688.0 / 65536

>>> Gradient explosion detected, grad_norm= 1531931.576085047
>>> Gradient explosion detected, grad_norm= 1200896.8323969638
[batch 10] loss=3.904478e+08 loss_diff=9.271930e-01 recon=3.904478e+08
obs_tick range: -1.0 369000.0  next_tick range: -0.9990481734275818 367500.0
normed next range: -1000000.0 1262.1707763671875
pred range: -380.1461486816406 53.15450668334961
mask valid positions: 43043.0 / 65536

>>> Gradient explosion detected, grad_norm= 1428283.8128954514
>>> Gradient explosion detected, grad_norm= 1141728.9601569336
[batch 20] loss=2.563802e+09 loss_diff=9.390767e-01 recon=2.563802e+09
obs_tick range: -0.976296067237854 387100.0  next_tick range: -0.9848082065582275 386200.0
normed next range: -1000000.0 24729.517578125
pred range: -380.9817810058594 74.43730163574219
mask valid positions: 36035.0 / 65536

[batch 30] loss=2.281249e+09 loss_diff=9.837835e-01 recon=2.281249e+09
obs_tick range: -0.9914446473121643 369500.0  next_tick range: -0.9848039746284485 366500.0
normed next range: -1000000.0 7529.1435546875
pred range: -381.6187744140625 69.5507583618164
mask valid positions: 43724.0 / 65536

>>> Gradient explosion detected, grad_norm= 7724767.099036582
>>> Gradient explosion detected, grad_norm= 4185677.990273121
>>> Gradient explosion detected, grad_norm= 5403912.973087921
>>> Gradient explosion detected, grad_norm= 4120040.431517769
>>> Gradient explosion detected, grad_norm= 3397167.038772498
>>> Gradient explosion detected, grad_norm= 3077843.2111163633
[batch 40] loss=6.157706e+08 loss_diff=9.541134e-01 recon=6.157706e+08
obs_tick range: -1.0 500000.0  next_tick range: -0.9961944818496704 366200.0
normed next range: -1000000.0 5622.22119140625
pred range: -381.74798583984375 11.90005111694336
mask valid positions: 42785.0 / 65536

[batch 50] loss=5.322984e+08 loss_diff=9.239266e-01 recon=5.322984e+08
obs_tick range: -1.0 354200.0  next_tick range: -0.9990479946136475 353600.0
normed next range: -1000000.0 8706.857421875
pred range: -381.83209228515625 11.436789512634277
mask valid positions: 34134.0 / 65536

>>> Gradient explosion detected, grad_norm= 1327280.7156816425
>>> Gradient explosion detected, grad_norm= 4388097.663475616
[batch 60] loss=1.477452e+09 loss_diff=9.698930e-01 recon=1.477452e+09
obs_tick range: -0.9961931705474854 375000.0  next_tick range: -0.9990481734275818 375500.0
normed next range: -1000000.0 11595.9521484375
pred range: -381.8370056152344 41.12765884399414
mask valid positions: 28591.0 / 65536

>>> Gradient explosion detected, grad_norm= 7259124.779919344
>>> Gradient explosion detected, grad_norm= 5202319.870918417
>>> Gradient explosion detected, grad_norm= 4464071.139828817
>>> Gradient explosion detected, grad_norm= 1153888.7281223482
[batch 70] loss=1.577077e+09 loss_diff=9.824386e-01 recon=1.577077e+09
obs_tick range: -1.0 393600.0  next_tick range: -0.9990481734275818 395000.0
normed next range: -1000000.0 2767.965576171875
pred range: -382.3592834472656 39.688453674316406
mask valid positions: 45102.0 / 65536

[batch 80] loss=1.260226e+09 loss_diff=9.605134e-01 recon=1.260226e+09
obs_tick range: -1.0 394500.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 7728.0029296875
pred range: -382.5466613769531 97.59266662597656
mask valid positions: 36258.0 / 65536

>>> Gradient explosion detected, grad_norm= 3319441.18604032
>>> Gradient explosion detected, grad_norm= 2935617.274599686
[batch 90] loss=1.513380e+09 loss_diff=9.401749e-01 recon=1.513380e+09
obs_tick range: -0.996194064617157 394000.0  next_tick range: -0.999048113822937 371200.0
normed next range: -1000000.0 13035.79296875
pred range: -383.774658203125 58.23744583129883
mask valid positions: 43579.0 / 65536

>>> Gradient explosion detected, grad_norm= 3202901.842288511
[batch 100] loss=1.793930e+10 loss_diff=9.812822e-01 recon=1.793930e+10
obs_tick range: -0.9990472793579102 380000.0  next_tick range: -0.9961941242218018 379900.0
normed next range: -1000000.0 1000000.0
pred range: -384.4112548828125 62.73112869262695
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 22381849.373530336
>>> Gradient explosion detected, grad_norm= 1824598.5094307768
>>> Gradient explosion detected, grad_norm= 15358274.76674878
>>> Gradient explosion detected, grad_norm= 2663771.748248437
[batch 110] loss=1.257134e+09 loss_diff=9.126413e-01 recon=1.257134e+09
obs_tick range: -0.9762946963310242 750000.0  next_tick range: -0.9848071932792664 357900.0
normed next range: -1000000.0 1000000.0
pred range: -383.8172302246094 13.370065689086914
mask valid positions: 49790.0 / 65536

>>> Gradient explosion detected, grad_norm= 1795926.6814625512
>>> Gradient explosion detected, grad_norm= 3066739.5798588726
>>> Gradient explosion detected, grad_norm= 7752717.0452617565
[batch 120] loss=5.969192e+08 loss_diff=9.443223e-01 recon=5.969192e+08
obs_tick range: -1.0 362700.0  next_tick range: -1.0 366100.0
normed next range: -1000000.0 2678.718994140625
pred range: -384.7978210449219 48.4205436706543
mask valid positions: 43525.0 / 65536

>>> Gradient explosion detected, grad_norm= 1395532.831882865
>>> Gradient explosion detected, grad_norm= 1726454.3694725693
>>> Gradient explosion detected, grad_norm= 34228934.68257931
[batch 130] loss=1.631644e+09 loss_diff=8.959220e-01 recon=1.631644e+09
obs_tick range: -0.9961913824081421 225200.0  next_tick range: -0.9990474581718445 367000.0
normed next range: -1000000.0 5822.873046875
pred range: -385.3249816894531 78.85426330566406
mask valid positions: 58236.0 / 65536

>>> Gradient explosion detected, grad_norm= 8148842.207236978
>>> Gradient explosion detected, grad_norm= 6827471.020561595
[batch 140] loss=7.255107e+08 loss_diff=8.794164e-01 recon=7.255107e+08
obs_tick range: -0.9914422631263733 395000.0  next_tick range: -0.9961928129196167 395000.0
normed next range: -1000000.0 2942.427490234375
pred range: -385.578125 58.8397216796875
mask valid positions: 49458.0 / 65536

[batch 150] loss=4.423686e+08 loss_diff=9.310839e-01 recon=4.423686e+08
obs_tick range: -1.0 390700.0  next_tick range: -0.9990479350090027 330300.0
normed next range: -1000000.0 12698.4072265625
pred range: -386.2284240722656 73.52604675292969
mask valid positions: 43125.0 / 65536

==============================
[2015-01][Epoch 8/20] | Time = 24.24 min
 - Total Loss : 1490787083.279446 | Recon Loss: 1490787083.219368 | Diff Loss: 0.936387
==============================
No improvement count: 1
[batch 0] loss=7.712389e+08 loss_diff=9.081726e-01 recon=7.712389e+08
obs_tick range: -0.9995337724685669 364200.0  next_tick range: -1.0 363000.0
normed next range: -1000000.0 6566.32470703125
pred range: -386.5240783691406 80.10553741455078
mask valid positions: 44288.0 / 65536

>>> Gradient explosion detected, grad_norm= 2553510.954678572
>>> Gradient explosion detected, grad_norm= 2376875.5906978473
>>> Gradient explosion detected, grad_norm= 7392297.739127866
[batch 10] loss=1.560691e+08 loss_diff=9.433386e-01 recon=1.560691e+08
obs_tick range: -0.9990479350090027 361000.0  next_tick range: -1.0 366100.0
normed next range: -1000000.0 47073.671875
pred range: -387.3410949707031 88.29529571533203
mask valid positions: 36090.0 / 65536

>>> Gradient explosion detected, grad_norm= 4942366.293379159
[batch 20] loss=6.477495e+08 loss_diff=9.864490e-01 recon=6.477495e+08
obs_tick range: -0.9990483522415161 375000.0  next_tick range: -1.0 378400.0
normed next range: -1000000.0 8640.4287109375
pred range: -387.9781188964844 92.73521423339844
mask valid positions: 22018.0 / 65536

>>> Gradient explosion detected, grad_norm= 3737484.476348732
>>> Gradient explosion detected, grad_norm= 7186179.601875734
>>> Gradient explosion detected, grad_norm= 1889178.270275865
>>> Gradient explosion detected, grad_norm= 1395763.570625604
[batch 30] loss=1.275434e+09 loss_diff=9.059857e-01 recon=1.275434e+09
obs_tick range: -0.9949765801429749 367400.0  next_tick range: -0.9969472289085388 367500.0
normed next range: -1000000.0 1634.6636962890625
pred range: -387.65167236328125 28.926313400268555
mask valid positions: 43376.0 / 65536

>>> Gradient explosion detected, grad_norm= 12803848.473893391
[batch 40] loss=9.079550e+01 loss_diff=9.217923e-01 recon=8.987371e+01
obs_tick range: -0.9990480542182922 365500.0  next_tick range: -1.0 371500.0
normed next range: -3.11126971244812 2683.17529296875
pred range: -10.581053733825684 16.483783721923828
mask valid positions: 44186.0 / 65536

>>> Gradient explosion detected, grad_norm= 9481273.772237228
>>> Gradient explosion detected, grad_norm= 5238446.247775756
[batch 50] loss=2.086997e+09 loss_diff=9.592122e-01 recon=2.086997e+09
obs_tick range: -0.9990478157997131 367500.0  next_tick range: -1.0 367500.0
normed next range: -1000000.0 7255.0712890625
pred range: -389.0944519042969 47.80354690551758
mask valid positions: 51275.0 / 65536

>>> Gradient explosion detected, grad_norm= 2834846.7653262885
[batch 60] loss=1.228336e+09 loss_diff=9.461139e-01 recon=1.228336e+09
obs_tick range: -1.0 349000.0  next_tick range: -0.9990481734275818 349200.0
normed next range: -1000000.0 1930.97216796875
pred range: -389.7411193847656 94.05687713623047
mask valid positions: 41858.0 / 65536

>>> Gradient explosion detected, grad_norm= 4382026.992090093
>>> Gradient explosion detected, grad_norm= 11601922.154677344
>>> Gradient explosion detected, grad_norm= 8676388.48786461
[batch 70] loss=3.606519e+08 loss_diff=8.961577e-01 recon=3.606519e+08
obs_tick range: -0.9994773268699646 367900.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 12095.8671875
pred range: -389.54638671875 59.12062072753906
mask valid positions: 22166.0 / 65536

>>> Gradient explosion detected, grad_norm= 7035193.116254829
>>> Gradient explosion detected, grad_norm= 9453664.369826447
[batch 80] loss=1.331537e+09 loss_diff=9.216148e-01 recon=1.331537e+09
obs_tick range: -0.999048113822937 871959.0  next_tick range: -1.0 375200.0
normed next range: -1000000.0 11982.1376953125
pred range: -390.36285400390625 97.712646484375
mask valid positions: 42366.0 / 65536

>>> Gradient explosion detected, grad_norm= 1157995.772440594
[batch 90] loss=2.612978e+09 loss_diff=9.118429e-01 recon=2.612978e+09
obs_tick range: -0.9993917346000671 366500.0  next_tick range: -1.0 365800.0
normed next range: -1000000.0 1336.3580322265625
pred range: -390.65106201171875 75.94034576416016
mask valid positions: 60644.0 / 65536

>>> Gradient explosion detected, grad_norm= 5826406.004068822
>>> Gradient explosion detected, grad_norm= 7396204.811138674
[batch 100] loss=9.314430e+08 loss_diff=9.288586e-01 recon=9.314430e+08
obs_tick range: -0.9969194531440735 367100.0  next_tick range: -0.9993917346000671 367100.0
normed next range: -1000000.0 19321.07421875
pred range: -390.84271240234375 78.95211791992188
mask valid positions: 28673.0 / 65536

>>> Gradient explosion detected, grad_norm= 2733679.70570911
[batch 110] loss=2.473294e+09 loss_diff=8.988385e-01 recon=2.473294e+09
obs_tick range: -0.9848065376281738 378000.0  next_tick range: -0.9914395213127136 370900.0
normed next range: -1000000.0 1000000.0
pred range: -391.4481201171875 59.37604904174805
mask valid positions: 51059.0 / 65536

>>> Gradient explosion detected, grad_norm= 1883432.1086124568
>>> Gradient explosion detected, grad_norm= 2428507.1825955915
[batch 120] loss=1.525731e+09 loss_diff=9.505222e-01 recon=1.525731e+09
obs_tick range: -1.0 394500.0  next_tick range: -1.0 393300.0
normed next range: -1000000.0 3904.841064453125
pred range: -392.2132568359375 66.7185287475586
mask valid positions: 56505.0 / 65536

>>> Gradient explosion detected, grad_norm= 2239223.616686195
>>> Gradient explosion detected, grad_norm= 2150238.0837196833
[batch 130] loss=1.423209e+09 loss_diff=9.356195e-01 recon=1.423209e+09
obs_tick range: -0.9659244418144226 391500.0  next_tick range: -0.9762958288192749 390400.0
normed next range: -1000000.0 25307.23828125
pred range: -392.8037414550781 63.33418273925781
mask valid positions: 29297.0 / 65536

[batch 140] loss=1.422186e+09 loss_diff=9.177138e-01 recon=1.422186e+09
obs_tick range: -0.996190071105957 357900.0  next_tick range: -0.9930698871612549 369000.0
normed next range: -1000000.0 5421.853515625
pred range: -393.881591796875 72.44375610351562
mask valid positions: 44520.0 / 65536

>>> Gradient explosion detected, grad_norm= 2444368.654045104
>>> Gradient explosion detected, grad_norm= 1380074.3072796015
>>> Gradient explosion detected, grad_norm= 2393682.207522312
[batch 150] loss=8.612990e+08 loss_diff=8.898573e-01 recon=8.612990e+08
obs_tick range: -0.9272217750549316 368500.0  next_tick range: -0.9427904486656189 369000.0
normed next range: -1000000.0 10648.7509765625
pred range: -394.7237854003906 54.34858322143555
mask valid positions: 50098.0 / 65536

==============================
[2015-01][Epoch 9/20] | Time = 24.16 min
 - Total Loss : 1420278239.785775 | Recon Loss: 1420278239.714571 | Diff Loss: 0.933871
==============================
No improvement count: 2
[batch 0] loss=1.637793e+09 loss_diff=8.969421e-01 recon=1.637793e+09
obs_tick range: -1.0 368000.0  next_tick range: -0.992551326751709 565000.0
normed next range: -1000000.0 8499.2783203125
pred range: -395.00616455078125 68.58152770996094
mask valid positions: 35941.0 / 65536

[batch 10] loss=1.706041e+09 loss_diff=9.029288e-01 recon=1.706041e+09
obs_tick range: -0.9762961268424988 394400.0  next_tick range: -0.9848081469535828 390700.0
normed next range: -1000000.0 3401.304931640625
pred range: -396.0628662109375 69.74810028076172
mask valid positions: 50903.0 / 65536

>>> Gradient explosion detected, grad_norm= 1994559.290571382
>>> Gradient explosion detected, grad_norm= 1865490.9828831777
[batch 20] loss=1.512061e+09 loss_diff=8.888429e-01 recon=1.512061e+09
obs_tick range: -0.984804630279541 394000.0  next_tick range: -0.991443932056427 375200.0
normed next range: -1000000.0 2923.400390625
pred range: -396.8568115234375 67.68138122558594
mask valid positions: 44096.0 / 65536

>>> Gradient explosion detected, grad_norm= 2207697.8739958913
[batch 30] loss=2.303273e+09 loss_diff=9.182183e-01 recon=2.303273e+09
obs_tick range: -0.9862878322601318 236100.0  next_tick range: -0.9927315711975098 367100.0
normed next range: -1000000.0 14815.8701171875
pred range: -397.77886962890625 66.32001495361328
mask valid positions: 36994.0 / 65536

>>> Gradient explosion detected, grad_norm= 2921359.89308176
[batch 40] loss=9.795815e+01 loss_diff=9.559803e-01 recon=9.700217e+01
obs_tick range: -1.0 382400.0  next_tick range: -1.0 381500.0
normed next range: -7.1889190673828125 2595.31591796875
pred range: -394.8379821777344 17.53732681274414
mask valid positions: 42178.0 / 65536

>>> Gradient explosion detected, grad_norm= 8067429.253898012
[batch 50] loss=1.918646e+09 loss_diff=9.088321e-01 recon=1.918646e+09
obs_tick range: -1.0 368400.0  next_tick range: -0.9990479946136475 365000.0
normed next range: -1000000.0 2790.499267578125
pred range: -399.6637268066406 59.74927520751953
mask valid positions: 51136.0 / 65536

>>> Gradient explosion detected, grad_norm= 2595009.7568858718
>>> Gradient explosion detected, grad_norm= 1935825.8081367596
[batch 60] loss=6.682466e+08 loss_diff=9.404774e-01 recon=6.682466e+08
obs_tick range: -0.9990474581718445 331800.0  next_tick range: -0.9961944222450256 357500.0
normed next range: -1000000.0 10943.79296875
pred range: -400.3003845214844 52.08002471923828
mask valid positions: 36295.0 / 65536

>>> Gradient explosion detected, grad_norm= 27839968.31778595
>>> Gradient explosion detected, grad_norm= 4564932.749548331
[batch 70] loss=4.479749e+08 loss_diff=9.147984e-01 recon=4.479749e+08
obs_tick range: -1.0 393300.0  next_tick range: -1.0 392900.0
normed next range: -1000000.0 8340.3076171875
pred range: -400.79779052734375 72.63546752929688
mask valid positions: 34878.0 / 65536

>>> Gradient explosion detected, grad_norm= 1713125.8678065506
[batch 80] loss=1.103338e+09 loss_diff=9.541616e-01 recon=1.103338e+09
obs_tick range: -1.0 389000.0  next_tick range: -1.0 388500.0
normed next range: -1000000.0 7662.68310546875
pred range: -401.4299621582031 59.347740173339844
mask valid positions: 37131.0 / 65536

>>> Gradient explosion detected, grad_norm= 2686772.0170011413
>>> Gradient explosion detected, grad_norm= 2934867.204744868
[batch 90] loss=9.327039e+08 loss_diff=9.333541e-01 recon=9.327039e+08
obs_tick range: -0.99619460105896 233200.0  next_tick range: -0.9914447665214539 324000.0
normed next range: -1000000.0 7540.09033203125
pred range: -402.1690979003906 56.65289306640625
mask valid positions: 40028.0 / 65536

>>> Gradient explosion detected, grad_norm= 1832615.3650887886
[batch 100] loss=2.648839e+08 loss_diff=9.613456e-01 recon=2.648839e+08
obs_tick range: -0.9914442896842957 320600.0  next_tick range: -0.9961903095245361 367100.0
normed next range: -1000000.0 1660.5269775390625
pred range: -402.9503173828125 66.88153839111328
mask valid positions: 48355.0 / 65536

[batch 110] loss=4.998455e+08 loss_diff=9.175072e-01 recon=4.998455e+08
obs_tick range: -0.9914454221725464 393600.0  next_tick range: -0.9969252943992615 395000.0
normed next range: -1000000.0 5904.126953125
pred range: -403.7923583984375 59.28466796875
mask valid positions: 43980.0 / 65536

>>> Gradient explosion detected, grad_norm= 13398778.291805996
>>> Gradient explosion detected, grad_norm= 4678599.834096676
[batch 120] loss=1.377507e+09 loss_diff=9.626313e-01 recon=1.377507e+09
obs_tick range: -0.9961941242218018 371700.0  next_tick range: -0.9914445877075195 373300.0
normed next range: -1000000.0 4549.96875
pred range: -404.66436767578125 13.57687759399414
mask valid positions: 50777.0 / 65536

>>> Gradient explosion detected, grad_norm= 1044413.7236959743
[batch 130] loss=2.088628e+09 loss_diff=9.588051e-01 recon=2.088628e+09
obs_tick range: -0.9990478754043579 371500.0  next_tick range: -1.0 371000.0
normed next range: -1000000.0 2072.26708984375
pred range: -405.0683898925781 61.632415771484375
mask valid positions: 51800.0 / 65536

>>> Gradient explosion detected, grad_norm= 2339176.101710981
[batch 140] loss=5.730541e+01 loss_diff=9.354442e-01 recon=5.636997e+01
obs_tick range: -1.0 366200.0  next_tick range: -0.9961928129196167 373300.0
normed next range: -2.4748735427856445 2850.313720703125
pred range: -9.914718627929688 11.672989845275879
mask valid positions: 51889.0 / 65536

>>> Gradient explosion detected, grad_norm= 2725160.4141565887
[batch 150] loss=1.960546e+09 loss_diff=9.520337e-01 recon=1.960546e+09
obs_tick range: -0.9961913228034973 379500.0  next_tick range: -0.99144047498703 379500.0
normed next range: -1000000.0 4061.704833984375
pred range: -406.3050537109375 103.78604125976562
mask valid positions: 58287.0 / 65536

==============================
[2015-01][Epoch 10/20] | Time = 24.04 min
 - Total Loss : 1419035342.191341 | Recon Loss: 1419035342.119263 | Diff Loss: 0.932335
==============================
No improvement count: 3
[batch 0] loss=4.599487e+08 loss_diff=9.525336e-01 recon=4.599487e+08
obs_tick range: -0.9949765801429749 691449.0  next_tick range: -0.9969472289085388 371700.0
normed next range: -1000000.0 10856.443359375
pred range: -406.4122314453125 86.42452239990234
mask valid positions: 36537.0 / 65536

>>> Gradient explosion detected, grad_norm= 3228052.2096313993
>>> Gradient explosion detected, grad_norm= 1018547.1790266628
>>> Gradient explosion detected, grad_norm= 6558183.672925488
[batch 10] loss=1.779909e+09 loss_diff=9.186328e-01 recon=1.779909e+09
obs_tick range: -1.0 395000.0  next_tick range: -1.0 394800.0
normed next range: -1000000.0 3203.175537109375
pred range: -407.3399658203125 41.56236267089844
mask valid positions: 58129.0 / 65536

[batch 20] loss=5.594445e+02 loss_diff=9.639245e-01 recon=5.584806e+02
obs_tick range: -0.9993932247161865 367100.0  next_tick range: -1.0 367100.0
normed next range: -7.1889190673828125 6506.056640625
pred range: -403.6053771972656 11.130661010742188
mask valid positions: 30063.0 / 65536

[batch 30] loss=9.130604e+08 loss_diff=9.586477e-01 recon=9.130604e+08
obs_tick range: -0.9762958884239197 370200.0  next_tick range: -0.965925395488739 376800.0
normed next range: -1000000.0 4319.9716796875
pred range: -408.7260437011719 75.72579956054688
mask valid positions: 39894.0 / 65536

>>> Gradient explosion detected, grad_norm= 1182092.8889594686
[batch 40] loss=3.158467e+09 loss_diff=9.130936e-01 recon=3.158467e+09
obs_tick range: -0.9961944222450256 369900.0  next_tick range: -0.9914445281028748 368500.0
normed next range: -1000000.0 1729.1348876953125
pred range: -409.60223388671875 62.567588806152344
mask valid positions: 51887.0 / 65536

>>> Gradient explosion detected, grad_norm= 2538047.7375118285
>>> Gradient explosion detected, grad_norm= 2749889.9012060463
[batch 50] loss=1.398938e+10 loss_diff=9.645067e-01 recon=1.398938e+10
obs_tick range: -0.9762959480285645 369000.0  next_tick range: -0.9848030805587769 368900.0
normed next range: -1000000.0 1000000.0
pred range: -410.386962890625 48.22447204589844
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 13352718.214301454
>>> Gradient explosion detected, grad_norm= 2753360.990992673
[batch 60] loss=7.591360e+08 loss_diff=9.079374e-01 recon=7.591360e+08
obs_tick range: -0.991443932056427 375000.0  next_tick range: -0.9961946606636047 375000.0
normed next range: -1000000.0 9566.9619140625
pred range: -411.1750793457031 54.02354049682617
mask valid positions: 50616.0 / 65536

>>> Gradient explosion detected, grad_norm= 3194922.780601693
>>> Gradient explosion detected, grad_norm= 2568303.2452057605
[batch 70] loss=6.412483e+08 loss_diff=9.500797e-01 recon=6.412483e+08
obs_tick range: -1.0 395700.0  next_tick range: -0.999048113822937 393000.0
normed next range: -1000000.0 4473.0283203125
pred range: -412.13555908203125 64.98238372802734
mask valid positions: 42072.0 / 65536

[batch 80] loss=9.348804e+01 loss_diff=9.277695e-01 recon=9.256027e+01
obs_tick range: -0.9762959480285645 392900.0  next_tick range: -0.9659227728843689 392300.0
normed next range: -2.4748737812042236 3947.09326171875
pred range: -10.42425537109375 14.269200325012207
mask valid positions: 50273.0 / 65536

>>> Gradient explosion detected, grad_norm= 14287716.562969347
>>> Gradient explosion detected, grad_norm= 13859731.367480585
>>> Gradient explosion detected, grad_norm= 9544614.30532408
>>> Gradient explosion detected, grad_norm= 4341180.8112310115
[batch 90] loss=1.307291e+09 loss_diff=9.072288e-01 recon=1.307291e+09
obs_tick range: -0.9914456605911255 368500.0  next_tick range: -0.9972506761550903 370200.0
normed next range: -1000000.0 2708.203125
pred range: -413.42138671875 14.90798568725586
mask valid positions: 43154.0 / 65536

>>> Gradient explosion detected, grad_norm= 3278099.300198734
>>> Gradient explosion detected, grad_norm= 6990648.905501109
[batch 100] loss=2.219830e+02 loss_diff=8.619767e-01 recon=2.211210e+02
obs_tick range: -0.999048113822937 375100.0  next_tick range: -0.99619460105896 375600.0
normed next range: -5.303300857543945 9836.4384765625
pred range: -8.112726211547852 13.781709671020508
mask valid positions: 56549.0 / 65536

>>> Gradient explosion detected, grad_norm= 6424109.001533929
>>> Gradient explosion detected, grad_norm= 3777000.317627823
>>> Gradient explosion detected, grad_norm= 8163798.138692966
[batch 110] loss=8.980484e+08 loss_diff=9.332492e-01 recon=8.980484e+08
obs_tick range: -0.9961902499198914 364000.0  next_tick range: -0.9990479350090027 363200.0
normed next range: -1000000.0 2159.9931640625
pred range: -413.1492919921875 16.130449295043945
mask valid positions: 43597.0 / 65536

>>> Gradient explosion detected, grad_norm= 7109994.42292471
[batch 120] loss=5.076578e+08 loss_diff=9.505726e-01 recon=5.076578e+08
obs_tick range: -0.992551326751709 500000.0  next_tick range: -0.996920645236969 394500.0
normed next range: -1000000.0 9878.560546875
pred range: -413.7027893066406 65.44583129882812
mask valid positions: 27377.0 / 65536

[batch 130] loss=1.421782e+09 loss_diff=1.018112e+00 recon=1.421782e+09
obs_tick range: -1.0 367400.0  next_tick range: -0.9990479350090027 367200.0
normed next range: -1000000.0 3383.04248046875
pred range: -414.90081787109375 72.39661407470703
mask valid positions: 50864.0 / 65536

>>> Gradient explosion detected, grad_norm= 6180295.197839456
>>> Gradient explosion detected, grad_norm= 5094923.3479919
>>> Gradient explosion detected, grad_norm= 3485301.2004034375
>>> Gradient explosion detected, grad_norm= 8987304.486394426
[batch 140] loss=5.651827e+08 loss_diff=9.757866e-01 recon=5.651827e+08
obs_tick range: -0.9961945414543152 214900.0  next_tick range: -0.9914457201957703 394000.0
normed next range: -1000000.0 13890.232421875
pred range: -413.86083984375 21.480125427246094
mask valid positions: 36163.0 / 65536

>>> Gradient explosion detected, grad_norm= 1220453.9462513565
>>> Gradient explosion detected, grad_norm= 1066468.3738367318
>>> Gradient explosion detected, grad_norm= 2260758.8814436137
>>> Gradient explosion detected, grad_norm= 11165528.456175018
[batch 150] loss=1.814218e+09 loss_diff=9.475509e-01 recon=1.814218e+09
obs_tick range: -0.9972280859947205 327000.0  next_tick range: -0.9993917942047119 327000.0
normed next range: -1000000.0 2935.94873046875
pred range: -414.8459777832031 90.20515441894531
mask valid positions: 51822.0 / 65536

>>> Gradient explosion detected, grad_norm= 1141740.1483486253
==============================
[2015-01][Epoch 11/20] | Time = 23.68 min
 - Total Loss : 1413776268.062847 | Recon Loss: 1413776267.991915 | Diff Loss: 0.940543
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-01 completed in 265.15 min
[1] 2015-02 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-02 | file : news_20150228.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.831377e+09 loss_diff=9.383410e-01 recon=1.831377e+09
obs_tick range: -0.999048113822937 331200.0  next_tick range: -0.9993920922279358 329900.0
normed next range: -1000000.0 4747.25439453125
pred range: -414.202392578125 84.5382308959961
mask valid positions: 51288.0 / 65536

>>> Gradient explosion detected, grad_norm= 3600101.844365965
>>> Gradient explosion detected, grad_norm= 1577938.9158888753
>>> Gradient explosion detected, grad_norm= 10301173.70043503
[batch 10] loss=1.836887e+09 loss_diff=9.029403e-01 recon=1.836887e+09
obs_tick range: -0.999048113822937 392500.0  next_tick range: -1.0 392600.0
normed next range: -1000000.0 2757.696044921875
pred range: -414.95050048828125 83.49490356445312
mask valid positions: 36646.0 / 65536

>>> Gradient explosion detected, grad_norm= 7730939.6260633
>>> Gradient explosion detected, grad_norm= 15047331.06060297
>>> Gradient explosion detected, grad_norm= 1013983.0544908833
>>> Gradient explosion detected, grad_norm= 6611531.406340441
>>> Gradient explosion detected, grad_norm= 43908140.47265683
[batch 20] loss=1.510396e+09 loss_diff=9.517064e-01 recon=1.510396e+09
obs_tick range: -0.9961923360824585 750000.0  next_tick range: -0.999048113822937 386200.0
normed next range: -1000000.0 1000000.0
pred range: -415.5313720703125 52.61787414550781
mask valid positions: 50098.0 / 65536

>>> Gradient explosion detected, grad_norm= 2128911.2267189836
[batch 30] loss=4.759344e+08 loss_diff=9.713473e-01 recon=4.759344e+08
obs_tick range: -0.992551326751709 352000.0  next_tick range: -0.996920645236969 365000.0
normed next range: -1000000.0 7018.59228515625
pred range: -416.2030029296875 59.58411407470703
mask valid positions: 35882.0 / 65536

>>> Gradient explosion detected, grad_norm= 1465016.6490999484
[batch 40] loss=1.133843e+09 loss_diff=9.865403e-01 recon=1.133843e+09
obs_tick range: -1.0 392200.0  next_tick range: -1.0 392000.0
normed next range: -1000000.0 4366.81298828125
pred range: -417.2500915527344 59.62800216674805
mask valid positions: 57842.0 / 65536

>>> Gradient explosion detected, grad_norm= 2654007.4461817266
>>> Gradient explosion detected, grad_norm= 1103504.5506759617
[batch 50] loss=1.348111e+09 loss_diff=9.613861e-01 recon=1.348111e+09
obs_tick range: -0.9990481734275818 365600.0  next_tick range: -0.9961941242218018 368700.0
normed next range: -1000000.0 19320.58984375
pred range: -417.8522644042969 74.90424346923828
mask valid positions: 44067.0 / 65536

>>> Gradient explosion detected, grad_norm= 1197022.341791391
>>> Gradient explosion detected, grad_norm= 3359369.1990611497
>>> Gradient explosion detected, grad_norm= 1299364.327197148
[batch 60] loss=9.756093e+02 loss_diff=9.196600e-01 recon=9.746896e+02
obs_tick range: -1.0 364100.0  next_tick range: -0.9990479350090027 364600.0
normed next range: -6.7175140380859375 11768.1826171875
pred range: -2.9851694107055664 23.665103912353516
mask valid positions: 44564.0 / 65536

[batch 70] loss=2.202241e+09 loss_diff=9.470330e-01 recon=2.202241e+09
obs_tick range: -0.9914448261260986 328100.0  next_tick range: -0.984808087348938 394000.0
normed next range: -1000000.0 6088.7255859375
pred range: -419.298095703125 61.13139724731445
mask valid positions: 51067.0 / 65536

>>> Gradient explosion detected, grad_norm= 2297706.7386787473
>>> Gradient explosion detected, grad_norm= 15463653.420909919
>>> Gradient explosion detected, grad_norm= 3478934.659156495
[batch 80] loss=4.245454e+08 loss_diff=9.866782e-01 recon=4.245454e+08
obs_tick range: -0.9848073124885559 381500.0  next_tick range: -0.991443395614624 380800.0
normed next range: -1000000.0 3768.90087890625
pred range: -420.08795166015625 48.92912673950195
mask valid positions: 56486.0 / 65536

>>> Gradient explosion detected, grad_norm= 2259070.3752112407
[batch 90] loss=1.810178e+09 loss_diff=9.532180e-01 recon=1.810178e+09
obs_tick range: -0.9990479350090027 369000.0  next_tick range: -1.0 370000.0
normed next range: -1000000.0 1881.6480712890625
pred range: -420.5701599121094 82.7124252319336
mask valid positions: 58260.0 / 65536

[batch 100] loss=1.885674e+09 loss_diff=9.023974e-01 recon=1.885674e+09
obs_tick range: -0.996920645236969 372600.0  next_tick range: -0.99921715259552 372600.0
normed next range: -1000000.0 5793.3369140625
pred range: -421.6321105957031 87.08429718017578
mask valid positions: 36755.0 / 65536

>>> Gradient explosion detected, grad_norm= 2003283.9299633887
>>> Gradient explosion detected, grad_norm= 1086571.1153318326
>>> Gradient explosion detected, grad_norm= 1372190.8613065053
[batch 110] loss=1.560269e+09 loss_diff=9.144737e-01 recon=1.560269e+09
obs_tick range: -0.9961910843849182 392900.0  next_tick range: -0.9914447069168091 393000.0
normed next range: -1000000.0 2510.25830078125
pred range: -422.15130615234375 71.9937973022461
mask valid positions: 51697.0 / 65536

[batch 120] loss=9.095046e+08 loss_diff=9.924645e-01 recon=9.095046e+08
obs_tick range: -1.0 384100.0  next_tick range: -1.0 382400.0
normed next range: -1000000.0 5705.603515625
pred range: -423.14019775390625 72.27827453613281
mask valid positions: 58126.0 / 65536

[batch 130] loss=1.060024e+09 loss_diff=9.467322e-01 recon=1.060024e+09
obs_tick range: -0.9961902499198914 371500.0  next_tick range: -0.9990479946136475 371500.0
normed next range: -1000000.0 18163.29296875
pred range: -424.16790771484375 66.18952178955078
mask valid positions: 36162.0 / 65536

>>> Gradient explosion detected, grad_norm= 1694448.3359664301
[batch 140] loss=1.428418e+09 loss_diff=9.692662e-01 recon=1.428418e+09
obs_tick range: -1.0 375100.0  next_tick range: -0.9426490664482117 373300.0
normed next range: -1000000.0 5718.740234375
pred range: -425.0872497558594 60.35969924926758
mask valid positions: 42924.0 / 65536

>>> Gradient explosion detected, grad_norm= 1404175.4137155875
[batch 150] loss=5.258414e+08 loss_diff=9.394025e-01 recon=5.258414e+08
obs_tick range: -0.99619460105896 371500.0  next_tick range: -0.9914447665214539 370200.0
normed next range: -1000000.0 9683.37109375
pred range: -425.7282409667969 57.818016052246094
mask valid positions: 35412.0 / 65536

>>> Gradient explosion detected, grad_norm= 1302280.5377575848
==============================
[2015-02][Epoch 1/20] | Time = 5.36 min
 - Total Loss : 1392662003.366494 | Recon Loss: 1392662003.305501 | Diff Loss: 0.940200
==============================
No improvement count: 1
[batch 0] loss=5.088588e+09 loss_diff=9.064325e-01 recon=5.088588e+09
obs_tick range: -1.0 366700.0  next_tick range: -0.9961941242218018 243400.0
normed next range: -1000000.0 4722.95654296875
pred range: -426.14837646484375 61.27124786376953
mask valid positions: 57735.0 / 65536

>>> Gradient explosion detected, grad_norm= 6328321.546504785
[batch 10] loss=2.571251e+09 loss_diff=9.707846e-01 recon=2.571251e+09
obs_tick range: -1.0 394500.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 3584.99169921875
pred range: -426.746337890625 72.28213500976562
mask valid positions: 51971.0 / 65536

>>> Gradient explosion detected, grad_norm= 2790225.583106688
[batch 20] loss=1.126296e+09 loss_diff=9.676525e-01 recon=1.126296e+09
obs_tick range: -0.9870009422302246 368800.0  next_tick range: -0.9914469122886658 367900.0
normed next range: -1000000.0 7165.6962890625
pred range: -427.35467529296875 76.26302337646484
mask valid positions: 20888.0 / 65536

>>> Gradient explosion detected, grad_norm= 2224843.7571292846
[batch 30] loss=9.826734e+08 loss_diff=9.250640e-01 recon=9.826734e+08
obs_tick range: -0.9914413094520569 225200.0  next_tick range: -0.9961941242218018 368500.0
normed next range: -1000000.0 4369.38330078125
pred range: -428.1609191894531 76.96016693115234
mask valid positions: 43260.0 / 65536

[batch 40] loss=2.378127e+09 loss_diff=9.067039e-01 recon=2.378127e+09
obs_tick range: -0.9971959590911865 691449.0  next_tick range: -0.9994773268699646 367900.0
normed next range: -1000000.0 14765.12109375
pred range: -429.00433349609375 64.50028228759766
mask valid positions: 29525.0 / 65536

>>> Gradient explosion detected, grad_norm= 11728323.854236737
[batch 50] loss=1.453291e+10 loss_diff=9.338176e-01 recon=1.453291e+10
obs_tick range: -0.9848074316978455 393700.0  next_tick range: -0.991443395614624 392700.0
normed next range: -1000000.0 1000000.0
pred range: -429.8753356933594 46.12228012084961
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 13798988.97460949
[batch 60] loss=2.989624e+09 loss_diff=9.543396e-01 recon=2.989624e+09
obs_tick range: -0.9969200491905212 357600.0  next_tick range: -0.9992408752441406 366800.0
normed next range: -1000000.0 4569.689453125
pred range: -430.745849609375 53.7882194519043
mask valid positions: 51259.0 / 65536

>>> Gradient explosion detected, grad_norm= 1729738.4215553275
>>> Gradient explosion detected, grad_norm= 14219368.007033376
[batch 70] loss=6.174976e+08 loss_diff=9.505212e-01 recon=6.174976e+08
obs_tick range: -1.0 330300.0  next_tick range: -1.0 586459.0
normed next range: -1000000.0 6945.68115234375
pred range: -431.4358215332031 56.45608901977539
mask valid positions: 36922.0 / 65536

>>> Gradient explosion detected, grad_norm= 1745426.1071465386
>>> Gradient explosion detected, grad_norm= 3530001.9757593367
[batch 80] loss=1.021625e+03 loss_diff=9.520178e-01 recon=1.020673e+03
obs_tick range: -0.996194064617157 384100.0  next_tick range: -0.999048113822937 382400.0
normed next range: -7.745054244995117 13509.888671875
pred range: -32.19205093383789 17.201492309570312
mask valid positions: 36329.0 / 65536

>>> Gradient explosion detected, grad_norm= 2674558.5292244763
[batch 90] loss=2.146005e+09 loss_diff=9.360457e-01 recon=2.146005e+09
obs_tick range: -0.999048113822937 393300.0  next_tick range: -0.9961944818496704 394000.0
normed next range: -1000000.0 3374.685302734375
pred range: -432.6828918457031 86.9540786743164
mask valid positions: 51050.0 / 65536

>>> Gradient explosion detected, grad_norm= 1305513.7324242187
>>> Gradient explosion detected, grad_norm= 1575851.820767705
>>> Gradient explosion detected, grad_norm= 2805101.906667024
[batch 100] loss=1.729529e+09 loss_diff=8.674551e-01 recon=1.729529e+09
obs_tick range: -0.9993916153907776 376600.0  next_tick range: -1.0 371000.0
normed next range: -1000000.0 4055.613525390625
pred range: -433.44512939453125 51.111083984375
mask valid positions: 51941.0 / 65536

>>> Gradient explosion detected, grad_norm= 2909491.8763292143
[batch 110] loss=2.839174e+09 loss_diff=8.605067e-01 recon=2.839174e+09
obs_tick range: -1.0 369000.0  next_tick range: -1.0 371400.0
normed next range: -1000000.0 1910.9886474609375
pred range: -434.2922668457031 58.672630310058594
mask valid positions: 56427.0 / 65536

>>> Gradient explosion detected, grad_norm= 1805785.0990059385
[batch 120] loss=2.065008e+09 loss_diff=9.600642e-01 recon=2.065008e+09
obs_tick range: -1.0 368500.0  next_tick range: -0.9961931705474854 357400.0
normed next range: -1000000.0 9235.8974609375
pred range: -435.15399169921875 52.77522277832031
mask valid positions: 50541.0 / 65536

>>> Gradient explosion detected, grad_norm= 15572211.757295102
[batch 130] loss=8.742216e+08 loss_diff=9.285929e-01 recon=8.742216e+08
obs_tick range: -1.0 368500.0  next_tick range: -1.0 357400.0
normed next range: -1000000.0 15662.974609375
pred range: -436.07110595703125 38.79450607299805
mask valid positions: 42704.0 / 65536

>>> Gradient explosion detected, grad_norm= 2292215.4331972436
>>> Gradient explosion detected, grad_norm= 1121323.6789545987
[batch 140] loss=1.791688e+09 loss_diff=9.028898e-01 recon=1.791688e+09
obs_tick range: -0.9859625101089478 370200.0  next_tick range: -0.9925494194030762 369000.0
normed next range: -1000000.0 4834.4794921875
pred range: -436.646484375 52.777217864990234
mask valid positions: 43701.0 / 65536

>>> Gradient explosion detected, grad_norm= 1074669.2532068857
>>> Gradient explosion detected, grad_norm= 196263281.38067803
>>> Gradient explosion detected, grad_norm= 1210645.3719345466
[batch 150] loss=8.374086e+08 loss_diff=9.307358e-01 recon=8.374086e+08
obs_tick range: -1.0 330000.0  next_tick range: -0.9990479350090027 369000.0
normed next range: -1000000.0 12491.1025390625
pred range: -437.0624084472656 79.875732421875
mask valid positions: 35144.0 / 65536

>>> Gradient explosion detected, grad_norm= 8973223.299189094
>>> Gradient explosion detected, grad_norm= 2491728.9395510065
>>> Gradient explosion detected, grad_norm= 62188858.92108491
==============================
[2015-02][Epoch 2/20] | Time = 5.63 min
 - Total Loss : 1713328241.755749 | Recon Loss: 1713328241.688738 | Diff Loss: 0.933817
==============================
No improvement count: 2
[batch 0] loss=1.604064e+09 loss_diff=9.424341e-01 recon=1.604064e+09
obs_tick range: -0.99619460105896 375600.0  next_tick range: -0.99619460105896 375100.0
normed next range: -1000000.0 10813.8994140625
pred range: -437.2709655761719 62.468658447265625
mask valid positions: 43269.0 / 65536

>>> Gradient explosion detected, grad_norm= 28292891.679121837
>>> Gradient explosion detected, grad_norm= 8454962.840332635
>>> Gradient explosion detected, grad_norm= 27420267.804575313
[batch 10] loss=2.095388e+09 loss_diff=9.309886e-01 recon=2.095388e+09
obs_tick range: -1.0 373300.0  next_tick range: -0.999048113822937 365800.0
normed next range: -1000000.0 4723.0546875
pred range: -437.22711181640625 59.010276794433594
mask valid positions: 58218.0 / 65536

>>> Gradient explosion detected, grad_norm= 2520408.1436979445
[batch 20] loss=5.874895e+08 loss_diff=9.128071e-01 recon=5.874895e+08
obs_tick range: -0.9238795042037964 352900.0  next_tick range: -0.9062895178794861 354700.0
normed next range: -1000000.0 21212.482421875
pred range: -437.94781494140625 76.16973114013672
mask valid positions: 34633.0 / 65536

>>> Gradient explosion detected, grad_norm= 3810059.110828227
>>> Gradient explosion detected, grad_norm= 10347890.230705239
>>> Gradient explosion detected, grad_norm= 7939714.365515009
>>> Gradient explosion detected, grad_norm= 12808923.4381968
>>> Gradient explosion detected, grad_norm= 1265480.4687861868
[batch 30] loss=9.185414e+08 loss_diff=9.574858e-01 recon=9.185414e+08
obs_tick range: -1.0 391500.0  next_tick range: -0.999048113822937 392100.0
normed next range: -1000000.0 5399.23193359375
pred range: -436.94775390625 17.71731185913086
mask valid positions: 35898.0 / 65536

>>> Gradient explosion detected, grad_norm= 1069950.4584274895
>>> Gradient explosion detected, grad_norm= 113568799.68870397
>>> Gradient explosion detected, grad_norm= 3086142.1970350025
>>> Gradient explosion detected, grad_norm= 3801704.0291417534
[batch 40] loss=1.691812e+09 loss_diff=8.788894e-01 recon=1.691812e+09
obs_tick range: -0.976296067237854 369000.0  next_tick range: -0.9848082065582275 389000.0
normed next range: -1000000.0 9284.0224609375
pred range: -437.2530212402344 51.04175567626953
mask valid positions: 51225.0 / 65536

>>> Gradient explosion detected, grad_norm= 4870476.068147819
>>> Gradient explosion detected, grad_norm= 1602451.8939532281
[batch 50] loss=5.742723e+08 loss_diff=1.007684e+00 recon=5.742723e+08
obs_tick range: -1.0 365500.0  next_tick range: -0.9994773268699646 348400.0
normed next range: -1000000.0 32113.52734375
pred range: -438.3651428222656 81.51942443847656
mask valid positions: 28471.0 / 65536

>>> Gradient explosion detected, grad_norm= 4128112.9567648284
>>> Gradient explosion detected, grad_norm= 3401614.7019317546
>>> Gradient explosion detected, grad_norm= 3806497.2507069376
[batch 60] loss=1.632748e+09 loss_diff=9.327737e-01 recon=1.632748e+09
obs_tick range: -0.9969194531440735 368900.0  next_tick range: -0.9993917346000671 357600.0
normed next range: -1000000.0 1000000.0
pred range: -438.95751953125 85.26243591308594
mask valid positions: 15132.0 / 65536

>>> Gradient explosion detected, grad_norm= 1230620.0363498435
[batch 70] loss=3.295141e+02 loss_diff=9.324917e-01 recon=3.285816e+02
obs_tick range: -0.9993917942047119 368000.0  next_tick range: -1.0 367400.0
normed next range: -19.445436477661133 8066.91455078125
pred range: -11.908037185668945 9.16659927368164
mask valid positions: 45141.0 / 65536

>>> Gradient explosion detected, grad_norm= 1621099.6965554378
[batch 80] loss=1.640140e+09 loss_diff=8.919995e-01 recon=1.640140e+09
obs_tick range: -0.9396919012069702 375200.0  next_tick range: -0.923870861530304 374600.0
normed next range: -1000000.0 2004.83544921875
pred range: -440.01910400390625 61.93999099731445
mask valid positions: 50732.0 / 65536

>>> Gradient explosion detected, grad_norm= 3499374.6986661195
>>> Gradient explosion detected, grad_norm= 2246842.7298160554
[batch 90] loss=7.372554e+06 loss_diff=9.240929e-01 recon=7.372552e+06
obs_tick range: -0.991443932056427 365100.0  next_tick range: -0.9848071336746216 365700.0
normed next range: -1000000.0 1219.3946533203125
pred range: -440.6963806152344 35.96229553222656
mask valid positions: 49293.0 / 65536

>>> Gradient explosion detected, grad_norm= 3534441.0440084455
>>> Gradient explosion detected, grad_norm= 2507585.1976355035
>>> Gradient explosion detected, grad_norm= 8125618.856197765
>>> Gradient explosion detected, grad_norm= 1202364.9240928923
[batch 100] loss=7.981255e+08 loss_diff=9.568268e-01 recon=7.981255e+08
obs_tick range: -1.0 365000.0  next_tick range: -0.9995337724685669 375000.0
normed next range: -1000000.0 9660.1845703125
pred range: -440.89447021484375 64.35016632080078
mask valid positions: 33118.0 / 65536

>>> Gradient explosion detected, grad_norm= 1223480.3368292532
[batch 110] loss=2.650925e+08 loss_diff=9.673893e-01 recon=2.650925e+08
obs_tick range: -1.0 325000.0  next_tick range: -1.0 327000.0
normed next range: -1000000.0 6291.90185546875
pred range: -441.0813293457031 63.357723236083984
mask valid positions: 34608.0 / 65536

>>> Gradient explosion detected, grad_norm= 6927290.4452336235
>>> Gradient explosion detected, grad_norm= 4311321.942211462
[batch 120] loss=2.673635e+02 loss_diff=9.291308e-01 recon=2.664344e+02
obs_tick range: -0.9961944818496704 367400.0  next_tick range: -0.9969472289085388 565000.0
normed next range: -7.1889190673828125 6644.73291015625
pred range: -439.52093505859375 18.49639129638672
mask valid positions: 50504.0 / 65536

>>> Gradient explosion detected, grad_norm= 3713700.4601884247
[batch 130] loss=8.141700e+08 loss_diff=9.131075e-01 recon=8.141700e+08
obs_tick range: -0.9993930459022522 500000.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 3025.347900390625
pred range: -442.9092102050781 78.99779510498047
mask valid positions: 44849.0 / 65536

>>> Gradient explosion detected, grad_norm= 14312006.235205654
[batch 140] loss=1.259782e+09 loss_diff=8.914413e-01 recon=1.259782e+09
obs_tick range: -1.0 357700.0  next_tick range: -1.0 387100.0
normed next range: -1000000.0 1000000.0
pred range: -444.0023498535156 64.40260314941406
mask valid positions: 57825.0 / 65536

>>> Gradient explosion detected, grad_norm= 3072632.9476407887
>>> Gradient explosion detected, grad_norm= 1929800.0019209152
[batch 150] loss=6.638120e+08 loss_diff=8.868989e-01 recon=6.638120e+08
obs_tick range: -1.0 396000.0  next_tick range: -1.0 395700.0
normed next range: -1000000.0 4311.1259765625
pred range: -444.909912109375 42.64554977416992
mask valid positions: 44334.0 / 65536

>>> Gradient explosion detected, grad_norm= 2971571.3150859624
==============================
[2015-02][Epoch 3/20] | Time = 5.63 min
 - Total Loss : 1432700115.869624 | Recon Loss: 1432700115.797981 | Diff Loss: 0.923355
==============================
No improvement count: 3
[batch 0] loss=9.564248e+06 loss_diff=9.662436e-01 recon=9.564247e+06
obs_tick range: -0.9961932897567749 375000.0  next_tick range: -0.9990479946136475 364200.0
normed next range: -4.360491752624512 1000000.0
pred range: -292.8510437011719 13.012674331665039
mask valid positions: 28526.0 / 65536

>>> Gradient explosion detected, grad_norm= 7055386.207466708
>>> Gradient explosion detected, grad_norm= 4824095.104347345
[batch 10] loss=1.621497e+09 loss_diff=9.131925e-01 recon=1.621497e+09
obs_tick range: -0.9537127614021301 387100.0  next_tick range: -0.9396918416023254 386200.0
normed next range: -1000000.0 4694.8359375
pred range: -446.0188903808594 77.56431579589844
mask valid positions: 37195.0 / 65536

>>> Gradient explosion detected, grad_norm= 3818085.629055869
>>> Gradient explosion detected, grad_norm= 3348327.4036212205
[batch 20] loss=1.994891e+09 loss_diff=9.056150e-01 recon=1.994891e+09
obs_tick range: -0.9990478157997131 394500.0  next_tick range: -0.9961944222450256 393300.0
normed next range: -1000000.0 1690.816162109375
pred range: -446.76763916015625 76.84370422363281
mask valid positions: 58101.0 / 65536

>>> Gradient explosion detected, grad_norm= 2834122.808860414
>>> Gradient explosion detected, grad_norm= 3331700.5399454143
[batch 30] loss=2.274770e+09 loss_diff=9.461421e-01 recon=2.274770e+09
obs_tick range: -0.9993932247161865 379500.0  next_tick range: -1.0 379500.0
normed next range: -1000000.0 1000000.0
pred range: -447.580322265625 69.37326049804688
mask valid positions: 45765.0 / 65536

>>> Gradient explosion detected, grad_norm= 3126992.5379271763
>>> Gradient explosion detected, grad_norm= 1790331.3810427182
[batch 40] loss=1.870638e+09 loss_diff=9.398632e-01 recon=1.870638e+09
obs_tick range: -0.9767646789550781 378000.0  next_tick range: -0.9865356683731079 378000.0
normed next range: -1000000.0 2393.73583984375
pred range: -447.9949035644531 75.74471282958984
mask valid positions: 44626.0 / 65536

>>> Gradient explosion detected, grad_norm= 4371653.071501711
>>> Gradient explosion detected, grad_norm= 7484464.811215381
[batch 50] loss=3.344487e+08 loss_diff=9.221980e-01 recon=3.344487e+08
obs_tick range: -1.0 392000.0  next_tick range: -1.0 393600.0
normed next range: -1000000.0 3313.370361328125
pred range: -448.1658020019531 79.42881774902344
mask valid positions: 57577.0 / 65536

>>> Gradient explosion detected, grad_norm= 2448510.91461265
>>> Gradient explosion detected, grad_norm= 3582501.015202567
[batch 60] loss=1.006798e+09 loss_diff=8.644816e-01 recon=1.006798e+09
obs_tick range: -0.9990479946136475 393900.0  next_tick range: -0.9961945414543152 393700.0
normed next range: -1000000.0 8142.59423828125
pred range: -448.9451599121094 66.70033264160156
mask valid positions: 49078.0 / 65536

>>> Gradient explosion detected, grad_norm= 2386077.486649627
[batch 70] loss=5.165497e+02 loss_diff=9.743981e-01 recon=5.155753e+02
obs_tick range: -0.9990479946136475 371500.0  next_tick range: -1.0 371600.0
normed next range: -2.4748737812042236 8437.9990234375
pred range: -7.101780891418457 14.645162582397461
mask valid positions: 35968.0 / 65536

>>> Gradient explosion detected, grad_norm= 6243851.802875825
>>> Gradient explosion detected, grad_norm= 4022186.432410755
[batch 80] loss=7.031119e+08 loss_diff=9.429101e-01 recon=7.031119e+08
obs_tick range: -1.0 369000.0  next_tick range: -0.999048113822937 371400.0
normed next range: -1000000.0 11661.224609375
pred range: -450.3111572265625 72.47393798828125
mask valid positions: 47927.0 / 65536

>>> Gradient explosion detected, grad_norm= 1242509.906123708
>>> Gradient explosion detected, grad_norm= 3015942.714298778
[batch 90] loss=1.831903e+09 loss_diff=8.641371e-01 recon=1.831903e+09
obs_tick range: -0.9762949347496033 362500.0  next_tick range: -0.9659286737442017 362000.0
normed next range: -1000000.0 3848.826416015625
pred range: -451.0555114746094 80.16658782958984
mask valid positions: 58318.0 / 65536

>>> Gradient explosion detected, grad_norm= 3229961.0283998516
[batch 100] loss=2.212410e+09 loss_diff=9.401644e-01 recon=2.212410e+09
obs_tick range: -1.0 378000.0  next_tick range: -0.996194064617157 378400.0
normed next range: -1000000.0 3900.165771484375
pred range: -451.6177978515625 67.59327697753906
mask valid positions: 35964.0 / 65536

>>> Gradient explosion detected, grad_norm= 4420419.855855813
>>> Gradient explosion detected, grad_norm= 4903900.918391627
[batch 110] loss=1.648948e+09 loss_diff=8.982660e-01 recon=1.648948e+09
obs_tick range: -0.9537163972854614 393600.0  next_tick range: -0.9659244418144226 395000.0
normed next range: -1000000.0 20633.892578125
pred range: -452.61798095703125 79.83097076416016
mask valid positions: 28478.0 / 65536

>>> Gradient explosion detected, grad_norm= 5895865.357076263
[batch 120] loss=4.914397e+08 loss_diff=9.366336e-01 recon=4.914397e+08
obs_tick range: -1.0 331800.0  next_tick range: -0.9563098549842834 368900.0
normed next range: -1000000.0 14490.6396484375
pred range: -453.1557922363281 63.60420227050781
mask valid positions: 35487.0 / 65536

>>> Gradient explosion detected, grad_norm= 9479012.859245563
>>> Gradient explosion detected, grad_norm= 4486524.690707988
[batch 130] loss=8.779951e+08 loss_diff=9.536462e-01 recon=8.779951e+08
obs_tick range: -1.0 1692079.0  next_tick range: -0.9990481734275818 366200.0
normed next range: -1000000.0 2298.64404296875
pred range: -453.89361572265625 77.58995819091797
mask valid positions: 50795.0 / 65536

>>> Gradient explosion detected, grad_norm= 6009116.839752813
>>> Gradient explosion detected, grad_norm= 42168094.12065613
>>> Gradient explosion detected, grad_norm= 2091502.2656780137
>>> Gradient explosion detected, grad_norm= 2356302.6676129512
[batch 140] loss=1.736349e+09 loss_diff=8.938596e-01 recon=1.736349e+09
obs_tick range: -0.9848071932792664 378000.0  next_tick range: -0.9914422631263733 389000.0
normed next range: -1000000.0 3720.135986328125
pred range: -454.491455078125 113.18704223632812
mask valid positions: 51055.0 / 65536

>>> Gradient explosion detected, grad_norm= 1508727.1816861655
>>> Gradient explosion detected, grad_norm= 8510528.172219925
>>> Gradient explosion detected, grad_norm= 9078046.541445892
[batch 150] loss=5.215788e+08 loss_diff=9.230753e-01 recon=5.215788e+08
obs_tick range: -1.0 392100.0  next_tick range: -1.0 393300.0
normed next range: -1000000.0 4020.7373046875
pred range: -454.8839111328125 67.50776672363281
mask valid positions: 57468.0 / 65536

==============================
[2015-02][Epoch 4/20] | Time = 5.63 min
 - Total Loss : 1272170116.069132 | Recon Loss: 1272170115.996267 | Diff Loss: 0.924001
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-02 completed in 22.26 min
[1] 2015-03 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-03 | file : news_20150331.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.538158e+09 loss_diff=9.447492e-01 recon=1.538158e+09
obs_tick range: -1.0 367900.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 7069.9970703125
pred range: -455.3241882324219 43.34991455078125
mask valid positions: 44415.0 / 65536

>>> Gradient explosion detected, grad_norm= 2231113.0975801875
>>> Gradient explosion detected, grad_norm= 3687942.606653871
>>> Gradient explosion detected, grad_norm= 2758741.896812017
>>> Gradient explosion detected, grad_norm= 1930734.4395974188
>>> Gradient explosion detected, grad_norm= 1479568.8541220785
>>> Gradient explosion detected, grad_norm= 7569936.619989305
[batch 10] loss=1.765071e+09 loss_diff=9.179671e-01 recon=1.765071e+09
obs_tick range: -0.9990479946136475 354100.0  next_tick range: -0.9961945414543152 354000.0
normed next range: -1000000.0 4241.57421875
pred range: -455.23114013671875 38.07313919067383
mask valid positions: 43226.0 / 65536

>>> Gradient explosion detected, grad_norm= 7417533.665565437
>>> Gradient explosion detected, grad_norm= 10112885.198519768
>>> Gradient explosion detected, grad_norm= 6515105.527926464
[batch 20] loss=6.936621e+08 loss_diff=9.498683e-01 recon=6.936621e+08
obs_tick range: -0.9914343357086182 364000.0  next_tick range: -0.996194064617157 363200.0
normed next range: -1000000.0 7098.69970703125
pred range: -456.18115234375 45.42717361450195
mask valid positions: 35616.0 / 65536

>>> Gradient explosion detected, grad_norm= 3062315.0049878852
>>> Gradient explosion detected, grad_norm= 56251332.13293677
>>> Gradient explosion detected, grad_norm= 7740645.435554708
[batch 30] loss=1.142654e+09 loss_diff=9.238917e-01 recon=1.142654e+09
obs_tick range: -0.9990481734275818 354200.0  next_tick range: -0.9961944818496704 353600.0
normed next range: -1000000.0 10073.46875
pred range: -456.31951904296875 68.00533294677734
mask valid positions: 43163.0 / 65536

>>> Gradient explosion detected, grad_norm= 13150329.53298709
>>> Gradient explosion detected, grad_norm= 2055030.3972157566
[batch 40] loss=1.977615e+09 loss_diff=9.098940e-01 recon=1.977615e+09
obs_tick range: -0.9847961068153381 367100.0  next_tick range: -0.991443395614624 376800.0
normed next range: -1000000.0 2372.896240234375
pred range: -456.8118896484375 101.8597412109375
mask valid positions: 44551.0 / 65536

>>> Gradient explosion detected, grad_norm= 4634799.531471239
[batch 50] loss=5.356303e+08 loss_diff=9.440625e-01 recon=5.356303e+08
obs_tick range: -0.99619460105896 750000.0  next_tick range: -0.999048113822937 392900.0
normed next range: -1000000.0 33600.52734375
pred range: -457.3399353027344 83.47147369384766
mask valid positions: 27642.0 / 65536

>>> Gradient explosion detected, grad_norm= 6084759.2121850215
>>> Gradient explosion detected, grad_norm= 6461168.454927855
[batch 60] loss=2.507232e+09 loss_diff=8.985527e-01 recon=2.507232e+09
obs_tick range: -0.9961943030357361 395700.0  next_tick range: -0.999048113822937 395000.0
normed next range: -1000000.0 2175.859375
pred range: -458.4906921386719 77.95509338378906
mask valid positions: 56578.0 / 65536

>>> Gradient explosion detected, grad_norm= 3470600.402535613
>>> Gradient explosion detected, grad_norm= 2093027.1020020777
[batch 70] loss=1.328431e+09 loss_diff=9.483889e-01 recon=1.328431e+09
obs_tick range: -0.9918777942657471 330000.0  next_tick range: -0.9969173073768616 378000.0
normed next range: -1000000.0 8460.291015625
pred range: -459.2419128417969 65.87793731689453
mask valid positions: 43359.0 / 65536

>>> Gradient explosion detected, grad_norm= 3854217.1133829914
>>> Gradient explosion detected, grad_norm= 4076215.20379544
>>> Gradient explosion detected, grad_norm= 35024570.91362622
>>> Gradient explosion detected, grad_norm= 1450074.8003879248
[batch 80] loss=1.283487e+09 loss_diff=9.170361e-01 recon=1.283487e+09
obs_tick range: -0.9990478754043579 375000.0  next_tick range: -1.0 375000.0
normed next range: -1000000.0 8186.6767578125
pred range: -459.7156066894531 69.86054229736328
mask valid positions: 35667.0 / 65536

>>> Gradient explosion detected, grad_norm= 3992692.545923648
>>> Gradient explosion detected, grad_norm= 19064393.148919094
>>> Gradient explosion detected, grad_norm= 8952689.91918411
[batch 90] loss=9.623924e+08 loss_diff=9.321707e-01 recon=9.623924e+08
obs_tick range: -0.9961923360824585 375000.0  next_tick range: -0.999048113822937 355900.0
normed next range: -1000000.0 4525.703125
pred range: -460.23419189453125 79.13420104980469
mask valid positions: 55966.0 / 65536

>>> Gradient explosion detected, grad_norm= 5883058.049401251
>>> Gradient explosion detected, grad_norm= 4685460.221798626
>>> Gradient explosion detected, grad_norm= 11338423.536559043
[batch 100] loss=1.553318e+09 loss_diff=9.155875e-01 recon=1.553318e+09
obs_tick range: -0.9961945414543152 375000.0  next_tick range: -0.999048113822937 366500.0
normed next range: -1000000.0 10800.142578125
pred range: -460.39697265625 80.84907531738281
mask valid positions: 51340.0 / 65536

>>> Gradient explosion detected, grad_norm= 4108701.5714020506
>>> Gradient explosion detected, grad_norm= 33334593.711834393
[batch 110] loss=1.628628e+09 loss_diff=8.652377e-01 recon=1.628628e+09
obs_tick range: -1.0 391500.0  next_tick range: -0.9990484118461609 392100.0
normed next range: -1000000.0 2619.028564453125
pred range: -460.5985107421875 80.49591064453125
mask valid positions: 43835.0 / 65536

>>> Gradient explosion detected, grad_norm= 9418634.667791715
>>> Gradient explosion detected, grad_norm= 9490047.752582578
>>> Gradient explosion detected, grad_norm= 9058093.73298875
[batch 120] loss=1.966005e+09 loss_diff=9.437041e-01 recon=1.966005e+09
obs_tick range: -1.0 379000.0  next_tick range: -0.999048113822937 379600.0
normed next range: -1000000.0 1698.8824462890625
pred range: -460.85003662109375 73.89949035644531
mask valid positions: 50866.0 / 65536

>>> Gradient explosion detected, grad_norm= 1290816.1315461763
>>> Gradient explosion detected, grad_norm= 1099437.5556088195
>>> Gradient explosion detected, grad_norm= 15175621.321156664
[batch 130] loss=1.358453e+10 loss_diff=9.673100e-01 recon=1.358453e+10
obs_tick range: -1.0 392500.0  next_tick range: -0.9990479350090027 392300.0
normed next range: -1000000.0 1000000.0
pred range: -460.9619445800781 90.97463989257812
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 18276285.098357238
>>> Gradient explosion detected, grad_norm= 5868803.869354313
>>> Gradient explosion detected, grad_norm= 7968836.8800550345
[batch 140] loss=9.358761e+08 loss_diff=8.867047e-01 recon=9.358761e+08
obs_tick range: -0.999048113822937 352000.0  next_tick range: -1.0 395000.0
normed next range: -1000000.0 4506.4453125
pred range: -461.6162109375 66.79960632324219
mask valid positions: 35230.0 / 65536

>>> Gradient explosion detected, grad_norm= 8577731.782293573
>>> Gradient explosion detected, grad_norm= 3161404.268669875
[batch 150] loss=1.310778e+09 loss_diff=8.852584e-01 recon=1.310778e+09
obs_tick range: -1.0 374000.0  next_tick range: -1.0 375000.0
normed next range: -1000000.0 28811.37109375
pred range: -462.0391540527344 78.91902923583984
mask valid positions: 42962.0 / 65536

==============================
[2015-03][Epoch 1/20] | Time = 5.39 min
 - Total Loss : 1689470812.674819 | Recon Loss: 1689470812.609272 | Diff Loss: 0.912513
==============================
No improvement count: 1
[batch 0] loss=5.684203e+08 loss_diff=9.069471e-01 recon=5.684203e+08
obs_tick range: -1.0 367300.0  next_tick range: -0.9990472793579102 394000.0
normed next range: -1000000.0 7084.37060546875
pred range: -462.60784912109375 84.8431396484375
mask valid positions: 36113.0 / 65536

>>> Gradient explosion detected, grad_norm= 11508737.123629114
>>> Gradient explosion detected, grad_norm= 5346667.405559604
>>> Gradient explosion detected, grad_norm= 5253673.21013588
>>> Gradient explosion detected, grad_norm= 7854760.704851855
>>> Gradient explosion detected, grad_norm= 4007032.025667908
[batch 10] loss=2.506240e+02 loss_diff=9.169890e-01 recon=2.497070e+02
obs_tick range: -1.0 364100.0  next_tick range: -0.999048113822937 369000.0
normed next range: -19.445436477661133 2678.399169921875
pred range: -372.7158508300781 10.899044036865234
mask valid positions: 58184.0 / 65536

>>> Gradient explosion detected, grad_norm= 22264936.78306506
>>> Gradient explosion detected, grad_norm= 1317006.7025814373
>>> Gradient explosion detected, grad_norm= 1184324.6591284245
>>> Gradient explosion detected, grad_norm= 1177722.5811386406
>>> Gradient explosion detected, grad_norm= 1635321.1457397747
[batch 20] loss=1.298366e+10 loss_diff=9.405195e-01 recon=1.298366e+10
obs_tick range: -1.0 374600.0  next_tick range: -0.999048113822937 375100.0
normed next range: -1000000.0 2191.57275390625
pred range: -463.39459228515625 60.350555419921875
mask valid positions: 64308.0 / 65536

>>> Gradient explosion detected, grad_norm= 19056703.34132278
>>> Gradient explosion detected, grad_norm= 4748177.663216295
[batch 30] loss=2.076541e+09 loss_diff=9.589202e-01 recon=2.076541e+09
obs_tick range: -0.984808087348938 394000.0  next_tick range: -0.9920357465744019 394000.0
normed next range: -1000000.0 3453.723388671875
pred range: -463.9945373535156 70.43643188476562
mask valid positions: 51403.0 / 65536

>>> Gradient explosion detected, grad_norm= 3507306.0377594433
>>> Gradient explosion detected, grad_norm= 25691591.82241329
[batch 40] loss=4.528207e+08 loss_diff=8.890851e-01 recon=4.528207e+08
obs_tick range: -1.0 396000.0  next_tick range: -0.9990478754043579 395700.0
normed next range: -1000000.0 2779.984375
pred range: -464.18646240234375 66.67308807373047
mask valid positions: 35303.0 / 65536

[batch 50] loss=1.530644e+09 loss_diff=9.089282e-01 recon=1.530644e+09
obs_tick range: -1.0 392100.0  next_tick range: -1.0 393300.0
normed next range: -1000000.0 1000000.0
pred range: -465.1361999511719 89.1204605102539
mask valid positions: 58156.0 / 65536

>>> Gradient explosion detected, grad_norm= 3115231.3943896303
>>> Gradient explosion detected, grad_norm= 3161862.3145371866
>>> Gradient explosion detected, grad_norm= 1422613.0109595114
>>> Gradient explosion detected, grad_norm= 4087632.3009998184
[batch 60] loss=1.225416e+09 loss_diff=8.686595e-01 recon=1.225416e+09
obs_tick range: -0.9961902499198914 367900.0  next_tick range: -0.9990479350090027 367100.0
normed next range: -1000000.0 1776.2738037109375
pred range: -465.7581787109375 109.33290100097656
mask valid positions: 43212.0 / 65536

>>> Gradient explosion detected, grad_norm= 4938597.695736135
>>> Gradient explosion detected, grad_norm= 12533053.868658246
[batch 70] loss=1.284883e+09 loss_diff=9.525098e-01 recon=1.284883e+09
obs_tick range: -0.9972502589225769 370000.0  next_tick range: -0.9993916153907776 370000.0
normed next range: -1000000.0 22119.92578125
pred range: -466.28375244140625 80.35482025146484
mask valid positions: 43898.0 / 65536

>>> Gradient explosion detected, grad_norm= 4266913.586362692
[batch 80] loss=1.649270e+09 loss_diff=9.811486e-01 recon=1.649270e+09
obs_tick range: -1.0 394000.0  next_tick range: -1.0 330400.0
normed next range: -1000000.0 13476.609375
pred range: -467.14263916015625 81.51191711425781
mask valid positions: 35686.0 / 65536

>>> Gradient explosion detected, grad_norm= 1530176.0797976428
>>> Gradient explosion detected, grad_norm= 9174208.580879256
>>> Gradient explosion detected, grad_norm= 1766326.8683170418
>>> Gradient explosion detected, grad_norm= 5233291.702198691
>>> Gradient explosion detected, grad_norm= 1494927.4525376498
>>> Gradient explosion detected, grad_norm= 9886021.498310491
>>> Gradient explosion detected, grad_norm= 1477015.4264140562
>>> Gradient explosion detected, grad_norm= 3270607.950577007
[batch 90] loss=1.602809e+09 loss_diff=8.973125e-01 recon=1.602809e+09
obs_tick range: -0.9914443492889404 393300.0  next_tick range: -0.9961930513381958 392900.0
normed next range: -1000000.0 5971.15478515625
pred range: -467.53271484375 93.33570098876953
mask valid positions: 51228.0 / 65536

[batch 100] loss=1.371490e+09 loss_diff=9.596989e-01 recon=1.371490e+09
obs_tick range: -0.9961928725242615 393300.0  next_tick range: -0.9914445281028748 393900.0
normed next range: -1000000.0 8368.9951171875
pred range: -468.19891357421875 83.02677917480469
mask valid positions: 43576.0 / 65536

>>> Gradient explosion detected, grad_norm= 13055295.381353926
>>> Gradient explosion detected, grad_norm= 1713207.6290236514
[batch 110] loss=2.265634e+08 loss_diff=9.013624e-01 recon=2.265634e+08
obs_tick range: -1.0 375000.0  next_tick range: -0.9990481734275818 366900.0
normed next range: -1000000.0 15261.5830078125
pred range: -469.0768127441406 70.03508758544922
mask valid positions: 35279.0 / 65536

>>> Gradient explosion detected, grad_norm= 2421904.48157507
>>> Gradient explosion detected, grad_norm= 2817459.5326331044
[batch 120] loss=1.555997e+09 loss_diff=9.052356e-01 recon=1.555997e+09
obs_tick range: -0.9961928129196167 373300.0  next_tick range: -0.9990478157997131 373700.0
normed next range: -1000000.0 4954.69384765625
pred range: -469.9334411621094 69.47257995605469
mask valid positions: 35782.0 / 65536

>>> Gradient explosion detected, grad_norm= 14464830.88321614
[batch 130] loss=8.116284e+08 loss_diff=9.230173e-01 recon=8.116284e+08
obs_tick range: -0.9969179034233093 366100.0  next_tick range: -0.9993910789489746 378400.0
normed next range: -1000000.0 18707.31640625
pred range: -470.6075134277344 80.95528411865234
mask valid positions: 36258.0 / 65536

>>> Gradient explosion detected, grad_norm= 4258597.352707489
>>> Gradient explosion detected, grad_norm= 7219059.868621231
[batch 140] loss=1.143849e+09 loss_diff=9.192395e-01 recon=1.143849e+09
obs_tick range: -0.9762911200523376 365000.0  next_tick range: -0.976296067237854 365000.0
normed next range: -1000000.0 37019.28125
pred range: -470.8436279296875 79.69908905029297
mask valid positions: 34303.0 / 65536

>>> Gradient explosion detected, grad_norm= 20651718.060027488
>>> Gradient explosion detected, grad_norm= 7214442.870866343
>>> Gradient explosion detected, grad_norm= 21790668.805578057
[batch 150] loss=6.426438e+08 loss_diff=9.648784e-01 recon=6.426438e+08
obs_tick range: -0.9993920922279358 351900.0  next_tick range: -1.0 352000.0
normed next range: -1000000.0 4497.10986328125
pred range: -471.61358642578125 58.31985092163086
mask valid positions: 29822.0 / 65536

>>> Gradient explosion detected, grad_norm= 5480092.494237348
>>> Gradient explosion detected, grad_norm= 23155746.45274878
==============================
[2015-03][Epoch 2/20] | Time = 5.64 min
 - Total Loss : 2035550131.670854 | Recon Loss: 2035550131.610377 | Diff Loss: 0.923336
==============================
No improvement count: 2
[batch 0] loss=1.855929e+09 loss_diff=9.137564e-01 recon=1.855929e+09
obs_tick range: -1.0 565000.0  next_tick range: -0.9848082065582275 361800.0
normed next range: -1000000.0 1000000.0
pred range: -471.7706604003906 82.56970977783203
mask valid positions: 35921.0 / 65536

>>> Gradient explosion detected, grad_norm= 16466149.85711398
>>> Gradient explosion detected, grad_norm= 10111532.415312575
[batch 10] loss=5.397308e+08 loss_diff=8.804331e-01 recon=5.397308e+08
obs_tick range: -0.9990478157997131 373700.0  next_tick range: -1.0 374000.0
normed next range: -1000000.0 4927.3154296875
pred range: -472.1368103027344 72.67848205566406
mask valid positions: 36854.0 / 65536

>>> Gradient explosion detected, grad_norm= 5234341.6782949185
>>> Gradient explosion detected, grad_norm= 7972365.520576227
[batch 20] loss=1.445505e+09 loss_diff=9.309243e-01 recon=1.445505e+09
obs_tick range: -0.9990472793579102 365100.0  next_tick range: -1.0 365700.0
normed next range: -1000000.0 2286.177490234375
pred range: -472.5246887207031 90.90987396240234
mask valid positions: 58184.0 / 65536

[batch 30] loss=1.042735e+09 loss_diff=9.195229e-01 recon=1.042735e+09
obs_tick range: -1.0 393300.0  next_tick range: -1.0 393900.0
normed next range: -1000000.0 10999.072265625
pred range: -473.22149658203125 90.20558166503906
mask valid positions: 51653.0 / 65536

>>> Gradient explosion detected, grad_norm= 4896512.246321048
>>> Gradient explosion detected, grad_norm= 12740855.972140385
[batch 40] loss=1.422877e+09 loss_diff=8.406793e-01 recon=1.422877e+09
obs_tick range: -1.0 361000.0  next_tick range: -0.9990474581718445 361000.0
normed next range: -1000000.0 12558.0419921875
pred range: -473.9209899902344 92.14247131347656
mask valid positions: 51194.0 / 65536

>>> Gradient explosion detected, grad_norm= 5261091.720675968
[batch 50] loss=6.751197e+08 loss_diff=9.039345e-01 recon=6.751197e+08
obs_tick range: -1.0 368800.0  next_tick range: -1.0 235900.0
normed next range: -1000000.0 1679.29150390625
pred range: -474.7193298339844 93.3568344116211
mask valid positions: 50451.0 / 65536

>>> Gradient explosion detected, grad_norm= 9569154.760521516
>>> Gradient explosion detected, grad_norm= 15974920.56692582
>>> Gradient explosion detected, grad_norm= 8776014.973609416
>>> Gradient explosion detected, grad_norm= 3706891.682977066
[batch 60] loss=6.458214e+08 loss_diff=8.822564e-01 recon=6.458214e+08
obs_tick range: -0.9971016645431519 392900.0  next_tick range: -0.9993922710418701 391500.0
normed next range: -1000000.0 5516.71875
pred range: -475.1799011230469 79.12522888183594
mask valid positions: 22221.0 / 65536

>>> Gradient explosion detected, grad_norm= 4239760.115595141
[batch 70] loss=1.853878e+02 loss_diff=9.137722e-01 recon=1.844741e+02
obs_tick range: -1.0 371500.0  next_tick range: -0.9238699674606323 371500.0
normed next range: -2.4748735427856445 3947.68212890625
pred range: -466.68963623046875 13.444709777832031
mask valid positions: 36276.0 / 65536

>>> Gradient explosion detected, grad_norm= 8901084.260841256
>>> Gradient explosion detected, grad_norm= 5585214.543305674
>>> Gradient explosion detected, grad_norm= 5319064.728561721
[batch 80] loss=2.734561e+09 loss_diff=9.234768e-01 recon=2.734561e+09
obs_tick range: -0.999046266078949 367000.0  next_tick range: -1.0 871959.0
normed next range: -1000000.0 7069.9970703125
pred range: -475.9793395996094 85.11520385742188
mask valid positions: 44308.0 / 65536

[batch 90] loss=5.578383e+08 loss_diff=8.971626e-01 recon=5.578383e+08
obs_tick range: -0.9723461866378784 378400.0  next_tick range: -0.9790471792221069 375200.0
normed next range: -1000000.0 4541.361328125
pred range: -476.6905212402344 92.30827331542969
mask valid positions: 58291.0 / 65536

>>> Gradient explosion detected, grad_norm= 5250047.293771296
>>> Gradient explosion detected, grad_norm= 5222026.779282325
>>> Gradient explosion detected, grad_norm= 4178709.8252474405
[batch 100] loss=1.612618e+09 loss_diff=8.965813e-01 recon=1.612618e+09
obs_tick range: -0.9914413094520569 395000.0  next_tick range: -0.9961941242218018 394100.0
normed next range: -1000000.0 13248.26171875
pred range: -477.5614318847656 74.93677520751953
mask valid positions: 43030.0 / 65536

>>> Gradient explosion detected, grad_norm= 1886647.7415371824
>>> Gradient explosion detected, grad_norm= 1826842.4755140997
>>> Gradient explosion detected, grad_norm= 3312848.318653592
[batch 110] loss=2.171003e+08 loss_diff=9.045721e-01 recon=2.171003e+08
obs_tick range: -0.9762953519821167 395000.0  next_tick range: -0.9659252762794495 394800.0
normed next range: -1000000.0 5267.744140625
pred range: -478.3233642578125 81.43119049072266
mask valid positions: 42258.0 / 65536

[batch 120] loss=1.606877e+09 loss_diff=8.790337e-01 recon=1.606877e+09
obs_tick range: -0.9990479350090027 375000.0  next_tick range: -0.9961943626403809 384100.0
normed next range: -1000000.0 7069.9970703125
pred range: -479.1800231933594 88.27667999267578
mask valid positions: 43353.0 / 65536

>>> Gradient explosion detected, grad_norm= 2021577.5625537678
>>> Gradient explosion detected, grad_norm= 17269912.419228934
[batch 130] loss=5.879509e+08 loss_diff=9.072650e-01 recon=5.879509e+08
obs_tick range: -0.999048113822937 393000.0  next_tick range: -1.0 393600.0
normed next range: -1000000.0 2939.061767578125
pred range: -479.90301513671875 70.16402435302734
mask valid positions: 57468.0 / 65536

>>> Gradient explosion detected, grad_norm= 1878081.585243298
>>> Gradient explosion detected, grad_norm= 3455023.658055764
>>> Gradient explosion detected, grad_norm= 6477044.132123747
[batch 140] loss=2.312025e+09 loss_diff=8.530431e-01 recon=2.312025e+09
obs_tick range: -0.9848069548606873 393700.0  next_tick range: -0.9859625101089478 392700.0
normed next range: -1000000.0 5620.72998046875
pred range: -480.72454833984375 62.762351989746094
mask valid positions: 36416.0 / 65536

>>> Gradient explosion detected, grad_norm= 2106996.6264728107
[batch 150] loss=1.021603e+09 loss_diff=9.350520e-01 recon=1.021603e+09
obs_tick range: -0.9396935701370239 378000.0  next_tick range: -0.9575781226158142 365000.0
normed next range: -1000000.0 4676.13232421875
pred range: -481.3719482421875 68.75080871582031
mask valid positions: 42852.0 / 65536

>>> Gradient explosion detected, grad_norm= 3001545.747811462
==============================
[2015-03][Epoch 3/20] | Time = 5.64 min
 - Total Loss : 1430326603.489853 | Recon Loss: 1430326603.424913 | Diff Loss: 0.909360
==============================
No improvement count: 3
[batch 0] loss=7.610818e+08 loss_diff=9.215336e-01 recon=7.610818e+08
obs_tick range: -0.9961944818496704 365600.0  next_tick range: -0.9914442896842957 365200.0
normed next range: -1000000.0 49718.375
pred range: -481.7807922363281 85.52307891845703
mask valid positions: 42723.0 / 65536

[batch 10] loss=2.453608e+09 loss_diff=8.995178e-01 recon=2.453608e+09
obs_tick range: -0.9969173073768616 371500.0  next_tick range: -0.9993932247161865 360000.0
normed next range: -1000000.0 3154.6376953125
pred range: -483.14483642578125 77.58100128173828
mask valid positions: 38502.0 / 65536

>>> Gradient explosion detected, grad_norm= 5168039.359335481
>>> Gradient explosion detected, grad_norm= 3410695.82865979
>>> Gradient explosion detected, grad_norm= 2060950.320348117
>>> Gradient explosion detected, grad_norm= 3187816.053327293
[batch 20] loss=2.652375e+09 loss_diff=8.735820e-01 recon=2.652375e+09
obs_tick range: -0.9990481734275818 364300.0  next_tick range: -0.9961925148963928 376800.0
normed next range: -1000000.0 2975.910400390625
pred range: -483.8623352050781 60.64171600341797
mask valid positions: 58353.0 / 65536

>>> Gradient explosion detected, grad_norm= 5390432.178827199
>>> Gradient explosion detected, grad_norm= 3370702.46268648
[batch 30] loss=1.218972e+09 loss_diff=9.003385e-01 recon=1.218972e+09
obs_tick range: -0.999048113822937 365200.0  next_tick range: -1.0 366400.0
normed next range: -1000000.0 3332.50537109375
pred range: -484.6775207519531 57.22079086303711
mask valid positions: 51039.0 / 65536

>>> Gradient explosion detected, grad_norm= 2891193.953208818
[batch 40] loss=2.827061e+09 loss_diff=9.236688e-01 recon=2.827061e+09
obs_tick range: -0.9990479946136475 189500.0  next_tick range: -0.9961945414543152 375000.0
normed next range: -1000000.0 14426.876953125
pred range: -485.3348693847656 64.77339935302734
mask valid positions: 35950.0 / 65536

[batch 50] loss=2.813774e+08 loss_diff=8.861400e-01 recon=2.813774e+08
obs_tick range: -0.9990481734275818 365000.0  next_tick range: -1.0 329800.0
normed next range: -1000000.0 6241.671875
pred range: -485.98040771484375 80.18850708007812
mask valid positions: 34861.0 / 65536

>>> Gradient explosion detected, grad_norm= 5300230.764930325
[batch 60] loss=1.238663e+09 loss_diff=9.439709e-01 recon=1.238663e+09
obs_tick range: -0.9781531691551208 367900.0  next_tick range: -0.9859625101089478 368900.0
normed next range: -1000000.0 2233.767578125
pred range: -486.8982238769531 72.7100830078125
mask valid positions: 43628.0 / 65536

>>> Gradient explosion detected, grad_norm= 4724407.688622144
>>> Gradient explosion detected, grad_norm= 2821179.1863045986
[batch 70] loss=2.974805e+02 loss_diff=8.942075e-01 recon=2.965863e+02
obs_tick range: -0.8870139122009277 375200.0  next_tick range: -0.9099788069725037 374600.0
normed next range: -2.474870204925537 3896.87939453125
pred range: -18.923812866210938 11.944206237792969
mask valid positions: 33710.0 / 65536

>>> Gradient explosion detected, grad_norm= 3694600.7417500024
>>> Gradient explosion detected, grad_norm= 1615748.3478668695
>>> Gradient explosion detected, grad_norm= 2094168.1851177895
>>> Gradient explosion detected, grad_norm= 7642312.604624593
>>> Gradient explosion detected, grad_norm= 3396844.903044143
>>> Gradient explosion detected, grad_norm= 2319465.4752120273
>>> Gradient explosion detected, grad_norm= 3619125.7577261506
>>> Gradient explosion detected, grad_norm= 3569891.9523105365
[batch 80] loss=1.671978e+09 loss_diff=9.329258e-01 recon=1.671978e+09
obs_tick range: -0.9961945414543152 361000.0  next_tick range: -0.999048113822937 361000.0
normed next range: -1000000.0 5703.96875
pred range: -488.0000305175781 68.0886459350586
mask valid positions: 58287.0 / 65536

>>> Gradient explosion detected, grad_norm= 10200476.377970075
>>> Gradient explosion detected, grad_norm= 7561891.619839599
>>> Gradient explosion detected, grad_norm= 9744180.178603915
>>> Gradient explosion detected, grad_norm= 1054686.216621595
[batch 90] loss=2.544415e+09 loss_diff=9.300683e-01 recon=2.544415e+09
obs_tick range: -0.9990481734275818 369000.0  next_tick range: -0.99619460105896 368900.0
normed next range: -1000000.0 2894.1494140625
pred range: -487.9583435058594 48.98936462402344
mask valid positions: 58256.0 / 65536

>>> Gradient explosion detected, grad_norm= 7805338.064768805
>>> Gradient explosion detected, grad_norm= 1787545.3865570147
[batch 100] loss=1.552734e+09 loss_diff=9.609711e-01 recon=1.552734e+09
obs_tick range: -0.9848073720932007 371500.0  next_tick range: -0.9762940406799316 370200.0
normed next range: -1000000.0 3119.387939453125
pred range: -488.47705078125 83.80183410644531
mask valid positions: 48672.0 / 65536

>>> Gradient explosion detected, grad_norm= 9419395.61390491
>>> Gradient explosion detected, grad_norm= 10592596.117027324
>>> Gradient explosion detected, grad_norm= 6274665.099939787
>>> Gradient explosion detected, grad_norm= 11180185.288116843
[batch 110] loss=1.660398e+09 loss_diff=9.270965e-01 recon=1.660398e+09
obs_tick range: -0.9993920922279358 368400.0  next_tick range: -1.0 368500.0
normed next range: -1000000.0 2582.783935546875
pred range: -488.9805603027344 84.28514099121094
mask valid positions: 50710.0 / 65536

>>> Gradient explosion detected, grad_norm= 3634497.1706437045
>>> Gradient explosion detected, grad_norm= 3396829.909368178
[batch 120] loss=1.152017e+09 loss_diff=9.974533e-01 recon=1.152017e+09
obs_tick range: -0.9994696378707886 367200.0  next_tick range: -1.0 691449.0
normed next range: -1000000.0 11874.2138671875
pred range: -489.7164001464844 87.08548736572266
mask valid positions: 37527.0 / 65536

>>> Gradient explosion detected, grad_norm= 3337378.9474048205
>>> Gradient explosion detected, grad_norm= 1693342.4873897647
>>> Gradient explosion detected, grad_norm= 3560941.900486569
[batch 130] loss=4.399747e+08 loss_diff=9.092156e-01 recon=4.399747e+08
obs_tick range: -0.9659244418144226 380000.0  next_tick range: -0.9563170671463013 380000.0
normed next range: -1000000.0 12204.85546875
pred range: -490.1966857910156 31.86288070678711
mask valid positions: 35300.0 / 65536

[batch 140] loss=1.153166e+09 loss_diff=8.923320e-01 recon=1.153166e+09
obs_tick range: -0.9993917346000671 369000.0  next_tick range: -1.0 360800.0
normed next range: -1000000.0 10171.4267578125
pred range: -491.3468017578125 67.8629150390625
mask valid positions: 40010.0 / 65536

>>> Gradient explosion detected, grad_norm= 1910988.7036528066
[batch 150] loss=5.132341e+08 loss_diff=9.189667e-01 recon=5.132341e+08
obs_tick range: -0.9914447665214539 395000.0  next_tick range: -0.9848071336746216 1692079.0
normed next range: -1000000.0 3792.200927734375
pred range: -492.2159118652344 73.8232192993164
mask valid positions: 27429.0 / 65536

==============================
[2015-03][Epoch 4/20] | Time = 5.64 min
 - Total Loss : 1289894983.084035 | Recon Loss: 1289894983.012464 | Diff Loss: 0.915167
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-03 completed in 22.30 min
[1] 2015-04 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-04 | file : news_20150430.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=4.175796e+08 loss_diff=8.540790e-01 recon=4.175796e+08
obs_tick range: -0.9961928129196167 373300.0  next_tick range: -0.9990478157997131 650000.0
normed next range: -1000000.0 6820.45556640625
pred range: -492.9183654785156 70.0687484741211
mask valid positions: 35453.0 / 65536

>>> Gradient explosion detected, grad_norm= 13510442.097377025
>>> Gradient explosion detected, grad_norm= 1903485.2587364365
[batch 10] loss=7.178401e+08 loss_diff=9.179002e-01 recon=7.178401e+08
obs_tick range: -0.9914343357086182 382400.0  next_tick range: -0.996194064617157 381500.0
normed next range: -1000000.0 9136.0498046875
pred range: -493.9459228515625 38.69642639160156
mask valid positions: 35047.0 / 65536

[batch 20] loss=1.135825e+09 loss_diff=9.626168e-01 recon=1.135825e+09
obs_tick range: -0.9961946606636047 1750000.0  next_tick range: -0.9990478157997131 394800.0
normed next range: -1000000.0 2949.338134765625
pred range: -495.24981689453125 76.5736312866211
mask valid positions: 50536.0 / 65536

[batch 30] loss=4.321476e+09 loss_diff=9.003540e-01 recon=4.321476e+09
obs_tick range: -1.0 374400.0  next_tick range: -0.999048113822937 375100.0
normed next range: -1000000.0 2147.82080078125
pred range: -496.73046875 92.21817016601562
mask valid positions: 51144.0 / 65536

>>> Gradient explosion detected, grad_norm= 3805130.8304915917
>>> Gradient explosion detected, grad_norm= 14552372.792657211
[batch 40] loss=1.427455e+09 loss_diff=8.855853e-01 recon=1.427455e+09
obs_tick range: -0.984803318977356 389000.0  next_tick range: -0.9914384484291077 388500.0
normed next range: -1000000.0 3794.085205078125
pred range: -497.8487243652344 64.306884765625
mask valid positions: 49818.0 / 65536

>>> Gradient explosion detected, grad_norm= 10818035.76659073
>>> Gradient explosion detected, grad_norm= 10821502.306351645
>>> Gradient explosion detected, grad_norm= 11974841.188240223
>>> Gradient explosion detected, grad_norm= 10790370.567195259
>>> Gradient explosion detected, grad_norm= 14911937.662529815
>>> Gradient explosion detected, grad_norm= 2457153.551765504
>>> Gradient explosion detected, grad_norm= 1185837.9117821972
[batch 50] loss=5.165028e+03 loss_diff=9.000851e-01 recon=5.164128e+03
obs_tick range: -1.0 1692079.0  next_tick range: -1.0 350000.0
normed next range: -9.110589027404785 38824.36328125
pred range: -16.269840240478516 12.429935455322266
mask valid positions: 36628.0 / 65536

>>> Gradient explosion detected, grad_norm= 1289361.7950415392
[batch 60] loss=2.025331e+09 loss_diff=9.662167e-01 recon=2.025331e+09
obs_tick range: -0.9914447665214539 371700.0  next_tick range: -0.9961923360824585 373300.0
normed next range: -1000000.0 4589.75390625
pred range: -499.13714599609375 36.6121940612793
mask valid positions: 43946.0 / 65536

>>> Gradient explosion detected, grad_norm= 5938116.884439091
[batch 70] loss=3.851894e+08 loss_diff=9.515234e-01 recon=3.851894e+08
obs_tick range: -1.0 329800.0  next_tick range: -1.0 371500.0
normed next range: -1000000.0 9589.0908203125
pred range: -499.177490234375 50.72431945800781
mask valid positions: 37490.0 / 65536

>>> Gradient explosion detected, grad_norm= 3839590.234464203
[batch 80] loss=2.598229e+09 loss_diff=9.071641e-01 recon=2.598229e+09
obs_tick range: -1.0 329700.0  next_tick range: -0.9990479350090027 367100.0
normed next range: -1000000.0 5847.46923828125
pred range: -500.2467041015625 76.9266586303711
mask valid positions: 36179.0 / 65536

[batch 90] loss=2.220547e+09 loss_diff=1.002926e+00 recon=2.220547e+09
obs_tick range: -1.0 379000.0  next_tick range: -0.9993920922279358 379600.0
normed next range: -1000000.0 3161.485107421875
pred range: -501.4152526855469 79.69649505615234
mask valid positions: 36156.0 / 65536

[batch 100] loss=1.567339e+09 loss_diff=1.000669e+00 recon=1.567339e+09
obs_tick range: -0.9914441108703613 343800.0  next_tick range: -0.9918777942657471 342000.0
normed next range: -1000000.0 2894.439697265625
pred range: -502.6603698730469 75.38417053222656
mask valid positions: 51635.0 / 65536

>>> Gradient explosion detected, grad_norm= 2409048.044956491
>>> Gradient explosion detected, grad_norm= 21849007.35740943
>>> Gradient explosion detected, grad_norm= 5074831.920281992
>>> Gradient explosion detected, grad_norm= 2514563.285737164
>>> Gradient explosion detected, grad_norm= 6340599.608882995
[batch 110] loss=2.222161e+09 loss_diff=9.056064e-01 recon=2.222161e+09
obs_tick range: -0.9993684887886047 366100.0  next_tick range: -1.0 376800.0
normed next range: -1000000.0 4350.51513671875
pred range: -503.08148193359375 52.168365478515625
mask valid positions: 44713.0 / 65536

>>> Gradient explosion detected, grad_norm= 3650243.995342466
>>> Gradient explosion detected, grad_norm= 5967572.08733558
>>> Gradient explosion detected, grad_norm= 1917791.0702438003
>>> Gradient explosion detected, grad_norm= 1881930.5153228017
>>> Gradient explosion detected, grad_norm= 88959390.47241172
[batch 120] loss=2.185746e+09 loss_diff=9.899154e-01 recon=2.185746e+09
obs_tick range: -0.9961932897567749 366800.0  next_tick range: -0.9990479946136475 366700.0
normed next range: -1000000.0 3363.931884765625
pred range: -503.278076171875 20.074066162109375
mask valid positions: 51109.0 / 65536

>>> Gradient explosion detected, grad_norm= 9854034.062542055
>>> Gradient explosion detected, grad_norm= 43712009.47749329
>>> Gradient explosion detected, grad_norm= 1801388.7264458905
[batch 130] loss=1.423924e+02 loss_diff=9.009186e-01 recon=1.414915e+02
obs_tick range: -1.0 373700.0  next_tick range: -1.0 375000.0
normed next range: -13.788582801818848 4791.7021484375
pred range: -25.558792114257812 16.50637435913086
mask valid positions: 49528.0 / 65536

>>> Gradient explosion detected, grad_norm= 8706693.85405616
>>> Gradient explosion detected, grad_norm= 8870189.093694089
>>> Gradient explosion detected, grad_norm= 1592906.4881442748
>>> Gradient explosion detected, grad_norm= 6237120.374289497
[batch 140] loss=2.008592e+09 loss_diff=8.965065e-01 recon=2.008592e+09
obs_tick range: -0.991442084312439 379900.0  next_tick range: -0.996194064617157 378300.0
normed next range: -1000000.0 21313.75
pred range: -502.7981262207031 52.58302307128906
mask valid positions: 36128.0 / 65536

>>> Gradient explosion detected, grad_norm= 11071230.880227461
>>> Gradient explosion detected, grad_norm= 27218556.54068277
>>> Gradient explosion detected, grad_norm= 8148921.564072513
>>> Gradient explosion detected, grad_norm= 25242769.530891694
[batch 150] loss=1.961027e+09 loss_diff=9.684894e-01 recon=1.961027e+09
obs_tick range: -1.0 375000.0  next_tick range: -1.0 371500.0
normed next range: -1000000.0 4214.857421875
pred range: -503.53662109375 83.30333709716797
mask valid positions: 43634.0 / 65536

>>> Gradient explosion detected, grad_norm= 13688881.088126576
>>> Gradient explosion detected, grad_norm= 10838987.06320305
>>> Gradient explosion detected, grad_norm= 4398187.919712527
==============================
[2015-04][Epoch 1/20] | Time = 5.59 min
 - Total Loss : 1656081262.551683 | Recon Loss: 1656081262.481471 | Diff Loss: 0.917351
==============================
No improvement count: 1
[batch 0] loss=8.688285e+08 loss_diff=9.595439e-01 recon=8.688285e+08
obs_tick range: -1.0 394500.0  next_tick range: -0.9969229698181152 350000.0
normed next range: -1000000.0 11321.69921875
pred range: -503.3985290527344 60.82625961303711
mask valid positions: 28538.0 / 65536

>>> Gradient explosion detected, grad_norm= 1857551.2575228189
>>> Gradient explosion detected, grad_norm= 9370661.832829928
>>> Gradient explosion detected, grad_norm= 17982880.6856903
[batch 10] loss=7.559942e+08 loss_diff=9.254616e-01 recon=7.559942e+08
obs_tick range: -0.999047577381134 367900.0  next_tick range: -0.996190071105957 369900.0
normed next range: -1000000.0 2811.094482421875
pred range: -504.3022766113281 40.77623748779297
mask valid positions: 35202.0 / 65536

>>> Gradient explosion detected, grad_norm= 6660161.459820398
>>> Gradient explosion detected, grad_norm= 1913074.4435153012
>>> Gradient explosion detected, grad_norm= 4092606.3460160866
>>> Gradient explosion detected, grad_norm= 81951054.97490734
>>> Gradient explosion detected, grad_norm= 1509017.5668751346
[batch 20] loss=4.257108e+08 loss_diff=8.985253e-01 recon=4.257108e+08
obs_tick range: -0.984804630279541 376800.0  next_tick range: -0.9762953519821167 387100.0
normed next range: -1000000.0 3704.962646484375
pred range: -504.6681213378906 86.04706573486328
mask valid positions: 42455.0 / 65536

>>> Gradient explosion detected, grad_norm= 21844279.63201209
>>> Gradient explosion detected, grad_norm= 1928527.3626980947
[batch 30] loss=8.749043e+08 loss_diff=8.822634e-01 recon=8.749043e+08
obs_tick range: -0.9914427399635315 366200.0  next_tick range: -0.99619460105896 366200.0
normed next range: -1000000.0 5913.677734375
pred range: -504.742431640625 73.12059020996094
mask valid positions: 27821.0 / 65536

>>> Gradient explosion detected, grad_norm= 2416633.856917945
[batch 40] loss=1.259273e+09 loss_diff=9.555290e-01 recon=1.259273e+09
obs_tick range: -1.0 365000.0  next_tick range: -0.9995337724685669 367500.0
normed next range: -1000000.0 3727.9599609375
pred range: -505.7888488769531 87.25444030761719
mask valid positions: 50774.0 / 65536

>>> Gradient explosion detected, grad_norm= 6509075.540039652
>>> Gradient explosion detected, grad_norm= 5297256.700862971
[batch 50] loss=7.773251e+08 loss_diff=9.026679e-01 recon=7.773251e+08
obs_tick range: -0.9990484118461609 394500.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 4972.1123046875
pred range: -506.4051208496094 87.10499572753906
mask valid positions: 37972.0 / 65536

>>> Gradient explosion detected, grad_norm= 7587047.812818862
>>> Gradient explosion detected, grad_norm= 6922092.965275912
[batch 60] loss=6.457083e+08 loss_diff=8.739258e-01 recon=6.457083e+08
obs_tick range: -0.9990483522415161 378000.0  next_tick range: -1.0 500000.0
normed next range: -1000000.0 1000000.0
pred range: -506.6634521484375 69.51399230957031
mask valid positions: 14349.0 / 65536

[batch 70] loss=1.325245e+09 loss_diff=8.990009e-01 recon=1.325245e+09
obs_tick range: -0.9990480542182922 380300.0  next_tick range: -1.0 380000.0
normed next range: -1000000.0 3932.05078125
pred range: -507.5689392089844 79.9845199584961
mask valid positions: 50713.0 / 65536

>>> Gradient explosion detected, grad_norm= 1079436.6688709483
>>> Gradient explosion detected, grad_norm= 3956034.832922224
[batch 80] loss=1.528111e+09 loss_diff=9.055209e-01 recon=1.528111e+09
obs_tick range: -0.9961932897567749 375000.0  next_tick range: -0.9990479946136475 371400.0
normed next range: -1000000.0 3063.09619140625
pred range: -508.23974609375 88.3287353515625
mask valid positions: 50934.0 / 65536

>>> Gradient explosion detected, grad_norm= 2084436.5801976733
>>> Gradient explosion detected, grad_norm= 1106525.0830056458
>>> Gradient explosion detected, grad_norm= 13362762.800000833
>>> Gradient explosion detected, grad_norm= 2465146.7742789392
[batch 90] loss=1.504433e+09 loss_diff=9.059627e-01 recon=1.504433e+09
obs_tick range: -1.0 365100.0  next_tick range: -0.9961942434310913 375000.0
normed next range: -1000000.0 6241.1875
pred range: -508.6993103027344 9.75394058227539
mask valid positions: 42864.0 / 65536

>>> Gradient explosion detected, grad_norm= 2463727.916435375
>>> Gradient explosion detected, grad_norm= 581470726.19717
>>> Gradient explosion detected, grad_norm= 2817781.193602835
>>> Gradient explosion detected, grad_norm= 11017174.723962804
>>> Gradient explosion detected, grad_norm= 24289391.737763282
[batch 100] loss=3.701216e+08 loss_diff=9.631644e-01 recon=3.701216e+08
obs_tick range: -0.991443395614624 380800.0  next_tick range: -0.9961920380592346 379900.0
normed next range: -1000000.0 3894.802734375
pred range: -508.473876953125 81.16134643554688
mask valid positions: 50551.0 / 65536

>>> Gradient explosion detected, grad_norm= 1615214.5043572744
>>> Gradient explosion detected, grad_norm= 27683397.597771496
>>> Gradient explosion detected, grad_norm= 2150097.1916074897
>>> Gradient explosion detected, grad_norm= 1738188.6142680799
>>> Gradient explosion detected, grad_norm= 1896933.2828086682
>>> Gradient explosion detected, grad_norm= 36023446.47113222
>>> Gradient explosion detected, grad_norm= 38251728.52526762
>>> Gradient explosion detected, grad_norm= 26400004.201762754
>>> Gradient explosion detected, grad_norm= 10717934.56376276
[batch 110] loss=4.909865e+08 loss_diff=8.656853e-01 recon=4.909865e+08
obs_tick range: -0.991446316242218 365000.0  next_tick range: -0.9969179034233093 365000.0
normed next range: -1000000.0 7200.27783203125
pred range: -507.95068359375 41.63883590698242
mask valid positions: 21643.0 / 65536

>>> Gradient explosion detected, grad_norm= 40235511.66634825
>>> Gradient explosion detected, grad_norm= 32059282.416063257
[batch 120] loss=2.090472e+09 loss_diff=8.442816e-01 recon=2.090472e+09
obs_tick range: -0.9993930459022522 565000.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 11981.53125
pred range: -505.7202453613281 50.76282501220703
mask valid positions: 52422.0 / 65536

>>> Gradient explosion detected, grad_norm= 34819233.59569238
>>> Gradient explosion detected, grad_norm= 1850414.555856476
>>> Gradient explosion detected, grad_norm= 2102406.1212570984
>>> Gradient explosion detected, grad_norm= 2466568.1250256905
>>> Gradient explosion detected, grad_norm= 8540244.769110482
>>> Gradient explosion detected, grad_norm= 7126700.157119746
[batch 130] loss=2.105755e+09 loss_diff=9.319738e-01 recon=2.105755e+09
obs_tick range: -0.9976633191108704 395800.0  next_tick range: -0.9995337724685669 396000.0
normed next range: -1000000.0 2832.091064453125
pred range: -507.9255065917969 48.62666702270508
mask valid positions: 51283.0 / 65536

>>> Gradient explosion detected, grad_norm= 7258594.558580787
>>> Gradient explosion detected, grad_norm= 2653865.835597745
[batch 140] loss=1.658489e+09 loss_diff=9.774067e-01 recon=1.658489e+09
obs_tick range: -0.984806478023529 394800.0  next_tick range: -0.9914427399635315 365600.0
normed next range: -1000000.0 14509.9423828125
pred range: -505.48828125 50.47293472290039
mask valid positions: 36325.0 / 65536

>>> Gradient explosion detected, grad_norm= 28780874.62050662
>>> Gradient explosion detected, grad_norm= 17788432.078692663
>>> Gradient explosion detected, grad_norm= 2449609.6388690057
>>> Gradient explosion detected, grad_norm= 9376179.181523912
>>> Gradient explosion detected, grad_norm= 7730431.22606614
>>> Gradient explosion detected, grad_norm= 1458698.9847107858
>>> Gradient explosion detected, grad_norm= 2333298.125154788
>>> Gradient explosion detected, grad_norm= 1058935.8400345647
[batch 150] loss=5.609226e+08 loss_diff=9.590296e-01 recon=5.609226e+08
obs_tick range: -0.9848065376281738 393300.0  next_tick range: -0.9914395213127136 392900.0
normed next range: -1000000.0 62300.48046875
pred range: -506.9746398925781 48.0563850402832
mask valid positions: 27365.0 / 65536

>>> Gradient explosion detected, grad_norm= 18040830.988693684
>>> Gradient explosion detected, grad_norm= 19386205.149261087
==============================
[2015-04][Epoch 2/20] | Time = 5.82 min
 - Total Loss : 1430205404.283744 | Recon Loss: 1430205404.215339 | Diff Loss: 0.911819
==============================
No improvement count: 2
[batch 0] loss=1.456548e+09 loss_diff=8.888602e-01 recon=1.456548e+09
obs_tick range: -1.0 379900.0  next_tick range: -1.0 379100.0
normed next range: -1000000.0 5795.81494140625
pred range: -507.1268005371094 37.80268096923828
mask valid positions: 28749.0 / 65536

>>> Gradient explosion detected, grad_norm= 13210546.286447966
>>> Gradient explosion detected, grad_norm= 5144924.925205126
>>> Gradient explosion detected, grad_norm= 4790037.199737663
>>> Gradient explosion detected, grad_norm= 3790277.978074506
>>> Gradient explosion detected, grad_norm= 3120148.096620171
>>> Gradient explosion detected, grad_norm= 7866997.679155939
>>> Gradient explosion detected, grad_norm= 2976431.0138283647
>>> Gradient explosion detected, grad_norm= 43859516.50619951
[batch 10] loss=2.415964e+09 loss_diff=8.973080e-01 recon=2.415964e+09
obs_tick range: -0.9927315711975098 750000.0  next_tick range: -0.9967746734619141 375000.0
normed next range: -1000000.0 21601.904296875
pred range: -506.3736572265625 8.524301528930664
mask valid positions: 22255.0 / 65536

[batch 20] loss=5.020447e+08 loss_diff=9.155291e-01 recon=5.020447e+08
obs_tick range: -1.0 363900.0  next_tick range: -1.0 500000.0
normed next range: -1000000.0 2772.630859375
pred range: -509.0638732910156 9.333738327026367
mask valid positions: 50118.0 / 65536

[batch 30] loss=1.012051e+09 loss_diff=9.366682e-01 recon=1.012051e+09
obs_tick range: -0.9993917942047119 370000.0  next_tick range: -1.0 370000.0
normed next range: -1000000.0 6613.7080078125
pred range: -511.2501220703125 9.129986763000488
mask valid positions: 29436.0 / 65536

[batch 40] loss=7.195460e+08 loss_diff=9.774710e-01 recon=7.195460e+08
obs_tick range: -0.9993915557861328 369000.0  next_tick range: -1.0 371400.0
normed next range: -1000000.0 11645.2841796875
pred range: -512.8504638671875 8.30505084991455
mask valid positions: 43676.0 / 65536

>>> Gradient explosion detected, grad_norm= 1023133.8980473803
[batch 50] loss=9.972492e+08 loss_diff=8.937089e-01 recon=9.972492e+08
obs_tick range: -1.0 369000.0  next_tick range: -1.0 366400.0
normed next range: -1000000.0 13491.8935546875
pred range: -514.3028564453125 10.33408260345459
mask valid positions: 44900.0 / 65536

>>> Gradient explosion detected, grad_norm= 1967717.7758292707
[batch 60] loss=1.090936e+09 loss_diff=8.843198e-01 recon=1.090936e+09
obs_tick range: -0.9659191370010376 392200.0  next_tick range: -0.9762871265411377 392000.0
normed next range: -1000000.0 8602.5458984375
pred range: -515.9857177734375 7.1973676681518555
mask valid positions: 50619.0 / 65536

[batch 70] loss=6.777941e+08 loss_diff=9.272566e-01 recon=6.777941e+08
obs_tick range: -0.9961945414543152 392300.0  next_tick range: -0.999048113822937 392500.0
normed next range: -1000000.0 2911.802978515625
pred range: -517.57080078125 16.816030502319336
mask valid positions: 56551.0 / 65536

[batch 80] loss=2.082533e+09 loss_diff=9.183471e-01 recon=2.082533e+09
obs_tick range: -0.9961903095245361 378000.0  next_tick range: -0.999046266078949 376600.0
normed next range: -1000000.0 6323.7607421875
pred range: -519.011474609375 6.908735752105713
mask valid positions: 50807.0 / 65536

[batch 90] loss=6.503688e+08 loss_diff=9.270689e-01 recon=6.503688e+08
obs_tick range: -1.0 371600.0  next_tick range: -0.9659255743026733 366200.0
normed next range: -1000000.0 4099.822265625
pred range: -520.5014038085938 6.804305553436279
mask valid positions: 36730.0 / 65536

[batch 100] loss=7.481734e+08 loss_diff=8.674600e-01 recon=7.481734e+08
obs_tick range: -0.9848071336746216 371500.0  next_tick range: -0.9762959480285645 369000.0
normed next range: -1000000.0 9353.2001953125
pred range: -521.7887573242188 7.233401775360107
mask valid positions: 41157.0 / 65536

[batch 110] loss=1.681052e+09 loss_diff=9.110730e-01 recon=1.681052e+09
obs_tick range: -1.0 366200.0  next_tick range: -0.9961946606636047 366200.0
normed next range: -1000000.0 10496.80859375
pred range: -523.1317749023438 6.618743896484375
mask valid positions: 26581.0 / 65536

[batch 120] loss=9.569853e+08 loss_diff=9.491292e-01 recon=9.569853e+08
obs_tick range: -0.9993910789489746 387100.0  next_tick range: -1.0 386200.0
normed next range: -1000000.0 3318.6513671875
pred range: -524.4740600585938 7.07120943069458
mask valid positions: 44417.0 / 65536

>>> Gradient explosion detected, grad_norm= 6427913.890166017
[batch 130] loss=4.576373e+08 loss_diff=9.759050e-01 recon=4.576373e+08
obs_tick range: -1.0 394000.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 1024.8662109375
pred range: -525.5941772460938 8.110745429992676
mask valid positions: 48232.0 / 65536

[batch 140] loss=7.740982e+08 loss_diff=9.561053e-01 recon=7.740982e+08
obs_tick range: -0.9848072528839111 375000.0  next_tick range: -0.9848076701164246 378400.0
normed next range: -1000000.0 19321.07421875
pred range: -526.4686889648438 8.47614860534668
mask valid positions: 26517.0 / 65536

[batch 150] loss=6.294780e+08 loss_diff=1.036783e+00 recon=6.294780e+08
obs_tick range: -0.999048113822937 565000.0  next_tick range: -0.9961913228034973 379500.0
normed next range: -1000000.0 3112.489990234375
pred range: -527.6869506835938 8.32888412475586
mask valid positions: 50214.0 / 65536

==============================
[2015-04][Epoch 3/20] | Time = 5.82 min
 - Total Loss : 1475894313.173007 | Recon Loss: 1475894313.112745 | Diff Loss: 0.928372
==============================
No improvement count: 3
[batch 0] loss=1.356515e+09 loss_diff=9.914634e-01 recon=1.356515e+09
obs_tick range: -0.9993934631347656 371000.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 8415.6259765625
pred range: -528.4070434570312 8.851961135864258
mask valid positions: 52357.0 / 65536

[batch 10] loss=1.204643e+09 loss_diff=9.677088e-01 recon=1.204643e+09
obs_tick range: -1.0 391500.0  next_tick range: -1.0 392100.0
normed next range: -1000000.0 22950.1796875
pred range: -529.7994384765625 14.552316665649414
mask valid positions: 44633.0 / 65536

[batch 20] loss=1.815209e+09 loss_diff=9.251568e-01 recon=1.815209e+09
obs_tick range: -0.9914447665214539 327000.0  next_tick range: -0.9961902499198914 371500.0
normed next range: -1000000.0 16874.015625
pred range: -531.3428955078125 6.954151153564453
mask valid positions: 35423.0 / 65536

[batch 30] loss=3.109042e+08 loss_diff=8.991941e-01 recon=3.109042e+08
obs_tick range: -1.0 362800.0  next_tick range: -1.0 361400.0
normed next range: -1000000.0 1000000.0
pred range: -532.8616333007812 6.9189934730529785
mask valid positions: 49676.0 / 65536

[batch 40] loss=2.812684e+08 loss_diff=9.562082e-01 recon=2.812684e+08
obs_tick range: -1.0 374400.0  next_tick range: -0.999048113822937 375100.0
normed next range: -1000000.0 818.6161499023438
pred range: -534.0714111328125 8.812742233276367
mask valid positions: 49414.0 / 65536

[batch 50] loss=1.111650e+09 loss_diff=1.014792e+00 recon=1.111650e+09
obs_tick range: -0.9969227910041809 366900.0  next_tick range: -0.9995337724685669 367000.0
normed next range: -1000000.0 5611.5400390625
pred range: -535.2587280273438 7.092027187347412
mask valid positions: 37091.0 / 65536

[batch 60] loss=2.164492e+09 loss_diff=9.749427e-01 recon=2.164492e+09
obs_tick range: -0.9914442896842957 367000.0  next_tick range: -0.9930698871612549 871959.0
normed next range: -1000000.0 2922.123291015625
pred range: -536.6974487304688 8.392829895019531
mask valid positions: 36462.0 / 65536

[batch 70] loss=1.313234e+09 loss_diff=9.442397e-01 recon=1.313234e+09
obs_tick range: -0.9993922710418701 371500.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 10813.685546875
pred range: -538.1045532226562 11.643153190612793
mask valid positions: 29876.0 / 65536

[batch 80] loss=3.649083e+08 loss_diff=9.562567e-01 recon=3.649083e+08
obs_tick range: -1.0 378500.0  next_tick range: -1.0 327100.0
normed next range: -1000000.0 4497.259765625
pred range: -539.509765625 7.082315444946289
mask valid positions: 42568.0 / 65536

[batch 90] loss=2.591728e+09 loss_diff=9.281685e-01 recon=2.591728e+09
obs_tick range: -0.9972280859947205 327000.0  next_tick range: -0.9993917942047119 357600.0
normed next range: -1000000.0 4071.255615234375
pred range: -541.0053100585938 7.9163970947265625
mask valid positions: 44748.0 / 65536

[batch 100] loss=8.209297e+08 loss_diff=9.675153e-01 recon=8.209297e+08
obs_tick range: -1.0 392900.0  next_tick range: -1.0 393000.0
normed next range: -1000000.0 15035.4521484375
pred range: -542.732666015625 8.292789459228516
mask valid positions: 29208.0 / 65536

[batch 110] loss=6.569673e+08 loss_diff=1.004233e+00 recon=6.569673e+08
obs_tick range: -0.999048113822937 370000.0  next_tick range: -0.9961944222450256 378000.0
normed next range: -1000000.0 4087.425048828125
pred range: -544.1063232421875 8.795729637145996
mask valid positions: 42858.0 / 65536

>>> Gradient explosion detected, grad_norm= 1567733.231781451
[batch 120] loss=1.828634e+09 loss_diff=9.383823e-01 recon=1.828634e+09
obs_tick range: -1.0 375000.0  next_tick range: -0.999048113822937 367000.0
normed next range: -1000000.0 6323.763671875
pred range: -545.38720703125 12.22931957244873
mask valid positions: 43655.0 / 65536

[batch 130] loss=1.869280e+09 loss_diff=9.378551e-01 recon=1.869280e+09
obs_tick range: -1.0 378400.0  next_tick range: -0.9990472793579102 368400.0
normed next range: -1000000.0 3376.76416015625
pred range: -546.3633422851562 13.448336601257324
mask valid positions: 51985.0 / 65536

[batch 140] loss=2.414847e+09 loss_diff=9.904400e-01 recon=2.414847e+09
obs_tick range: -0.9961944222450256 374600.0  next_tick range: -0.9914448261260986 378000.0
normed next range: -1000000.0 1454.170166015625
pred range: -547.5416259765625 14.431049346923828
mask valid positions: 52538.0 / 65536

[batch 150] loss=7.686008e+08 loss_diff=9.915832e-01 recon=7.686008e+08
obs_tick range: -0.9927315711975098 367100.0  next_tick range: -0.9969200491905212 367100.0
normed next range: -1000000.0 3756.882080078125
pred range: -548.7169189453125 13.571968078613281
mask valid positions: 43368.0 / 65536

>>> Gradient explosion detected, grad_norm= 1403715.3859928155
==============================
[2015-04][Epoch 4/20] | Time = 5.80 min
 - Total Loss : 1641215864.364568 | Recon Loss: 1641215864.290374 | Diff Loss: 0.956948
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-04 completed in 23.04 min
[1] 2015-05 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-05 | file : news_20150531.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=5.697636e+08 loss_diff=9.815251e-01 recon=5.697636e+08
obs_tick range: -0.999048113822937 371500.0  next_tick range: -1.0 371000.0
normed next range: -1000000.0 5044.36181640625
pred range: -549.6192016601562 13.82052230834961
mask valid positions: 43837.0 / 65536

[batch 10] loss=6.389536e+08 loss_diff=9.396172e-01 recon=6.389536e+08
obs_tick range: -1.0 350000.0  next_tick range: -0.9993933439254761 367100.0
normed next range: -1000000.0 15873.8251953125
pred range: -550.762451171875 12.627899169921875
mask valid positions: 34541.0 / 65536

[batch 20] loss=7.744269e+08 loss_diff=9.010258e-01 recon=7.744269e+08
obs_tick range: -0.9990481734275818 367100.0  next_tick range: -1.0 367900.0
normed next range: -1000000.0 9407.4482421875
pred range: -551.780029296875 7.6375908851623535
mask valid positions: 35770.0 / 65536

[batch 30] loss=1.978943e+09 loss_diff=9.241476e-01 recon=1.978943e+09
obs_tick range: -0.9990478157997131 373700.0  next_tick range: -1.0 374000.0
normed next range: -1000000.0 3956.707275390625
pred range: -553.0866088867188 7.462691307067871
mask valid positions: 36162.0 / 65536

[batch 40] loss=2.033278e+09 loss_diff=9.663443e-01 recon=2.033278e+09
obs_tick range: -0.99144047498703 393600.0  next_tick range: -0.9848073720932007 395800.0
normed next range: -1000000.0 2932.994873046875
pred range: -554.421142578125 10.483169555664062
mask valid positions: 44486.0 / 65536

[batch 50] loss=1.851102e+09 loss_diff=9.744930e-01 recon=1.851102e+09
obs_tick range: -1.0 366100.0  next_tick range: -0.9990483522415161 367100.0
normed next range: -1000000.0 1642.263671875
pred range: -555.9089965820312 7.735858917236328
mask valid positions: 51121.0 / 65536

[batch 60] loss=1.796536e+09 loss_diff=1.008694e+00 recon=1.796536e+09
obs_tick range: -1.0 392500.0  next_tick range: -1.0 392300.0
normed next range: -1000000.0 13228.0771484375
pred range: -557.5106201171875 6.364472389221191
mask valid positions: 29016.0 / 65536

[batch 70] loss=2.939842e+08 loss_diff=9.240730e-01 recon=2.939842e+08
obs_tick range: -0.9396913647651672 365000.0  next_tick range: -0.9537087678909302 330700.0
normed next range: -1000000.0 1000000.0
pred range: -559.0823364257812 6.38246488571167
mask valid positions: 33684.0 / 65536

[batch 80] loss=1.996125e+09 loss_diff=9.097116e-01 recon=1.996125e+09
obs_tick range: -1.0 375000.0  next_tick range: -1.0 348400.0
normed next range: -1000000.0 19719.671875
pred range: -560.4601440429688 6.418361663818359
mask valid positions: 30300.0 / 65536

[batch 90] loss=2.052770e+09 loss_diff=9.469303e-01 recon=2.052770e+09
obs_tick range: -1.0 373300.0  next_tick range: -1.0 365600.0
normed next range: -1000000.0 2268.8837890625
pred range: -561.8169555664062 9.392717361450195
mask valid positions: 45125.0 / 65536

[batch 100] loss=1.177352e+09 loss_diff=9.947838e-01 recon=1.177352e+09
obs_tick range: -0.9925494194030762 368000.0  next_tick range: -0.9969194531440735 322500.0
normed next range: -1000000.0 11580.8681640625
pred range: -563.2476196289062 6.564659118652344
mask valid positions: 29621.0 / 65536

[batch 110] loss=1.894522e+09 loss_diff=9.343227e-01 recon=1.894522e+09
obs_tick range: -0.9990481734275818 368900.0  next_tick range: -0.9961941242218018 365800.0
normed next range: -1000000.0 1697.178466796875
pred range: -564.3811645507812 12.8496675491333
mask valid positions: 43525.0 / 65536

[batch 120] loss=7.547295e+08 loss_diff=9.199720e-01 recon=7.547295e+08
obs_tick range: -0.991446316242218 370900.0  next_tick range: -0.9969179034233093 371200.0
normed next range: -1000000.0 2277.4990234375
pred range: -565.6771240234375 6.671440124511719
mask valid positions: 50662.0 / 65536

[batch 130] loss=2.090446e+09 loss_diff=9.658757e-01 recon=2.090446e+09
obs_tick range: -0.999048113822937 379600.0  next_tick range: -0.9961913228034973 379500.0
normed next range: -1000000.0 2080.199951171875
pred range: -567.2359008789062 6.6803693771362305
mask valid positions: 50871.0 / 65536

[batch 140] loss=1.043991e+09 loss_diff=9.223696e-01 recon=1.043991e+09
obs_tick range: -0.9969200491905212 375000.0  next_tick range: -0.9992408752441406 367100.0
normed next range: -1000000.0 3300.065185546875
pred range: -568.6517333984375 6.711872100830078
mask valid positions: 36188.0 / 65536

>>> Gradient explosion detected, grad_norm= 1914526.4554252515
[batch 150] loss=7.907421e+08 loss_diff=9.450977e-01 recon=7.907421e+08
obs_tick range: -0.9855577349662781 368700.0  next_tick range: -0.9914466738700867 368700.0
normed next range: -1000000.0 16947.51953125
pred range: -570.1348266601562 6.934903621673584
mask valid positions: 29747.0 / 65536

==============================
[2015-05][Epoch 1/20] | Time = 5.36 min
 - Total Loss : 1597858344.462540 | Recon Loss: 1597858344.395089 | Diff Loss: 0.939278
==============================
No improvement count: 1
[batch 0] loss=2.431139e+09 loss_diff=8.981214e-01 recon=2.431139e+09
obs_tick range: -1.0 381500.0  next_tick range: -1.0 380800.0
normed next range: -1000000.0 3428.40234375
pred range: -571.0912475585938 6.858983993530273
mask valid positions: 44227.0 / 65536

[batch 10] loss=8.765131e+08 loss_diff=8.920622e-01 recon=8.765131e+08
obs_tick range: -0.9961950778961182 367100.0  next_tick range: -0.9990483522415161 375000.0
normed next range: -1000000.0 8154.85595703125
pred range: -572.3710327148438 7.10336971282959
mask valid positions: 29012.0 / 65536

[batch 20] loss=2.024951e+09 loss_diff=9.507037e-01 recon=2.024951e+09
obs_tick range: -0.9990478157997131 376800.0  next_tick range: -1.0 375100.0
normed next range: -1000000.0 4700.25244140625
pred range: -573.97412109375 8.80519962310791
mask valid positions: 29464.0 / 65536

[batch 30] loss=2.330273e+09 loss_diff=9.136943e-01 recon=2.330273e+09
obs_tick range: -0.999048113822937 366200.0  next_tick range: -1.0 366400.0
normed next range: -1000000.0 1335.727294921875
pred range: -575.6140747070312 6.773842811584473
mask valid positions: 52415.0 / 65536

[batch 40] loss=5.300372e+08 loss_diff=9.144229e-01 recon=5.300372e+08
obs_tick range: -0.9848023653030396 392500.0  next_tick range: -0.9762857556343079 392300.0
normed next range: -1000000.0 2040.3223876953125
pred range: -577.1146240234375 8.107912063598633
mask valid positions: 42497.0 / 65536

>>> Gradient explosion detected, grad_norm= 1419602.7298909451
>>> Gradient explosion detected, grad_norm= 2057389.5068971487
>>> Gradient explosion detected, grad_norm= 2375565.432611178
[batch 50] loss=4.554981e+08 loss_diff=8.886355e-01 recon=4.554981e+08
obs_tick range: -0.9925476908683777 392000.0  next_tick range: -0.9961950778961182 393600.0
normed next range: -1000000.0 3172.078369140625
pred range: -577.9627075195312 21.168066024780273
mask valid positions: 48049.0 / 65536

>>> Gradient explosion detected, grad_norm= 15578305.23701215
[batch 60] loss=4.175086e+08 loss_diff=8.918317e-01 recon=4.175086e+08
obs_tick range: -0.9990479350090027 393700.0  next_tick range: -0.99619460105896 392700.0
normed next range: -1000000.0 6074.6181640625
pred range: -578.3126220703125 20.800809860229492
mask valid positions: 50244.0 / 65536

>>> Gradient explosion detected, grad_norm= 13269938.488488123
>>> Gradient explosion detected, grad_norm= 3121764.5280613923
[batch 70] loss=4.046371e+08 loss_diff=9.596088e-01 recon=4.046371e+08
obs_tick range: -0.9762951135635376 392900.0  next_tick range: -0.984807014465332 393000.0
normed next range: -1000000.0 2593.5927734375
pred range: -579.0603637695312 63.43613815307617
mask valid positions: 49598.0 / 65536

>>> Gradient explosion detected, grad_norm= 4940900.056969219
>>> Gradient explosion detected, grad_norm= 1156745.1975815038
>>> Gradient explosion detected, grad_norm= 2333731.080011734
>>> Gradient explosion detected, grad_norm= 19203750.31016019
>>> Gradient explosion detected, grad_norm= 6386402.740418856
[batch 80] loss=1.836366e+09 loss_diff=9.444193e-01 recon=1.836366e+09
obs_tick range: -0.9961944818496704 393000.0  next_tick range: -0.9914446473121643 392900.0
normed next range: -1000000.0 7669.44775390625
pred range: -579.54345703125 43.7205810546875
mask valid positions: 36347.0 / 65536

>>> Gradient explosion detected, grad_norm= 4301212.117623194
>>> Gradient explosion detected, grad_norm= 5739849.068538779
>>> Gradient explosion detected, grad_norm= 1728970.7222802353
[batch 90] loss=1.757836e+09 loss_diff=9.408281e-01 recon=1.757836e+09
obs_tick range: -0.9914393424987793 375000.0  next_tick range: -0.9961913824081421 378400.0
normed next range: -1000000.0 2100.359130859375
pred range: -580.0611572265625 29.54876708984375
mask valid positions: 50833.0 / 65536

[batch 100] loss=8.361540e+08 loss_diff=9.078118e-01 recon=8.361540e+08
obs_tick range: -1.0 370200.0  next_tick range: -0.9990472793579102 370200.0
normed next range: -1000000.0 50367.5
pred range: -580.7221069335938 68.38356018066406
mask valid positions: 36382.0 / 65536

>>> Gradient explosion detected, grad_norm= 1032153.1955161314
[batch 110] loss=4.680988e+08 loss_diff=9.486833e-01 recon=4.680988e+08
obs_tick range: -1.0 371500.0  next_tick range: -1.0 371000.0
normed next range: -1000000.0 7070.00244140625
pred range: -581.2103881835938 61.56618118286133
mask valid positions: 50828.0 / 65536

[batch 120] loss=7.500019e+08 loss_diff=9.411192e-01 recon=7.500019e+08
obs_tick range: -0.9848073720932007 367200.0  next_tick range: -0.9762940406799316 367000.0
normed next range: -1000000.0 3767.81640625
pred range: -582.0135498046875 62.885902404785156
mask valid positions: 43104.0 / 65536

>>> Gradient explosion detected, grad_norm= 3072919.029795869
>>> Gradient explosion detected, grad_norm= 1368736.7972773653
>>> Gradient explosion detected, grad_norm= 27483578.404118247
[batch 130] loss=5.221490e+09 loss_diff=8.891585e-01 recon=5.221490e+09
obs_tick range: -1.0 365100.0  next_tick range: -0.9659244418144226 365500.0
normed next range: -1000000.0 881.55419921875
pred range: -582.7833251953125 26.977230072021484
mask valid positions: 51352.0 / 65536

>>> Gradient explosion detected, grad_norm= 15005569.074385863
>>> Gradient explosion detected, grad_norm= 2692376.252387328
>>> Gradient explosion detected, grad_norm= 1035648.5710435429
[batch 140] loss=2.022605e+09 loss_diff=9.963996e-01 recon=2.022605e+09
obs_tick range: -0.9994773268699646 368500.0  next_tick range: -1.0 363300.0
normed next range: -1000000.0 1000000.0
pred range: -583.3364868164062 21.09906005859375
mask valid positions: 16118.0 / 65536

[batch 150] loss=1.986991e+03 loss_diff=9.062473e-01 recon=1.986085e+03
obs_tick range: -0.9914445877075195 396000.0  next_tick range: -0.9961943030357361 395700.0
normed next range: -7.1889190673828125 19693.396484375
pred range: -581.1932373046875 17.131044387817383
mask valid positions: 36181.0 / 65536

>>> Gradient explosion detected, grad_norm= 1128702.9383399026
==============================
[2015-05][Epoch 2/20] | Time = 5.63 min
 - Total Loss : 1449049773.019950 | Recon Loss: 1449049772.948715 | Diff Loss: 0.929005
==============================
No improvement count: 2
[batch 0] loss=2.511409e+09 loss_diff=9.947135e-01 recon=2.511409e+09
obs_tick range: -0.9914444088935852 218900.0  next_tick range: -0.9961945414543152 378000.0
normed next range: -1000000.0 3984.827880859375
pred range: -584.9207763671875 37.487735748291016
mask valid positions: 43934.0 / 65536

>>> Gradient explosion detected, grad_norm= 3726384.8540485785
[batch 10] loss=7.511985e+08 loss_diff=8.646029e-01 recon=7.511985e+08
obs_tick range: -1.0 394000.0  next_tick range: -0.9862880110740662 378400.0
normed next range: -1000000.0 7372.6943359375
pred range: -585.9788208007812 47.63236999511719
mask valid positions: 35903.0 / 65536

>>> Gradient explosion detected, grad_norm= 2858294.8693791046
>>> Gradient explosion detected, grad_norm= 2620008.733956187
[batch 20] loss=1.532354e+09 loss_diff=8.826882e-01 recon=1.532354e+09
obs_tick range: -0.9990481734275818 367400.0  next_tick range: -0.9961941242218018 367200.0
normed next range: -1000000.0 3109.49755859375
pred range: -586.6751098632812 25.536399841308594
mask valid positions: 56668.0 / 65536

>>> Gradient explosion detected, grad_norm= 7993479.418393471
>>> Gradient explosion detected, grad_norm= 8966398.154192848
>>> Gradient explosion detected, grad_norm= 3031444.3156169686
>>> Gradient explosion detected, grad_norm= 1270265.7159743768
>>> Gradient explosion detected, grad_norm= 8376472.169879269
>>> Gradient explosion detected, grad_norm= 1309000.1692482696
[batch 30] loss=6.011526e+08 loss_diff=9.236435e-01 recon=6.011526e+08
obs_tick range: -0.999048113822937 366200.0  next_tick range: -1.0 361000.0
normed next range: -1000000.0 7038.2734375
pred range: -586.8986206054688 22.222213745117188
mask valid positions: 56798.0 / 65536

>>> Gradient explosion detected, grad_norm= 21709207.169575732
>>> Gradient explosion detected, grad_norm= 9032799.115075935
[batch 40] loss=3.716277e+08 loss_diff=8.708821e-01 recon=3.716277e+08
obs_tick range: -1.0 349000.0  next_tick range: -0.991443932056427 349200.0
normed next range: -1000000.0 2804.072998046875
pred range: -587.5859375 23.66280746459961
mask valid positions: 50093.0 / 65536

>>> Gradient explosion detected, grad_norm= 11628480.03074845
>>> Gradient explosion detected, grad_norm= 1177504.5558480378
[batch 50] loss=9.315096e+08 loss_diff=8.839085e-01 recon=9.315096e+08
obs_tick range: -0.9993915557861328 335500.0  next_tick range: -1.0 335600.0
normed next range: -1000000.0 5754.35009765625
pred range: -588.2620239257812 23.826505661010742
mask valid positions: 38116.0 / 65536

>>> Gradient explosion detected, grad_norm= 107661828.9802826
>>> Gradient explosion detected, grad_norm= 3141994.5776642775
>>> Gradient explosion detected, grad_norm= 1433601.5969150504
>>> Gradient explosion detected, grad_norm= 1964294.9549774344
>>> Gradient explosion detected, grad_norm= 1072154.0274681079
[batch 60] loss=4.294807e+08 loss_diff=8.660284e-01 recon=4.294807e+08
obs_tick range: -0.9990483522415161 367500.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 5858.02734375
pred range: -588.6226196289062 31.87421226501465
mask valid positions: 22624.0 / 65536

>>> Gradient explosion detected, grad_norm= 1238374.8306952354
[batch 70] loss=1.781800e+09 loss_diff=9.603776e-01 recon=1.781800e+09
obs_tick range: -0.999048113822937 381500.0  next_tick range: -1.0 380800.0
normed next range: -1000000.0 4427.82373046875
pred range: -588.8424682617188 44.10083770751953
mask valid positions: 44389.0 / 65536

>>> Gradient explosion detected, grad_norm= 1007239.0166633975
[batch 80] loss=1.597785e+02 loss_diff=9.389096e-01 recon=1.588396e+02
obs_tick range: -0.9914448261260986 343800.0  next_tick range: -0.9848060607910156 375000.0
normed next range: -4.500514507293701 2578.375
pred range: -585.8773193359375 13.77349853515625
mask valid positions: 34506.0 / 65536

>>> Gradient explosion detected, grad_norm= 1257550.8403342322
[batch 90] loss=1.810463e+09 loss_diff=9.138541e-01 recon=1.810463e+09
obs_tick range: -0.999048113822937 365000.0  next_tick range: -1.0 366400.0
normed next range: -1000000.0 2651.261962890625
pred range: -590.3939208984375 70.67583465576172
mask valid positions: 51964.0 / 65536

[batch 100] loss=1.302006e+09 loss_diff=8.909976e-01 recon=1.302006e+09
obs_tick range: -0.9659208655357361 361900.0  next_tick range: -0.9762956500053406 362300.0
normed next range: -1000000.0 2802.883056640625
pred range: -591.1732788085938 74.772216796875
mask valid positions: 50982.0 / 65536

>>> Gradient explosion detected, grad_norm= 16665805.665281892
>>> Gradient explosion detected, grad_norm= 3719277.7458925066
>>> Gradient explosion detected, grad_norm= 17045531.127043486
>>> Gradient explosion detected, grad_norm= 4780482.184819668
[batch 110] loss=5.490004e+08 loss_diff=9.029281e-01 recon=5.490004e+08
obs_tick range: -0.991442084312439 366100.0  next_tick range: -0.996194064617157 365600.0
normed next range: -1000000.0 5654.71435546875
pred range: -591.8345947265625 55.33852005004883
mask valid positions: 35397.0 / 65536

>>> Gradient explosion detected, grad_norm= 185013964.54548353
>>> Gradient explosion detected, grad_norm= 9245089.770153293
>>> Gradient explosion detected, grad_norm= 17094685.95683214
[batch 120] loss=5.872691e+08 loss_diff=9.726344e-01 recon=5.872691e+08
obs_tick range: -0.9848073720932007 368900.0  next_tick range: -0.9762940406799316 357400.0
normed next range: -1000000.0 3590.6904296875
pred range: -591.6589965820312 24.566707611083984
mask valid positions: 36028.0 / 65536

>>> Gradient explosion detected, grad_norm= 65563016.205625005
>>> Gradient explosion detected, grad_norm= 12288492.988177156
>>> Gradient explosion detected, grad_norm= 1214907.0025783412
>>> Gradient explosion detected, grad_norm= 2849949.4571811664
[batch 130] loss=1.713355e+09 loss_diff=9.209465e-01 recon=1.713355e+09
obs_tick range: -1.0 379300.0  next_tick range: -1.0 379000.0
normed next range: -1000000.0 5044.36181640625
pred range: -592.535400390625 25.315950393676758
mask valid positions: 43940.0 / 65536

>>> Gradient explosion detected, grad_norm= 6011232.104982517
>>> Gradient explosion detected, grad_norm= 1796296.3376988333
>>> Gradient explosion detected, grad_norm= 2578522.815222265
>>> Gradient explosion detected, grad_norm= 3294666.755779177
>>> Gradient explosion detected, grad_norm= 2064278.2518862493
>>> Gradient explosion detected, grad_norm= 1367076.355275635
>>> Gradient explosion detected, grad_norm= 4362025.229378701
>>> Gradient explosion detected, grad_norm= 13024202.532797175
[batch 140] loss=8.202371e+02 loss_diff=9.396462e-01 recon=8.192974e+02
obs_tick range: -0.9994773268699646 365600.0  next_tick range: -1.0 363800.0
normed next range: -6.126928806304932 11113.2763671875
pred range: -37.994441986083984 12.535623550415039
mask valid positions: 44326.0 / 65536

>>> Gradient explosion detected, grad_norm= 30815781.401186384
>>> Gradient explosion detected, grad_norm= 1052185.9029891973
[batch 150] loss=2.033848e+09 loss_diff=9.475506e-01 recon=2.033848e+09
obs_tick range: -1.0 366200.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 1720.1669921875
pred range: -592.310546875 24.388492584228516
mask valid positions: 58401.0 / 65536

>>> Gradient explosion detected, grad_norm= 110666451.95072354
==============================
[2015-05][Epoch 3/20] | Time = 5.63 min
 - Total Loss : 1615164730.310635 | Recon Loss: 1615164730.245026 | Diff Loss: 0.925989
==============================
No improvement count: 3
[batch 0] loss=5.962446e+02 loss_diff=9.177535e-01 recon=5.953269e+02
obs_tick range: -0.9995337724685669 363200.0  next_tick range: -1.0 228600.0
normed next range: -4.513599872589111 7992.17041015625
pred range: -106.18849182128906 13.91380786895752
mask valid positions: 36452.0 / 65536

[batch 10] loss=1.404017e+09 loss_diff=9.784248e-01 recon=1.404017e+09
obs_tick range: -0.996194064617157 363400.0  next_tick range: -0.999048113822937 343800.0
normed next range: -1000000.0 3239.28662109375
pred range: -593.0008544921875 52.744014739990234
mask valid positions: 44756.0 / 65536

[batch 20] loss=1.355347e+09 loss_diff=9.271085e-01 recon=1.355347e+09
obs_tick range: -0.9961943626403809 365000.0  next_tick range: -0.9927315711975098 368900.0
normed next range: -1000000.0 4471.5537109375
pred range: -594.0110473632812 61.81440734863281
mask valid positions: 37452.0 / 65536

[batch 30] loss=3.299806e+08 loss_diff=9.602365e-01 recon=3.299806e+08
obs_tick range: -1.0 395000.0  next_tick range: -1.0 394800.0
normed next range: -1000000.0 9416.16015625
pred range: -594.82958984375 63.61329650878906
mask valid positions: 57516.0 / 65536

>>> Gradient explosion detected, grad_norm= 3030368.9926011804
[batch 40] loss=1.890798e+09 loss_diff=9.630353e-01 recon=1.890798e+09
obs_tick range: -1.0 379300.0  next_tick range: -1.0 379000.0
normed next range: -1000000.0 2154.256103515625
pred range: -595.6815795898438 57.12193298339844
mask valid positions: 52155.0 / 65536

>>> Gradient explosion detected, grad_norm= 4607235.274284747
[batch 50] loss=1.104444e+02 loss_diff=8.953330e-01 recon=1.095490e+02
obs_tick range: -0.9961944818496704 366200.0  next_tick range: -0.9914442896842957 367500.0
normed next range: -2.474870204925537 2337.129150390625
pred range: -29.55524253845215 22.436920166015625
mask valid positions: 42807.0 / 65536

[batch 60] loss=1.502330e+09 loss_diff=8.789712e-01 recon=1.502330e+09
obs_tick range: -1.0 392600.0  next_tick range: -1.0 391500.0
normed next range: -1000000.0 41798.01171875
pred range: -597.565185546875 60.37313461303711
mask valid positions: 36084.0 / 65536

>>> Gradient explosion detected, grad_norm= 6332578.877330492
>>> Gradient explosion detected, grad_norm= 6194184.015337075
>>> Gradient explosion detected, grad_norm= 11896154.84198529
>>> Gradient explosion detected, grad_norm= 1065109.2254582967
[batch 70] loss=2.328941e+09 loss_diff=9.463385e-01 recon=2.328941e+09
obs_tick range: -0.99619460105896 375600.0  next_tick range: -0.9914447665214539 375100.0
normed next range: -1000000.0 7378.08154296875
pred range: -598.5986328125 26.651227951049805
mask valid positions: 29086.0 / 65536

[batch 80] loss=1.875898e+09 loss_diff=9.545501e-01 recon=1.875898e+09
obs_tick range: -0.978151261806488 369900.0  next_tick range: -0.9894740581512451 368500.0
normed next range: -1000000.0 3129.40673828125
pred range: -599.3225708007812 38.591861724853516
mask valid positions: 29818.0 / 65536

>>> Gradient explosion detected, grad_norm= 7023592.095865375
>>> Gradient explosion detected, grad_norm= 1113915.3634627261
>>> Gradient explosion detected, grad_norm= 1314090.7930841309
[batch 90] loss=1.567414e+09 loss_diff=9.749509e-01 recon=1.567414e+09
obs_tick range: -0.984804630279541 368000.0  next_tick range: -0.9762970209121704 375000.0
normed next range: -1000000.0 6478.49365234375
pred range: -599.668701171875 38.781951904296875
mask valid positions: 50981.0 / 65536

[batch 100] loss=3.117337e+08 loss_diff=9.165733e-01 recon=3.117337e+08
obs_tick range: -1.0 365000.0  next_tick range: -0.9993932247161865 375000.0
normed next range: -1000000.0 28061.859375
pred range: -600.4369506835938 38.14044952392578
mask valid positions: 43695.0 / 65536

>>> Gradient explosion detected, grad_norm= 3216466.759242654
>>> Gradient explosion detected, grad_norm= 1802442.1364758404
[batch 110] loss=2.038213e+09 loss_diff=9.506311e-01 recon=2.038213e+09
obs_tick range: -0.9993684887886047 3089266.0  next_tick range: -1.0 367000.0
normed next range: -1000000.0 23064.291015625
pred range: -601.4155883789062 48.35315704345703
mask valid positions: 44506.0 / 65536

[batch 120] loss=9.709344e+08 loss_diff=9.253305e-01 recon=9.709344e+08
obs_tick range: -0.9396884441375732 367900.0  next_tick range: -0.9267891645431519 375000.0
normed next range: -1000000.0 9393.41015625
pred range: -602.3560791015625 24.42681312561035
mask valid positions: 41057.0 / 65536

>>> Gradient explosion detected, grad_norm= 37723229.14236165
[batch 130] loss=2.250965e+09 loss_diff=9.218947e-01 recon=2.250965e+09
obs_tick range: -1.0 364300.0  next_tick range: -0.9990478157997131 366100.0
normed next range: -1000000.0 3702.5810546875
pred range: -603.2101440429688 35.705169677734375
mask valid positions: 51195.0 / 65536

>>> Gradient explosion detected, grad_norm= 6196395.8056251705
[batch 140] loss=6.296860e+08 loss_diff=9.265062e-01 recon=6.296860e+08
obs_tick range: -0.9961942434310913 373300.0  next_tick range: -0.9990478157997131 378000.0
normed next range: -1000000.0 13297.3193359375
pred range: -604.1029663085938 41.772621154785156
mask valid positions: 51050.0 / 65536

>>> Gradient explosion detected, grad_norm= 2860614.696439203
>>> Gradient explosion detected, grad_norm= 1351135.5998766203
>>> Gradient explosion detected, grad_norm= 1092203.583431806
[batch 150] loss=7.390143e+08 loss_diff=8.964490e-01 recon=7.390143e+08
obs_tick range: -1.0 369000.0  next_tick range: -1.0 368900.0
normed next range: -1000000.0 28352.455078125
pred range: -604.681640625 59.37748718261719
mask valid positions: 57628.0 / 65536

>>> Gradient explosion detected, grad_norm= 32779723.873928893
>>> Gradient explosion detected, grad_norm= 1797984.3234283668
==============================
[2015-05][Epoch 4/20] | Time = 5.63 min
 - Total Loss : 1451699404.282204 | Recon Loss: 1451699404.216180 | Diff Loss: 0.928613
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-05 completed in 22.25 min
[1] 2015-06 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-06 | file : news_20150630.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.051794e+09 loss_diff=9.168453e-01 recon=1.051794e+09
obs_tick range: -0.9914447069168091 375100.0  next_tick range: -0.9848074316978455 394000.0
normed next range: -1000000.0 3613.098388671875
pred range: -605.046875 49.000492095947266
mask valid positions: 43080.0 / 65536

[batch 10] loss=1.862877e+09 loss_diff=9.694726e-01 recon=1.862877e+09
obs_tick range: -0.9667929410934448 394500.0  next_tick range: -0.976296067237854 393300.0
normed next range: -1000000.0 3197.799072265625
pred range: -605.8186645507812 66.79412841796875
mask valid positions: 58005.0 / 65536

>>> Gradient explosion detected, grad_norm= 39268973.88475132
>>> Gradient explosion detected, grad_norm= 2466219.988549808
[batch 20] loss=1.017914e+09 loss_diff=8.736074e-01 recon=1.017914e+09
obs_tick range: -0.984803318977356 375000.0  next_tick range: -0.9914384484291077 369000.0
normed next range: -1000000.0 11981.8310546875
pred range: -606.7306518554688 58.20230484008789
mask valid positions: 50669.0 / 65536

>>> Gradient explosion detected, grad_norm= 1084486.173620468
[batch 30] loss=2.012186e+09 loss_diff=9.120485e-01 recon=2.012186e+09
obs_tick range: -0.9990479946136475 371400.0  next_tick range: -1.0 370900.0
normed next range: -1000000.0 3050.610107421875
pred range: -607.9924926757812 52.32569122314453
mask valid positions: 58259.0 / 65536

[batch 40] loss=9.161433e+08 loss_diff=9.124783e-01 recon=9.161433e+08
obs_tick range: -0.9990472793579102 392300.0  next_tick range: -1.0 392200.0
normed next range: -1000000.0 3647.173583984375
pred range: -609.0007934570312 55.60343933105469
mask valid positions: 34393.0 / 65536

>>> Gradient explosion detected, grad_norm= 3080645.8280502874
[batch 50] loss=6.200883e+02 loss_diff=9.394117e-01 recon=6.191489e+02
obs_tick range: -1.0 361300.0  next_tick range: -0.9990472793579102 363900.0
normed next range: -4.245338439941406 5795.81494140625
pred range: -27.73828887939453 13.423409461975098
mask valid positions: 35654.0 / 65536

[batch 60] loss=1.736445e+09 loss_diff=8.802446e-01 recon=1.736445e+09
obs_tick range: -0.9961943030357361 379500.0  next_tick range: -0.9914442896842957 379200.0
normed next range: -1000000.0 1679.62451171875
pred range: -611.0067749023438 59.50739669799805
mask valid positions: 58155.0 / 65536

>>> Gradient explosion detected, grad_norm= 1532658.5557347285
>>> Gradient explosion detected, grad_norm= 1284755.6863140964
[batch 70] loss=8.012669e+08 loss_diff=9.477290e-01 recon=8.012669e+08
obs_tick range: -0.9971959590911865 357400.0  next_tick range: -0.9994773268699646 384100.0
normed next range: -1000000.0 4798.0556640625
pred range: -611.8233642578125 22.056644439697266
mask valid positions: 36490.0 / 65536

>>> Gradient explosion detected, grad_norm= 1812871.7304814872
[batch 80] loss=1.481386e+10 loss_diff=8.989989e-01 recon=1.481386e+10
obs_tick range: -0.9914445877075195 396000.0  next_tick range: -0.9961943030357361 395700.0
normed next range: -1000000.0 1000000.0
pred range: -612.6458740234375 45.096435546875
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 61137952.89110702
>>> Gradient explosion detected, grad_norm= 9324590.36038542
>>> Gradient explosion detected, grad_norm= 1055494.5307391468
>>> Gradient explosion detected, grad_norm= 6778357.007292383
>>> Gradient explosion detected, grad_norm= 3779552.252881769
[batch 90] loss=1.531720e+09 loss_diff=8.909056e-01 recon=1.531720e+09
obs_tick range: -1.0 871959.0  next_tick range: -1.0 379000.0
normed next range: -1000000.0 1745.5172119140625
pred range: -613.3219604492188 28.63060760498047
mask valid positions: 51101.0 / 65536

>>> Gradient explosion detected, grad_norm= 2366645.348215969
>>> Gradient explosion detected, grad_norm= 2080769.0842961925
>>> Gradient explosion detected, grad_norm= 1230014.1204655136
>>> Gradient explosion detected, grad_norm= 1186313.7864589822
[batch 100] loss=1.578759e+09 loss_diff=8.936700e-01 recon=1.578759e+09
obs_tick range: -0.9267891645431519 368000.0  next_tick range: -0.942645788192749 368000.0
normed next range: -1000000.0 3863.635009765625
pred range: -614.0470581054688 24.683547973632812
mask valid positions: 28125.0 / 65536

>>> Gradient explosion detected, grad_norm= 1031529.6970616671
>>> Gradient explosion detected, grad_norm= 16135358.676189383
>>> Gradient explosion detected, grad_norm= 1826371.0906424697
[batch 110] loss=1.640854e+09 loss_diff=9.053414e-01 recon=1.640854e+09
obs_tick range: -0.9914469122886658 393000.0  next_tick range: -0.9969229698181152 392900.0
normed next range: -1000000.0 1303.35986328125
pred range: -614.47216796875 23.41265869140625
mask valid positions: 44547.0 / 65536

>>> Gradient explosion detected, grad_norm= 29556578.807309378
[batch 120] loss=1.684341e+09 loss_diff=8.586890e-01 recon=1.684341e+09
obs_tick range: -0.9848071336746216 365500.0  next_tick range: -0.9768896102905273 367300.0
normed next range: -1000000.0 19079.46484375
pred range: -615.3509521484375 22.021183013916016
mask valid positions: 50841.0 / 65536

>>> Gradient explosion detected, grad_norm= 5659712.423390469
[batch 130] loss=7.508374e+08 loss_diff=8.770710e-01 recon=7.508374e+08
obs_tick range: -1.0 367100.0  next_tick range: -0.9762955904006958 367900.0
normed next range: -1000000.0 1741.6478271484375
pred range: -616.2733154296875 22.96591567993164
mask valid positions: 42207.0 / 65536

[batch 140] loss=4.148760e+02 loss_diff=9.215971e-01 recon=4.139544e+02
obs_tick range: -1.0 365000.0  next_tick range: -1.0 375000.0
normed next range: -3.68705677986145 7816.103515625
pred range: -43.93016815185547 15.435432434082031
mask valid positions: 42885.0 / 65536

[batch 150] loss=4.800367e+08 loss_diff=8.865117e-01 recon=4.800367e+08
obs_tick range: -1.0 366400.0  next_tick range: -1.0 366100.0
normed next range: -1000000.0 5591.55908203125
pred range: -618.4322509765625 22.049226760864258
mask valid positions: 48803.0 / 65536

>>> Gradient explosion detected, grad_norm= 1664664.2154271682
==============================
[2015-06][Epoch 1/20] | Time = 5.63 min
 - Total Loss : 1482399185.779007 | Recon Loss: 1482399185.707172 | Diff Loss: 0.914280
==============================
No improvement count: 1
[batch 0] loss=5.701063e+08 loss_diff=9.128422e-01 recon=5.701063e+08
obs_tick range: -0.9961932897567749 392900.0  next_tick range: -0.9990479946136475 392200.0
normed next range: -1000000.0 1000000.0
pred range: -619.1646118164062 23.56480598449707
mask valid positions: 57978.0 / 65536

>>> Gradient explosion detected, grad_norm= 1725332.2614663371
[batch 10] loss=2.427406e+09 loss_diff=8.873478e-01 recon=2.427406e+09
obs_tick range: -0.9762945175170898 373700.0  next_tick range: -0.9848071932792664 375000.0
normed next range: -1000000.0 2485.391357421875
pred range: -620.01318359375 23.75044059753418
mask valid positions: 50767.0 / 65536

>>> Gradient explosion detected, grad_norm= 2672745.650290374
>>> Gradient explosion detected, grad_norm= 17517645.43626621
>>> Gradient explosion detected, grad_norm= 18363911.21615191
[batch 20] loss=2.040989e+09 loss_diff=8.750141e-01 recon=2.040989e+09
obs_tick range: -1.0 393600.0  next_tick range: -1.0 395000.0
normed next range: -1000000.0 4142.04833984375
pred range: -620.9021606445312 23.513179779052734
mask valid positions: 45738.0 / 65536

>>> Gradient explosion detected, grad_norm= 6628985.493359151
>>> Gradient explosion detected, grad_norm= 9864871.393117249
[batch 30] loss=6.220036e+08 loss_diff=8.912765e-01 recon=6.220036e+08
obs_tick range: -0.9762958884239197 349000.0  next_tick range: -0.984803318977356 395000.0
normed next range: -1000000.0 5044.36181640625
pred range: -621.293212890625 22.266639709472656
mask valid positions: 34452.0 / 65536

>>> Gradient explosion detected, grad_norm= 5080117.100165079
>>> Gradient explosion detected, grad_norm= 9025882.136966536
[batch 40] loss=1.198594e+03 loss_diff=9.137410e-01 recon=1.197680e+03
obs_tick range: -1.0 367200.0  next_tick range: -1.0 691449.0
normed next range: -3.7780871391296387 9427.4931640625
pred range: -74.98178100585938 12.748167991638184
mask valid positions: 29418.0 / 65536

>>> Gradient explosion detected, grad_norm= 1924291.079507204
>>> Gradient explosion detected, grad_norm= 1242039.4453598603
>>> Gradient explosion detected, grad_norm= 4302352.284890093
[batch 50] loss=3.513552e+08 loss_diff=8.799070e-01 recon=3.513552e+08
obs_tick range: -0.9990479946136475 360000.0  next_tick range: -0.9961945414543152 359000.0
normed next range: -1000000.0 2695.11669921875
pred range: -622.7286376953125 23.845874786376953
mask valid positions: 42901.0 / 65536

>>> Gradient explosion detected, grad_norm= 1675664.571599524
>>> Gradient explosion detected, grad_norm= 3593621.3943680017
>>> Gradient explosion detected, grad_norm= 2177578.3972203927
>>> Gradient explosion detected, grad_norm= 2359121.5597756025
[batch 60] loss=7.325357e+08 loss_diff=8.690680e-01 recon=7.325357e+08
obs_tick range: -1.0 391500.0  next_tick range: -1.0 390400.0
normed next range: -1000000.0 2785.459228515625
pred range: -623.4387817382812 24.4798583984375
mask valid positions: 43136.0 / 65536

>>> Gradient explosion detected, grad_norm= 101632784.60635807
[batch 70] loss=5.668983e+08 loss_diff=9.271533e-01 recon=5.668983e+08
obs_tick range: -0.9848069548606873 393700.0  next_tick range: -0.9781534671783447 392700.0
normed next range: -1000000.0 2324.81103515625
pred range: -622.4002075195312 20.2407283782959
mask valid positions: 50455.0 / 65536

>>> Gradient explosion detected, grad_norm= 96552402.38379608
[batch 80] loss=1.551060e+10 loss_diff=9.266175e-01 recon=1.551060e+10
obs_tick range: -0.9762857556343079 393000.0  next_tick range: -0.9762876033782959 393600.0
normed next range: -1000000.0 1000000.0
pred range: -623.6017456054688 24.853809356689453
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 95964235.1924062
>>> Gradient explosion detected, grad_norm= 14565253.283857103
[batch 90] loss=1.762775e+09 loss_diff=8.995985e-01 recon=1.762775e+09
obs_tick range: -0.9990478754043579 363200.0  next_tick range: -0.99921715259552 363300.0
normed next range: -1000000.0 3899.96923828125
pred range: -624.3110961914062 21.634037017822266
mask valid positions: 51101.0 / 65536

>>> Gradient explosion detected, grad_norm= 9033518.471712468
>>> Gradient explosion detected, grad_norm= 80957093.59916697
>>> Gradient explosion detected, grad_norm= 9700014.428156191
>>> Gradient explosion detected, grad_norm= 3696174.689151352
>>> Gradient explosion detected, grad_norm= 1815490.037855736
[batch 100] loss=2.089765e+09 loss_diff=8.589857e-01 recon=2.089765e+09
obs_tick range: -1.0 370000.0  next_tick range: -1.0 370000.0
normed next range: -1000000.0 2550.82861328125
pred range: -624.4407958984375 23.433252334594727
mask valid positions: 51316.0 / 65536

>>> Gradient explosion detected, grad_norm= 2081277.2595910912
>>> Gradient explosion detected, grad_norm= 1581129.07867825
>>> Gradient explosion detected, grad_norm= 1268987.738031027
[batch 110] loss=1.818538e+09 loss_diff=9.751524e-01 recon=1.818538e+09
obs_tick range: -0.999048113822937 368000.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 1652.1951904296875
pred range: -623.4318237304688 17.824092864990234
mask valid positions: 51688.0 / 65536

>>> Gradient explosion detected, grad_norm= 8500229.158939093
>>> Gradient explosion detected, grad_norm= 13830471.116551055
>>> Gradient explosion detected, grad_norm= 2588211.7847154234
>>> Gradient explosion detected, grad_norm= 3908104.635869951
>>> Gradient explosion detected, grad_norm= 3352706.6585881817
[batch 120] loss=1.572825e+09 loss_diff=9.056524e-01 recon=1.572825e+09
obs_tick range: -1.0 379300.0  next_tick range: -1.0 379000.0
normed next range: -1000000.0 4084.236328125
pred range: -624.3155517578125 22.765779495239258
mask valid positions: 50746.0 / 65536

>>> Gradient explosion detected, grad_norm= 9188282.955624329
>>> Gradient explosion detected, grad_norm= 2154283.416708666
[batch 130] loss=6.718472e+08 loss_diff=8.841808e-01 recon=6.718472e+08
obs_tick range: -0.992551326751709 371500.0  next_tick range: -0.996920645236969 371500.0
normed next range: -1000000.0 11192.3935546875
pred range: -625.423583984375 18.30113410949707
mask valid positions: 21625.0 / 65536

>>> Gradient explosion detected, grad_norm= 7003053.833169413
>>> Gradient explosion detected, grad_norm= 3410844.7166613596
[batch 140] loss=2.984000e+09 loss_diff=9.322249e-01 recon=2.984000e+09
obs_tick range: -0.9971959590911865 368000.0  next_tick range: -0.9994773268699646 370000.0
normed next range: -1000000.0 1000000.0
pred range: -626.3804321289062 22.17124366760254
mask valid positions: 36911.0 / 65536

>>> Gradient explosion detected, grad_norm= 4408777.73054766
>>> Gradient explosion detected, grad_norm= 19685787.753243174
>>> Gradient explosion detected, grad_norm= 8402380.93991859
>>> Gradient explosion detected, grad_norm= 3905299.454990924
[batch 150] loss=7.683219e+08 loss_diff=9.123234e-01 recon=7.683219e+08
obs_tick range: -0.9990484118461609 366200.0  next_tick range: -1.0 368500.0
normed next range: -1000000.0 8926.1884765625
pred range: -627.0001831054688 17.03820037841797
mask valid positions: 44440.0 / 65536

>>> Gradient explosion detected, grad_norm= 7914919.371433094
>>> Gradient explosion detected, grad_norm= 1969335.992317553
>>> Gradient explosion detected, grad_norm= 9805158.982969733
>>> Gradient explosion detected, grad_norm= 9372377.513911508
==============================
[2015-06][Epoch 2/20] | Time = 5.67 min
 - Total Loss : 1518851675.138805 | Recon Loss: 1518851675.069269 | Diff Loss: 0.910202
==============================
No improvement count: 2
[batch 0] loss=1.392715e+09 loss_diff=9.012586e-01 recon=1.392715e+09
obs_tick range: -0.9681811332702637 394500.0  next_tick range: -0.9781754612922668 393300.0
normed next range: -1000000.0 3226.055419921875
pred range: -627.3761596679688 19.24178695678711
mask valid positions: 41861.0 / 65536

>>> Gradient explosion detected, grad_norm= 7656617.055821095
[batch 10] loss=1.194048e+09 loss_diff=9.832305e-01 recon=1.194048e+09
obs_tick range: -0.999048113822937 367900.0  next_tick range: -1.0 367100.0
normed next range: -1000000.0 2428.266357421875
pred range: -628.2462158203125 19.879638671875
mask valid positions: 44409.0 / 65536

>>> Gradient explosion detected, grad_norm= 1298003.3648765
>>> Gradient explosion detected, grad_norm= 1956720.0234140186
>>> Gradient explosion detected, grad_norm= 5527862.1695020115
[batch 20] loss=1.111457e+09 loss_diff=9.068736e-01 recon=1.111457e+09
obs_tick range: -0.9790485501289368 394100.0  next_tick range: -0.9848079085350037 395000.0
normed next range: -1000000.0 4805.833984375
pred range: -629.1521606445312 18.099382400512695
mask valid positions: 43216.0 / 65536

>>> Gradient explosion detected, grad_norm= 8151138.52252354
>>> Gradient explosion detected, grad_norm= 1602160.838187219
>>> Gradient explosion detected, grad_norm= 18244864.983239993
[batch 30] loss=1.770690e+09 loss_diff=9.312722e-01 recon=1.770690e+09
obs_tick range: -0.999048113822937 379600.0  next_tick range: -0.9961913228034973 379500.0
normed next range: -1000000.0 3277.560302734375
pred range: -629.8822021484375 17.324403762817383
mask valid positions: 38049.0 / 65536

>>> Gradient explosion detected, grad_norm= 14093165.058711605
>>> Gradient explosion detected, grad_norm= 5551110.407506788
[batch 40] loss=2.474306e+09 loss_diff=8.818251e-01 recon=2.474306e+09
obs_tick range: -0.9862902164459229 371500.0  next_tick range: -0.9930831789970398 394000.0
normed next range: -1000000.0 2419.05029296875
pred range: -630.4553833007812 23.005434036254883
mask valid positions: 37395.0 / 65536

>>> Gradient explosion detected, grad_norm= 2548548.936769214
>>> Gradient explosion detected, grad_norm= 4756445.901959368
>>> Gradient explosion detected, grad_norm= 1124638.3850865366
>>> Gradient explosion detected, grad_norm= 3537403.8011285304
>>> Gradient explosion detected, grad_norm= 2346984.1817808347
[batch 50] loss=7.026463e+08 loss_diff=9.183277e-01 recon=7.026463e+08
obs_tick range: -0.99692302942276 372600.0  next_tick range: -0.9990484118461609 372600.0
normed next range: -1000000.0 2367.580322265625
pred range: -630.762451171875 17.017501831054688
mask valid positions: 43808.0 / 65536

[batch 60] loss=2.280974e+09 loss_diff=8.810124e-01 recon=2.280974e+09
obs_tick range: -1.0 323900.0  next_tick range: -1.0 378400.0
normed next range: -1000000.0 6507.09228515625
pred range: -631.5715942382812 20.469026565551758
mask valid positions: 36861.0 / 65536

>>> Gradient explosion detected, grad_norm= 1483818.916906453
>>> Gradient explosion detected, grad_norm= 3797488.7111679423
>>> Gradient explosion detected, grad_norm= 34748528.02456692
[batch 70] loss=1.101987e+09 loss_diff=8.768480e-01 recon=1.101987e+09
obs_tick range: -1.0 373300.0  next_tick range: -0.9990478157997131 368900.0
normed next range: -1000000.0 3072.267578125
pred range: -632.2801513671875 21.200151443481445
mask valid positions: 57182.0 / 65536

>>> Gradient explosion detected, grad_norm= 3309564.8923879755
[batch 80] loss=6.718568e+08 loss_diff=9.334788e-01 recon=6.718568e+08
obs_tick range: -0.9781534671783447 179254.0  next_tick range: -0.9862902164459229 368000.0
normed next range: -1000000.0 2478.912841796875
pred range: -633.048828125 21.340789794921875
mask valid positions: 42166.0 / 65536

>>> Gradient explosion detected, grad_norm= 2021700.3999275076
>>> Gradient explosion detected, grad_norm= 34336868.18556121
[batch 90] loss=1.153822e+09 loss_diff=9.016121e-01 recon=1.153822e+09
obs_tick range: -0.9990481734275818 394800.0  next_tick range: -0.999048113822937 393300.0
normed next range: -1000000.0 7101.689453125
pred range: -634.143798828125 20.434219360351562
mask valid positions: 51230.0 / 65536

[batch 100] loss=9.708865e+06 loss_diff=8.753955e-01 recon=9.708864e+06
obs_tick range: -0.9925552606582642 371700.0  next_tick range: -0.9961949586868286 373300.0
normed next range: -1000000.0 19321.07421875
pred range: -634.5762939453125 15.256576538085938
mask valid positions: 28091.0 / 65536

[batch 110] loss=9.282378e+08 loss_diff=9.654182e-01 recon=9.282378e+08
obs_tick range: -0.99921715259552 361800.0  next_tick range: -1.0 361700.0
normed next range: -1000000.0 6399.544921875
pred range: -636.2149047851562 16.143367767333984
mask valid positions: 29052.0 / 65536

>>> Gradient explosion detected, grad_norm= 3126103.1127389264
>>> Gradient explosion detected, grad_norm= 2480551.073056291
>>> Gradient explosion detected, grad_norm= 3885899.2264623363
[batch 120] loss=1.019989e+09 loss_diff=8.752815e-01 recon=1.019989e+09
obs_tick range: -0.9961928725242615 393300.0  next_tick range: -0.9914445281028748 393900.0
normed next range: -1000000.0 7830.97021484375
pred range: -637.347412109375 19.62638282775879
mask valid positions: 42641.0 / 65536

>>> Gradient explosion detected, grad_norm= 54456442.190772235
>>> Gradient explosion detected, grad_norm= 3196888.8646447607
[batch 130] loss=5.914802e+08 loss_diff=8.974470e-01 recon=5.914802e+08
obs_tick range: -1.0 565000.0  next_tick range: -1.0 392000.0
normed next range: -1000000.0 1315.1768798828125
pred range: -637.9671020507812 19.70763397216797
mask valid positions: 50505.0 / 65536

>>> Gradient explosion detected, grad_norm= 11952801.868954178
>>> Gradient explosion detected, grad_norm= 10552305.076082766
>>> Gradient explosion detected, grad_norm= 11330005.455652477
[batch 140] loss=2.287636e+08 loss_diff=9.224790e-01 recon=2.287636e+08
obs_tick range: -0.9271922707557678 331800.0  next_tick range: -0.9426490664482117 369000.0
normed next range: -1000000.0 1825.7216796875
pred range: -638.8168334960938 19.354040145874023
mask valid positions: 32549.0 / 65536

[batch 150] loss=4.532849e+08 loss_diff=9.242672e-01 recon=4.532849e+08
obs_tick range: -0.9930698871612549 371500.0  next_tick range: -0.9972502589225769 370000.0
normed next range: -1000000.0 7058.08154296875
pred range: -639.4362182617188 21.903549194335938
mask valid positions: 34454.0 / 65536

>>> Gradient explosion detected, grad_norm= 3040760.065511777
>>> Gradient explosion detected, grad_norm= 2187099.2070090217
==============================
[2015-06][Epoch 3/20] | Time = 5.67 min
 - Total Loss : 1706478186.060219 | Recon Loss: 1706478185.989328 | Diff Loss: 0.911668
==============================
No improvement count: 3
[batch 0] loss=1.401138e+09 loss_diff=8.386685e-01 recon=1.401138e+09
obs_tick range: -1.0 361000.0  next_tick range: -1.0 362000.0
normed next range: -1000000.0 2740.802490234375
pred range: -640.0679321289062 20.80834197998047
mask valid positions: 44844.0 / 65536

[batch 10] loss=8.321870e+08 loss_diff=8.971629e-01 recon=8.321870e+08
obs_tick range: -0.9762954115867615 380300.0  next_tick range: -0.9781502485275269 380000.0
normed next range: -1000000.0 2914.31982421875
pred range: -640.933837890625 18.671186447143555
mask valid positions: 43206.0 / 65536

>>> Gradient explosion detected, grad_norm= 4831026.279397479
>>> Gradient explosion detected, grad_norm= 2791538.459954082
>>> Gradient explosion detected, grad_norm= 2341225.412812279
[batch 20] loss=7.480435e+08 loss_diff=8.319639e-01 recon=7.480435e+08
obs_tick range: -0.9969179034233093 395000.0  next_tick range: -0.9993910789489746 378400.0
normed next range: -1000000.0 26880.3203125
pred range: -641.9113159179688 19.6666259765625
mask valid positions: 20635.0 / 65536

>>> Gradient explosion detected, grad_norm= 12772736.319970101
>>> Gradient explosion detected, grad_norm= 2714509.234330212
[batch 30] loss=1.199869e+09 loss_diff=8.678018e-01 recon=1.199869e+09
obs_tick range: -0.999048113822937 368800.0  next_tick range: -0.9961944818496704 344000.0
normed next range: -1000000.0 2757.806640625
pred range: -642.2265014648438 20.623016357421875
mask valid positions: 50625.0 / 65536

>>> Gradient explosion detected, grad_norm= 2289600.500355122
[batch 40] loss=1.144277e+09 loss_diff=9.357260e-01 recon=1.144277e+09
obs_tick range: -0.9914447665214539 367000.0  next_tick range: -0.9961923360824585 367000.0
normed next range: -1000000.0 9706.4931640625
pred range: -643.1887817382812 18.500205993652344
mask valid positions: 34834.0 / 65536

>>> Gradient explosion detected, grad_norm= 2584703.5821759915
>>> Gradient explosion detected, grad_norm= 1567144.459234454
>>> Gradient explosion detected, grad_norm= 2476296.2917302162
[batch 50] loss=1.438659e+10 loss_diff=9.232284e-01 recon=1.438659e+10
obs_tick range: -0.9914413094520569 361700.0  next_tick range: -0.9961941242218018 361400.0
normed next range: -1000000.0 1000000.0
pred range: -644.0958862304688 20.695613861083984
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 21809100.496162426
>>> Gradient explosion detected, grad_norm= 5029524.938910499
>>> Gradient explosion detected, grad_norm= 15144660.02344974
[batch 60] loss=1.254106e+09 loss_diff=9.549839e-01 recon=1.254106e+09
obs_tick range: -0.992551326751709 367200.0  next_tick range: -0.996920645236969 367000.0
normed next range: -1000000.0 18707.31640625
pred range: -643.5032348632812 16.672468185424805
mask valid positions: 36128.0 / 65536

>>> Gradient explosion detected, grad_norm= 1965482.8216201393
>>> Gradient explosion detected, grad_norm= 7191305.977714988
[batch 70] loss=2.465711e+09 loss_diff=8.989198e-01 recon=2.465711e+09
obs_tick range: -0.9969472289085388 396000.0  next_tick range: -0.9990483522415161 3089266.0
normed next range: -1000000.0 12168.1435546875
pred range: -645.2833862304688 18.797021865844727
mask valid positions: 29643.0 / 65536

[batch 80] loss=1.169588e+09 loss_diff=8.239997e-01 recon=1.169588e+09
obs_tick range: -0.9994773268699646 395000.0  next_tick range: -1.0 362800.0
normed next range: -1000000.0 5795.33203125
pred range: -645.7860107421875 16.07585906982422
mask valid positions: 51159.0 / 65536

>>> Gradient explosion detected, grad_norm= 1635293.1565262647
>>> Gradient explosion detected, grad_norm= 1532506.2961562634
[batch 90] loss=1.896657e+09 loss_diff=9.369951e-01 recon=1.896657e+09
obs_tick range: -1.0 368000.0  next_tick range: -0.999048113822937 365000.0
normed next range: -1000000.0 3313.340087890625
pred range: -646.7821044921875 15.754469871520996
mask valid positions: 43467.0 / 65536

>>> Gradient explosion detected, grad_norm= 5751798.051506984
>>> Gradient explosion detected, grad_norm= 4255646.44482609
>>> Gradient explosion detected, grad_norm= 14254312.504270134
[batch 100] loss=8.313020e+08 loss_diff=9.175147e-01 recon=8.313020e+08
obs_tick range: -0.9990481734275818 392700.0  next_tick range: -0.9961941242218018 392300.0
normed next range: -1000000.0 1000000.0
pred range: -647.5338134765625 16.078203201293945
mask valid positions: 43144.0 / 65536

[batch 110] loss=2.845082e+08 loss_diff=9.373558e-01 recon=2.845082e+08
obs_tick range: -0.9990483522415161 367500.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 64806.72265625
pred range: -648.4675903320312 15.254929542541504
mask valid positions: 22343.0 / 65536

>>> Gradient explosion detected, grad_norm= 5398900.282075774
>>> Gradient explosion detected, grad_norm= 6058443.6472193785
>>> Gradient explosion detected, grad_norm= 23574630.389574606
[batch 120] loss=4.290612e+08 loss_diff=9.346046e-01 recon=4.290612e+08
obs_tick range: -0.9993920922279358 368700.0  next_tick range: -1.0 368700.0
normed next range: -1000000.0 7478.89306640625
pred range: -648.9647216796875 15.725811958312988
mask valid positions: 35340.0 / 65536

>>> Gradient explosion detected, grad_norm= 6474683.739143021
>>> Gradient explosion detected, grad_norm= 2943781.2188388854
>>> Gradient explosion detected, grad_norm= 2028184.4227509426
>>> Gradient explosion detected, grad_norm= 1348631.035490871
[batch 130] loss=6.071127e+08 loss_diff=9.187832e-01 recon=6.071127e+08
obs_tick range: -1.0 382400.0  next_tick range: -1.0 381500.0
normed next range: -1000000.0 6678.01171875
pred range: -649.6825561523438 15.912978172302246
mask valid positions: 42923.0 / 65536

>>> Gradient explosion detected, grad_norm= 5581998.370329249
>>> Gradient explosion detected, grad_norm= 3546784.071792349
[batch 140] loss=1.489597e+09 loss_diff=8.781631e-01 recon=1.489597e+09
obs_tick range: -0.9961950778961182 368700.0  next_tick range: -0.9990483522415161 371500.0
normed next range: -1000000.0 3005.83447265625
pred range: -650.545166015625 20.590158462524414
mask valid positions: 38035.0 / 65536

>>> Gradient explosion detected, grad_norm= 2897857.269658415
>>> Gradient explosion detected, grad_norm= 2170847.1614925233
[batch 150] loss=1.430233e+09 loss_diff=9.409547e-01 recon=1.430233e+09
obs_tick range: -1.0 367900.0  next_tick range: -1.0 367100.0
normed next range: -1000000.0 2312.646484375
pred range: -651.1961669921875 21.973995208740234
mask valid positions: 43549.0 / 65536

>>> Gradient explosion detected, grad_norm= 2115541.3706029356
>>> Gradient explosion detected, grad_norm= 2514368.6787799317
==============================
[2015-06][Epoch 4/20] | Time = 5.72 min
 - Total Loss : 1451112280.345479 | Recon Loss: 1451112280.275231 | Diff Loss: 0.903184
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-06 completed in 22.70 min
[1] 2015-07 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-07 | file : news_20150731.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.196434e+09 loss_diff=8.632200e-01 recon=1.196434e+09
obs_tick range: -0.9992408752441406 366800.0  next_tick range: -1.0 366700.0
normed next range: -1000000.0 4637.14990234375
pred range: -651.8324584960938 21.241174697875977
mask valid positions: 42725.0 / 65536

>>> Gradient explosion detected, grad_norm= 4269470.150571784
>>> Gradient explosion detected, grad_norm= 9534661.976956563
>>> Gradient explosion detected, grad_norm= 4046217.507897653
[batch 10] loss=3.190338e+09 loss_diff=8.996083e-01 recon=3.190338e+09
obs_tick range: -0.9914448261260986 348400.0  next_tick range: -0.9914343357086182 349300.0
normed next range: -1000000.0 4675.19189453125
pred range: -652.4437866210938 20.11798858642578
mask valid positions: 58083.0 / 65536

>>> Gradient explosion detected, grad_norm= 11392313.980383934
[batch 20] loss=7.597384e+08 loss_diff=8.683754e-01 recon=7.597384e+08
obs_tick range: -1.0 393000.0  next_tick range: -1.0 392900.0
normed next range: -1000000.0 5611.5400390625
pred range: -652.865234375 19.514150619506836
mask valid positions: 36211.0 / 65536

[batch 30] loss=2.717631e+09 loss_diff=8.971015e-01 recon=2.717631e+09
obs_tick range: -1.0 366100.0  next_tick range: -1.0 365500.0
normed next range: -1000000.0 7687.54443359375
pred range: -653.8463745117188 15.290955543518066
mask valid positions: 51668.0 / 65536

>>> Gradient explosion detected, grad_norm= 10001255.891137214
>>> Gradient explosion detected, grad_norm= 9370349.5316795
>>> Gradient explosion detected, grad_norm= 13417244.21418259
>>> Gradient explosion detected, grad_norm= 6786196.957466823
[batch 40] loss=1.647544e+09 loss_diff=9.137751e-01 recon=1.647544e+09
obs_tick range: -0.9969179034233093 352500.0  next_tick range: -0.9993910789489746 378400.0
normed next range: -1000000.0 9565.0146484375
pred range: -654.47900390625 15.879966735839844
mask valid positions: 44032.0 / 65536

[batch 50] loss=1.881952e+08 loss_diff=9.284436e-01 recon=1.881952e+08
obs_tick range: -1.0 371500.0  next_tick range: -1.0 371500.0
normed next range: -1000000.0 4238.1171875
pred range: -655.3677368164062 22.019573211669922
mask valid positions: 36668.0 / 65536

>>> Gradient explosion detected, grad_norm= 2427528.1288129487
[batch 60] loss=5.662817e+08 loss_diff=9.492487e-01 recon=5.662817e+08
obs_tick range: -1.0 392600.0  next_tick range: -1.0 391500.0
normed next range: -1000000.0 8653.9140625
pred range: -656.71484375 21.285459518432617
mask valid positions: 43451.0 / 65536

>>> Gradient explosion detected, grad_norm= 5569964.795748194
[batch 70] loss=6.307492e+08 loss_diff=9.423258e-01 recon=6.307492e+08
obs_tick range: -1.0 366100.0  next_tick range: -0.9990472793579102 365800.0
normed next range: -1000000.0 4713.1015625
pred range: -658.3839111328125 20.620222091674805
mask valid positions: 43904.0 / 65536

>>> Gradient explosion detected, grad_norm= 8117296.045658288
[batch 80] loss=7.017610e+08 loss_diff=9.280165e-01 recon=7.017610e+08
obs_tick range: -0.9862902164459229 381500.0  next_tick range: -0.9930831789970398 380800.0
normed next range: -1000000.0 9779.412109375
pred range: -659.6234130859375 18.132221221923828
mask valid positions: 43861.0 / 65536

>>> Gradient explosion detected, grad_norm= 2747324.9237200273
>>> Gradient explosion detected, grad_norm= 2197198.344786719
[batch 90] loss=3.312806e+03 loss_diff=9.165341e-01 recon=3.311890e+03
obs_tick range: -1.0 373700.0  next_tick range: -1.0 375000.0
normed next range: -3.2104928493499756 14684.787109375
pred range: -517.8103637695312 13.452781677246094
mask valid positions: 21792.0 / 65536

>>> Gradient explosion detected, grad_norm= 4740062.797004357
[batch 100] loss=9.862443e+08 loss_diff=9.069778e-01 recon=9.862443e+08
obs_tick range: -0.99921715259552 366800.0  next_tick range: -1.0 366700.0
normed next range: -1000000.0 2137.21435546875
pred range: -661.7503662109375 17.062028884887695
mask valid positions: 55348.0 / 65536

>>> Gradient explosion detected, grad_norm= 3829412.849612874
>>> Gradient explosion detected, grad_norm= 1797870.492611546
>>> Gradient explosion detected, grad_norm= 3121575.4219187004
>>> Gradient explosion detected, grad_norm= 1030745.9168776214
>>> Gradient explosion detected, grad_norm= 1379653.8473763645
>>> Gradient explosion detected, grad_norm= 1495917.4864227066
>>> Gradient explosion detected, grad_norm= 1185595.5959892967
[batch 110] loss=5.376113e+08 loss_diff=8.798292e-01 recon=5.376113e+08
obs_tick range: -1.0 357600.0  next_tick range: -1.0 357900.0
normed next range: -1000000.0 6297.51708984375
pred range: -661.9271850585938 16.986740112304688
mask valid positions: 49822.0 / 65536

>>> Gradient explosion detected, grad_norm= 1641234.1650315518
[batch 120] loss=1.770522e+09 loss_diff=8.813515e-01 recon=1.770522e+09
obs_tick range: -1.0 365500.0  next_tick range: -0.9692352414131165 357400.0
normed next range: -1000000.0 14274.7294921875
pred range: -662.6544189453125 24.278318405151367
mask valid positions: 36255.0 / 65536

>>> Gradient explosion detected, grad_norm= 3538724.122134436
[batch 130] loss=8.124436e+08 loss_diff=9.091716e-01 recon=8.124436e+08
obs_tick range: -0.9961931705474854 365000.0  next_tick range: -0.9990481734275818 365000.0
normed next range: -1000000.0 3863.152099609375
pred range: -663.1898803710938 18.574771881103516
mask valid positions: 41685.0 / 65536

[batch 140] loss=2.101133e+09 loss_diff=9.301628e-01 recon=2.101133e+09
obs_tick range: -1.0 368400.0  next_tick range: -0.976296067237854 365000.0
normed next range: -1000000.0 10800.142578125
pred range: -664.2410278320312 17.58722686767578
mask valid positions: 50385.0 / 65536

>>> Gradient explosion detected, grad_norm= 12156612.05373511
>>> Gradient explosion detected, grad_norm= 1642633.0674121554
>>> Gradient explosion detected, grad_norm= 2383181.9701092415
[batch 150] loss=4.898781e+08 loss_diff=8.898742e-01 recon=4.898781e+08
obs_tick range: -0.9848074316978455 367300.0  next_tick range: -0.9762944579124451 352900.0
normed next range: -1000000.0 3863.63916015625
pred range: -665.2744750976562 16.38422203063965
mask valid positions: 34844.0 / 65536

>>> Gradient explosion detected, grad_norm= 4192425.964906649
==============================
[2015-07][Epoch 1/20] | Time = 5.41 min
 - Total Loss : 1295356140.010757 | Recon Loss: 1295356139.941663 | Diff Loss: 0.907425
==============================
No improvement count: 1
[batch 0] loss=6.091830e+08 loss_diff=8.706962e-01 recon=6.091830e+08
obs_tick range: -1.0 368000.0  next_tick range: -0.9993684887886047 366100.0
normed next range: -1000000.0 8880.275390625
pred range: -665.7490844726562 19.279361724853516
mask valid positions: 35621.0 / 65536

[batch 10] loss=1.504233e+09 loss_diff=9.466577e-01 recon=1.504233e+09
obs_tick range: -0.9848071336746216 375000.0  next_tick range: -0.9787248969078064 375500.0
normed next range: -1000000.0 5019.48974609375
pred range: -666.8631591796875 23.29706573486328
mask valid positions: 21910.0 / 65536

>>> Gradient explosion detected, grad_norm= 2366610.4705889462
>>> Gradient explosion detected, grad_norm= 2373188.69928709
[batch 20] loss=3.905096e+08 loss_diff=8.933361e-01 recon=3.905096e+08
obs_tick range: -0.9426509141921997 395000.0  next_tick range: -0.9563833475112915 395000.0
normed next range: -1000000.0 2527.549560546875
pred range: -668.0607299804688 20.727258682250977
mask valid positions: 36270.0 / 65536

>>> Gradient explosion detected, grad_norm= 2585311.6258705114
>>> Gradient explosion detected, grad_norm= 32883928.513088774
>>> Gradient explosion detected, grad_norm= 1462293.5330908583
>>> Gradient explosion detected, grad_norm= 2320240.155676501
>>> Gradient explosion detected, grad_norm= 4564758.965916448
[batch 30] loss=2.008982e+09 loss_diff=9.607236e-01 recon=2.008982e+09
obs_tick range: -0.9990479946136475 364200.0  next_tick range: -1.0 586459.0
normed next range: -1000000.0 13854.10546875
pred range: -669.1622924804688 13.844490051269531
mask valid positions: 51159.0 / 65536

>>> Gradient explosion detected, grad_norm= 4570206.37220274
>>> Gradient explosion detected, grad_norm= 1814301.9360556186
[batch 40] loss=2.481873e+09 loss_diff=9.493442e-01 recon=2.481873e+09
obs_tick range: -1.0 650000.0  next_tick range: -0.9990472793579102 371200.0
normed next range: -1000000.0 6998.36376953125
pred range: -669.2981567382812 13.144848823547363
mask valid positions: 50411.0 / 65536

>>> Gradient explosion detected, grad_norm= 2666744.800878875
[batch 50] loss=6.751185e+08 loss_diff=9.171558e-01 recon=6.751185e+08
obs_tick range: -0.9762949347496033 500000.0  next_tick range: -0.9659258127212524 367000.0
normed next range: -1000000.0 5744.09326171875
pred range: -670.256591796875 13.019837379455566
mask valid positions: 40345.0 / 65536

>>> Gradient explosion detected, grad_norm= 2389152.9575443217
>>> Gradient explosion detected, grad_norm= 2922871.606171886
>>> Gradient explosion detected, grad_norm= 2718825.245176638
[batch 60] loss=2.041548e+09 loss_diff=8.733187e-01 recon=2.041548e+09
obs_tick range: -0.986307680606842 368900.0  next_tick range: -0.9914457201957703 332400.0
normed next range: -1000000.0 5461.65185546875
pred range: -671.1851196289062 15.404443740844727
mask valid positions: 36646.0 / 65536

>>> Gradient explosion detected, grad_norm= 7706381.377434586
>>> Gradient explosion detected, grad_norm= 3660197.7850029
>>> Gradient explosion detected, grad_norm= 3313729.767980174
[batch 70] loss=4.856062e+08 loss_diff=8.857895e-01 recon=4.856062e+08
obs_tick range: -1.0 374400.0  next_tick range: -0.999048113822937 375100.0
normed next range: -1000000.0 3292.949951171875
pred range: -672.0117797851562 16.692583084106445
mask valid positions: 50669.0 / 65536

>>> Gradient explosion detected, grad_norm= 5866453.837567609
>>> Gradient explosion detected, grad_norm= 8227307.66354138
>>> Gradient explosion detected, grad_norm= 26509425.888373062
>>> Gradient explosion detected, grad_norm= 8469687.288606571
[batch 80] loss=2.033054e+09 loss_diff=9.559321e-01 recon=2.033054e+09
obs_tick range: -0.9994773268699646 382400.0  next_tick range: -1.0 381500.0
normed next range: -1000000.0 6229.98681640625
pred range: -672.8043823242188 14.968208312988281
mask valid positions: 44747.0 / 65536

>>> Gradient explosion detected, grad_norm= 12383281.735043226
[batch 90] loss=1.655306e+09 loss_diff=9.068401e-01 recon=1.655306e+09
obs_tick range: -1.0 375000.0  next_tick range: -1.0 353200.0
normed next range: -1000000.0 22187.421875
pred range: -673.3976440429688 15.63772964477539
mask valid positions: 52655.0 / 65536

>>> Gradient explosion detected, grad_norm= 2068632.657385687
[batch 100] loss=1.171217e+09 loss_diff=8.908893e-01 recon=1.171217e+09
obs_tick range: -1.0 366200.0  next_tick range: -1.0 378000.0
normed next range: -1000000.0 9510.0029296875
pred range: -674.4663696289062 13.141470909118652
mask valid positions: 44418.0 / 65536

>>> Gradient explosion detected, grad_norm= 3033415.0861099074
>>> Gradient explosion detected, grad_norm= 1967385.600284225
[batch 110] loss=1.223235e+09 loss_diff=9.280077e-01 recon=1.223235e+09
obs_tick range: -0.9659255146980286 395000.0  next_tick range: -0.976294219493866 378400.0
normed next range: -1000000.0 4808.28466796875
pred range: -675.43603515625 15.33172607421875
mask valid positions: 50471.0 / 65536

>>> Gradient explosion detected, grad_norm= 12463780.150424864
>>> Gradient explosion detected, grad_norm= 2779357.273824855
>>> Gradient explosion detected, grad_norm= 11900782.129372638
[batch 120] loss=3.294140e+02 loss_diff=8.838335e-01 recon=3.285302e+02
obs_tick range: -0.9914444088935852 366200.0  next_tick range: -0.9961945414543152 366200.0
normed next range: -5.820100784301758 5598.4443359375
pred range: -27.817279815673828 15.330388069152832
mask valid positions: 43606.0 / 65536

>>> Gradient explosion detected, grad_norm= 7739494.442478686
>>> Gradient explosion detected, grad_norm= 19358159.07891471
>>> Gradient explosion detected, grad_norm= 5023170.2571677
>>> Gradient explosion detected, grad_norm= 6167934.4925736105
>>> Gradient explosion detected, grad_norm= 1795803.1467620255
>>> Gradient explosion detected, grad_norm= 1511844.592425141
[batch 130] loss=2.147229e+09 loss_diff=8.739874e-01 recon=2.147229e+09
obs_tick range: -0.9914456605911255 360600.0  next_tick range: -0.9972506761550903 360000.0
normed next range: -1000000.0 5795.82080078125
pred range: -676.633056640625 17.25258445739746
mask valid positions: 35771.0 / 65536

>>> Gradient explosion detected, grad_norm= 4139603.4525016285
>>> Gradient explosion detected, grad_norm= 2681794.1255136062
[batch 140] loss=2.417437e+09 loss_diff=8.693603e-01 recon=2.417437e+09
obs_tick range: -0.991443395614624 367100.0  next_tick range: -0.99619460105896 368000.0
normed next range: -1000000.0 6719.36572265625
pred range: -677.679931640625 13.275982856750488
mask valid positions: 36542.0 / 65536

>>> Gradient explosion detected, grad_norm= 2555992.2023420352
[batch 150] loss=1.206985e+09 loss_diff=8.459256e-01 recon=1.206985e+09
obs_tick range: -0.9914447665214539 393700.0  next_tick range: -0.9848073124885559 392700.0
normed next range: -1000000.0 1000000.0
pred range: -678.2784423828125 13.510600090026855
mask valid positions: 57696.0 / 65536

==============================
[2015-07][Epoch 2/20] | Time = 5.67 min
 - Total Loss : 1448741017.206426 | Recon Loss: 1448741017.136817 | Diff Loss: 0.903077
==============================
No improvement count: 2
[batch 0] loss=2.046996e+02 loss_diff=9.292223e-01 recon=2.037704e+02
obs_tick range: -0.9993910789489746 395000.0  next_tick range: -1.0 395000.0
normed next range: -2.4748735427856445 4308.19775390625
pred range: -20.001482009887695 10.049965858459473
mask valid positions: 43894.0 / 65536

>>> Gradient explosion detected, grad_norm= 4753702.087550923
>>> Gradient explosion detected, grad_norm= 4478720.22441627
>>> Gradient explosion detected, grad_norm= 5063978.507040416
[batch 10] loss=5.203498e+08 loss_diff=9.200017e-01 recon=5.203498e+08
obs_tick range: -0.9990479946136475 393900.0  next_tick range: -0.9961941242218018 393700.0
normed next range: -1000000.0 5117.69482421875
pred range: -679.7401733398438 23.45563507080078
mask valid positions: 35420.0 / 65536

>>> Gradient explosion detected, grad_norm= 8979076.048732745
>>> Gradient explosion detected, grad_norm= 3161873.338844003
[batch 20] loss=2.085397e+09 loss_diff=8.368489e-01 recon=2.085397e+09
obs_tick range: -0.9762956500053406 650000.0  next_tick range: -0.9848062992095947 361200.0
normed next range: -1000000.0 4792.85498046875
pred range: -680.59423828125 25.587331771850586
mask valid positions: 43841.0 / 65536

>>> Gradient explosion detected, grad_norm= 6743892.989002055
>>> Gradient explosion detected, grad_norm= 4207336.478764968
>>> Gradient explosion detected, grad_norm= 1771868.125005744
[batch 30] loss=1.663091e+09 loss_diff=8.804905e-01 recon=1.663091e+09
obs_tick range: -1.0 371500.0  next_tick range: -1.0 368400.0
normed next range: -1000000.0 3186.097900390625
pred range: -681.2288208007812 12.400404930114746
mask valid positions: 51152.0 / 65536

[batch 40] loss=1.285280e+10 loss_diff=8.808098e-01 recon=1.285280e+10
obs_tick range: -1.0 366100.0  next_tick range: -0.9990472793579102 365800.0
normed next range: -1000000.0 1000000.0
pred range: -682.1399536132812 13.935571670532227
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 34628776.75737276
>>> Gradient explosion detected, grad_norm= 3618463.8882493093
[batch 50] loss=1.422049e+09 loss_diff=8.801805e-01 recon=1.422049e+09
obs_tick range: -0.999048113822937 375000.0  next_tick range: -1.0 375000.0
normed next range: -1000000.0 5127.20458984375
pred range: -682.9915771484375 17.776826858520508
mask valid positions: 36011.0 / 65536

>>> Gradient explosion detected, grad_norm= 3103133.79509208
>>> Gradient explosion detected, grad_norm= 1801794.1570850983
[batch 60] loss=6.380083e+08 loss_diff=9.192680e-01 recon=6.380083e+08
obs_tick range: -0.9914447665214539 379200.0  next_tick range: -0.9961902499198914 380300.0
normed next range: -1000000.0 6719.36572265625
pred range: -684.2774047851562 14.319087028503418
mask valid positions: 42976.0 / 65536

>>> Gradient explosion detected, grad_norm= 3215681.6728754924
>>> Gradient explosion detected, grad_norm= 2015247.8210770767
>>> Gradient explosion detected, grad_norm= 5843365.657177708
>>> Gradient explosion detected, grad_norm= 6850471.1132351495
[batch 70] loss=3.818896e+09 loss_diff=8.982235e-01 recon=3.818896e+09
obs_tick range: -0.9993933439254761 350000.0  next_tick range: -1.0 360800.0
normed next range: -1000000.0 14287.69921875
pred range: -685.3112182617188 15.012226104736328
mask valid positions: 24440.0 / 65536

>>> Gradient explosion detected, grad_norm= 4632802.070681465
>>> Gradient explosion detected, grad_norm= 2951382.6257149247
>>> Gradient explosion detected, grad_norm= 2847685.404379034
[batch 80] loss=1.117786e+09 loss_diff=8.644812e-01 recon=1.117786e+09
obs_tick range: -0.9961945414543152 368700.0  next_tick range: -0.9967746734619141 394000.0
normed next range: -1000000.0 38642.87109375
pred range: -685.40087890625 18.097084045410156
mask valid positions: 30215.0 / 65536

>>> Gradient explosion detected, grad_norm= 7851884.830537947
>>> Gradient explosion detected, grad_norm= 5690873.430297759
[batch 90] loss=1.090001e+03 loss_diff=9.047987e-01 recon=1.089096e+03
obs_tick range: -0.9862877130508423 366700.0  next_tick range: -0.9925476908683777 366200.0
normed next range: -6.246109962463379 11312.783203125
pred range: -19.334142684936523 17.87539291381836
mask valid positions: 41822.0 / 65536

>>> Gradient explosion detected, grad_norm= 5402638.466736171
[batch 100] loss=1.017733e+09 loss_diff=9.058051e-01 recon=1.017733e+09
obs_tick range: -0.9537158012390137 365600.0  next_tick range: -0.9659249186515808 1750000.0
normed next range: -1000000.0 80641.96875
pred range: -686.8994750976562 12.377018928527832
mask valid positions: 19805.0 / 65536

>>> Gradient explosion detected, grad_norm= 11271446.985005246
[batch 110] loss=2.219472e+09 loss_diff=8.887724e-01 recon=2.219472e+09
obs_tick range: -1.0 335600.0  next_tick range: -1.0 361000.0
normed next range: -1000000.0 6881.91748046875
pred range: -688.0680541992188 16.763505935668945
mask valid positions: 44235.0 / 65536

>>> Gradient explosion detected, grad_norm= 5505391.949385808
>>> Gradient explosion detected, grad_norm= 4819352.5749660805
>>> Gradient explosion detected, grad_norm= 7625166.330783511
[batch 120] loss=2.411051e+09 loss_diff=8.979511e-01 recon=2.411051e+09
obs_tick range: -0.9961944818496704 394000.0  next_tick range: -0.9990480542182922 394000.0
normed next range: -1000000.0 1624.9698486328125
pred range: -689.0529174804688 18.044443130493164
mask valid positions: 58462.0 / 65536

>>> Gradient explosion detected, grad_norm= 6032216.166707931
>>> Gradient explosion detected, grad_norm= 2373901.955126907
>>> Gradient explosion detected, grad_norm= 12215290.188322073
>>> Gradient explosion detected, grad_norm= 1679874.883265097
[batch 130] loss=8.477407e+08 loss_diff=8.752558e-01 recon=8.477407e+08
obs_tick range: -0.999046266078949 395000.0  next_tick range: -1.0 365800.0
normed next range: -1000000.0 12688.2919921875
pred range: -689.7178955078125 16.798847198486328
mask valid positions: 35020.0 / 65536

>>> Gradient explosion detected, grad_norm= 26661357.790155005
>>> Gradient explosion detected, grad_norm= 8236329.389023633
>>> Gradient explosion detected, grad_norm= 29744815.58205847
>>> Gradient explosion detected, grad_norm= 5171064.17892707
[batch 140] loss=1.872999e+09 loss_diff=9.265690e-01 recon=1.872999e+09
obs_tick range: -1.0 378500.0  next_tick range: -1.0 374000.0
normed next range: -1000000.0 4320.40771484375
pred range: -690.1312255859375 16.072477340698242
mask valid positions: 42559.0 / 65536

>>> Gradient explosion detected, grad_norm= 1442554.9542848952
>>> Gradient explosion detected, grad_norm= 11363180.338293755
[batch 150] loss=1.405296e+09 loss_diff=9.792352e-01 recon=1.405296e+09
obs_tick range: -0.9925552606582642 356500.0  next_tick range: -0.9961949586868286 371500.0
normed next range: -1000000.0 4897.708984375
pred range: -690.4246826171875 15.72398567199707
mask valid positions: 36502.0 / 65536

>>> Gradient explosion detected, grad_norm= 11084223.342736956
>>> Gradient explosion detected, grad_norm= 59097419.68930144
==============================
[2015-07][Epoch 3/20] | Time = 5.67 min
 - Total Loss : 1640953798.123602 | Recon Loss: 1640953798.055210 | Diff Loss: 0.898197
==============================
No improvement count: 3
[batch 0] loss=3.407337e+08 loss_diff=9.365504e-01 recon=3.407337e+08
obs_tick range: -0.9961925148963928 394100.0  next_tick range: -0.9914445281028748 395000.0
normed next range: -1000000.0 10414.7763671875
pred range: -690.905029296875 21.251487731933594
mask valid positions: 42899.0 / 65536

>>> Gradient explosion detected, grad_norm= 6271271.57081798
>>> Gradient explosion detected, grad_norm= 6107865.362427961
>>> Gradient explosion detected, grad_norm= 5523419.52883577
>>> Gradient explosion detected, grad_norm= 9264510.80433777
[batch 10] loss=1.870837e+09 loss_diff=9.175546e-01 recon=1.870837e+09
obs_tick range: -0.9971959590911865 368700.0  next_tick range: -0.9994773268699646 367900.0
normed next range: -1000000.0 5409.37890625
pred range: -691.3882446289062 20.15675926208496
mask valid positions: 29410.0 / 65536

>>> Gradient explosion detected, grad_norm= 5383664.798233984
>>> Gradient explosion detected, grad_norm= 7124732.236840345
>>> Gradient explosion detected, grad_norm= 2798391.8739748653
>>> Gradient explosion detected, grad_norm= 7147307.128558958
>>> Gradient explosion detected, grad_norm= 6300237.8200261835
>>> Gradient explosion detected, grad_norm= 1851256.8185251546
>>> Gradient explosion detected, grad_norm= 33657908.308027804
[batch 20] loss=1.727278e+09 loss_diff=8.845150e-01 recon=1.727278e+09
obs_tick range: -0.9914447069168091 376800.0  next_tick range: -0.9862925410270691 375100.0
normed next range: -1000000.0 7347.07177734375
pred range: -691.7037963867188 21.799184799194336
mask valid positions: 35374.0 / 65536

>>> Gradient explosion detected, grad_norm= 2840044.2266445314
>>> Gradient explosion detected, grad_norm= 3950457.510203535
>>> Gradient explosion detected, grad_norm= 12693549.889580097
>>> Gradient explosion detected, grad_norm= 30474597.52624992
[batch 30] loss=1.098878e+09 loss_diff=8.921092e-01 recon=1.098878e+09
obs_tick range: -1.0 393300.0  next_tick range: -1.0 393900.0
normed next range: -1000000.0 3328.726318359375
pred range: -691.943603515625 18.675418853759766
mask valid positions: 50976.0 / 65536

>>> Gradient explosion detected, grad_norm= 19955578.355999272
>>> Gradient explosion detected, grad_norm= 6714970.268010371
>>> Gradient explosion detected, grad_norm= 11889298.110836672
[batch 40] loss=2.064708e+09 loss_diff=9.072497e-01 recon=2.064708e+09
obs_tick range: -0.9969229698181152 367000.0  next_tick range: -0.9993933439254761 871959.0
normed next range: -1000000.0 15080.8974609375
pred range: -690.6683349609375 16.668920516967773
mask valid positions: 43379.0 / 65536

>>> Gradient explosion detected, grad_norm= 20039640.167355333
>>> Gradient explosion detected, grad_norm= 16219409.424425716
>>> Gradient explosion detected, grad_norm= 8721114.025528528
>>> Gradient explosion detected, grad_norm= 14849087.138572851
>>> Gradient explosion detected, grad_norm= 1285995.275010763
>>> Gradient explosion detected, grad_norm= 1344092.2802888362
[batch 50] loss=1.842813e+09 loss_diff=9.011499e-01 recon=1.842813e+09
obs_tick range: -0.99619460105896 371400.0  next_tick range: -0.9914447665214539 371500.0
normed next range: -1000000.0 5910.2080078125
pred range: -692.2267456054688 16.477596282958984
mask valid positions: 29412.0 / 65536

>>> Gradient explosion detected, grad_norm= 63147143.53443302
>>> Gradient explosion detected, grad_norm= 7243630.078342416
>>> Gradient explosion detected, grad_norm= 5915986.206501066
[batch 60] loss=1.800689e+09 loss_diff=9.376756e-01 recon=1.800689e+09
obs_tick range: -0.9862878322601318 395000.0  next_tick range: -0.9927315711975098 3089266.0
normed next range: -1000000.0 7347.31640625
pred range: -692.6713256835938 16.465633392333984
mask valid positions: 36606.0 / 65536

>>> Gradient explosion detected, grad_norm= 4388995.936267629
>>> Gradient explosion detected, grad_norm= 6028420.625335688
>>> Gradient explosion detected, grad_norm= 4036637.612643972
>>> Gradient explosion detected, grad_norm= 5344568.153961558
>>> Gradient explosion detected, grad_norm= 4634048.8859966295
[batch 70] loss=4.131659e+08 loss_diff=9.054012e-01 recon=4.131659e+08
obs_tick range: -0.9993915557861328 378400.0  next_tick range: -1.0 378500.0
normed next range: -1000000.0 20756.27734375
pred range: -693.1123657226562 17.344778060913086
mask valid positions: 31204.0 / 65536

>>> Gradient explosion detected, grad_norm= 77631338.2599731
>>> Gradient explosion detected, grad_norm= 30579229.026804883
>>> Gradient explosion detected, grad_norm= 1216166.3008923547
>>> Gradient explosion detected, grad_norm= 18041124.769974846
[batch 80] loss=9.670020e+08 loss_diff=8.564228e-01 recon=9.670020e+08
obs_tick range: -0.9969472289085388 367500.0  next_tick range: -0.9990483522415161 367500.0
normed next range: -1000000.0 18020.12890625
pred range: -693.0549926757812 17.178770065307617
mask valid positions: 36241.0 / 65536

>>> Gradient explosion detected, grad_norm= 1028908.1502375201
>>> Gradient explosion detected, grad_norm= 8800858.363667345
[batch 90] loss=1.300125e+09 loss_diff=8.610629e-01 recon=1.300125e+09
obs_tick range: -1.0 362800.0  next_tick range: -1.0 365600.0
normed next range: -1000000.0 4676.12744140625
pred range: -693.4999389648438 15.853592872619629
mask valid positions: 36103.0 / 65536

>>> Gradient explosion detected, grad_norm= 11234471.461688226
>>> Gradient explosion detected, grad_norm= 9922279.659761084
>>> Gradient explosion detected, grad_norm= 14107836.619144239
>>> Gradient explosion detected, grad_norm= 63472603.34023314
>>> Gradient explosion detected, grad_norm= 11975741.944765186
[batch 100] loss=9.976183e+08 loss_diff=9.007157e-01 recon=9.976183e+08
obs_tick range: -0.9914442896842957 395000.0  next_tick range: -0.9961944222450256 395000.0
normed next range: -1000000.0 1570.285400390625
pred range: -694.2432861328125 17.14034080505371
mask valid positions: 49509.0 / 65536

>>> Gradient explosion detected, grad_norm= 1430440.3638791032
>>> Gradient explosion detected, grad_norm= 2531229.1905849087
>>> Gradient explosion detected, grad_norm= 2162160.0812493986
>>> Gradient explosion detected, grad_norm= 1090197.5665683423
>>> Gradient explosion detected, grad_norm= 1351697.147238163
[batch 110] loss=6.428323e+08 loss_diff=9.824271e-01 recon=6.428323e+08
obs_tick range: -0.9990478157997131 373700.0  next_tick range: -1.0 374000.0
normed next range: -1000000.0 3343.360107421875
pred range: -694.5313720703125 16.272647857666016
mask valid positions: 43076.0 / 65536

>>> Gradient explosion detected, grad_norm= 2373038.2146430276
>>> Gradient explosion detected, grad_norm= 8402701.212840494
>>> Gradient explosion detected, grad_norm= 4710146.44151233
[batch 120] loss=7.416488e+08 loss_diff=9.296875e-01 recon=7.416488e+08
obs_tick range: -1.0 369500.0  next_tick range: -1.0 387100.0
normed next range: -1000000.0 16981.712890625
pred range: -694.7529907226562 15.456060409545898
mask valid positions: 42600.0 / 65536

>>> Gradient explosion detected, grad_norm= 3194173.0031276257
>>> Gradient explosion detected, grad_norm= 11673469.772103487
>>> Gradient explosion detected, grad_norm= 5427418.895796557
[batch 130] loss=4.429470e+08 loss_diff=9.286525e-01 recon=4.429470e+08
obs_tick range: -0.9848072528839111 369000.0  next_tick range: -0.9762950539588928 371400.0
normed next range: -1000000.0 4446.81884765625
pred range: -695.6685791015625 14.003891944885254
mask valid positions: 50012.0 / 65536

>>> Gradient explosion detected, grad_norm= 12973129.937704686
>>> Gradient explosion detected, grad_norm= 8003762.41532847
[batch 140] loss=1.379718e+09 loss_diff=9.495667e-01 recon=1.379718e+09
obs_tick range: -1.0 395000.0  next_tick range: -1.0 361700.0
normed next range: -1000000.0 7129.01904296875
pred range: -695.9599609375 14.206178665161133
mask valid positions: 28493.0 / 65536

>>> Gradient explosion detected, grad_norm= 1184220.572997629
>>> Gradient explosion detected, grad_norm= 1567314.9452091188
[batch 150] loss=1.860577e+09 loss_diff=8.851634e-01 recon=1.860577e+09
obs_tick range: -1.0 367300.0  next_tick range: -0.999048113822937 365800.0
normed next range: -1000000.0 9975.650390625
pred range: -697.0518188476562 18.732053756713867
mask valid positions: 35718.0 / 65536

>>> Gradient explosion detected, grad_norm= 1293276.5233760043
>>> Gradient explosion detected, grad_norm= 9324311.004227625
==============================
[2015-07][Epoch 4/20] | Time = 5.67 min
 - Total Loss : 1633715392.498457 | Recon Loss: 1633715392.430322 | Diff Loss: 0.905360
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-07 completed in 22.43 min
[1] 2015-08 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-08 | file : news_20150831.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=2.453885e+09 loss_diff=9.216859e-01 recon=2.453885e+09
obs_tick range: -0.992336630821228 375000.0  next_tick range: -0.9969189763069153 375000.0
normed next range: -1000000.0 1000000.0
pred range: -697.3782958984375 20.608081817626953
mask valid positions: 43489.0 / 65536

>>> Gradient explosion detected, grad_norm= 6669373.536216769
>>> Gradient explosion detected, grad_norm= 25716900.338287793
>>> Gradient explosion detected, grad_norm= 9801408.017683715
>>> Gradient explosion detected, grad_norm= 14760172.039988449
>>> Gradient explosion detected, grad_norm= 2469864.268044202
[batch 10] loss=1.522426e+09 loss_diff=9.088903e-01 recon=1.522426e+09
obs_tick range: -0.999048113822937 375000.0  next_tick range: -1.0 373700.0
normed next range: -1000000.0 2339.59130859375
pred range: -698.1961669921875 21.71904182434082
mask valid positions: 51166.0 / 65536

>>> Gradient explosion detected, grad_norm= 13179878.693949621
>>> Gradient explosion detected, grad_norm= 2085884.0407636408
[batch 20] loss=3.947022e+09 loss_diff=8.954637e-01 recon=3.947022e+09
obs_tick range: -1.0 395800.0  next_tick range: -0.9914445877075195 396000.0
normed next range: -1000000.0 1205.0274658203125
pred range: -698.5032958984375 15.54422378540039
mask valid positions: 51418.0 / 65536

>>> Gradient explosion detected, grad_norm= 23322333.241418257
>>> Gradient explosion detected, grad_norm= 1040142.7332472763
>>> Gradient explosion detected, grad_norm= 18129826.854455665
[batch 30] loss=3.068758e+09 loss_diff=9.115155e-01 recon=3.068758e+09
obs_tick range: -1.0 393600.0  next_tick range: -0.9972280859947205 395800.0
normed next range: -1000000.0 14746.2177734375
pred range: -699.1619873046875 15.952774047851562
mask valid positions: 35534.0 / 65536

>>> Gradient explosion detected, grad_norm= 19427129.87572778
>>> Gradient explosion detected, grad_norm= 4718609.367510138
>>> Gradient explosion detected, grad_norm= 3560721.62394406
>>> Gradient explosion detected, grad_norm= 2300336.6005358677
[batch 40] loss=1.115147e+09 loss_diff=9.795189e-01 recon=1.115147e+09
obs_tick range: -1.0 370200.0  next_tick range: -1.0 369000.0
normed next range: -1000000.0 3897.65771484375
pred range: -699.3805541992188 15.36169719696045
mask valid positions: 50884.0 / 65536

>>> Gradient explosion detected, grad_norm= 6073653.054237233
>>> Gradient explosion detected, grad_norm= 1476738.8157559165
>>> Gradient explosion detected, grad_norm= 42453081.2280449
[batch 50] loss=1.826089e+09 loss_diff=8.920280e-01 recon=1.826089e+09
obs_tick range: -1.0 375100.0  next_tick range: -0.999048113822937 373300.0
normed next range: -1000000.0 3897.248046875
pred range: -700.166015625 16.200359344482422
mask valid positions: 58268.0 / 65536

>>> Gradient explosion detected, grad_norm= 3841932.870599648
[batch 60] loss=1.986800e+08 loss_diff=9.022372e-01 recon=1.986800e+08
obs_tick range: -0.9993684887886047 378400.0  next_tick range: -1.0 378000.0
normed next range: -1000000.0 5076.77880859375
pred range: -700.58447265625 20.257537841796875
mask valid positions: 35185.0 / 65536

>>> Gradient explosion detected, grad_norm= 2970686.1100525768
[batch 70] loss=2.143187e+09 loss_diff=8.958726e-01 recon=2.143187e+09
obs_tick range: -0.9990478157997131 386200.0  next_tick range: -0.9961944222450256 367000.0
normed next range: -1000000.0 2111.291748046875
pred range: -701.71484375 15.20081901550293
mask valid positions: 58295.0 / 65536

>>> Gradient explosion detected, grad_norm= 2508310.643422921
>>> Gradient explosion detected, grad_norm= 22339001.63836783
[batch 80] loss=1.341373e+09 loss_diff=9.155303e-01 recon=1.341373e+09
obs_tick range: -0.9990476965904236 365000.0  next_tick range: -1.0 364000.0
normed next range: -1000000.0 1359.482666015625
pred range: -703.1473999023438 15.461092948913574
mask valid positions: 63496.0 / 65536

>>> Gradient explosion detected, grad_norm= 24036806.086044185
>>> Gradient explosion detected, grad_norm= 4941672.561686816
[batch 90] loss=9.822746e+08 loss_diff=8.486466e-01 recon=9.822746e+08
obs_tick range: -0.9848073124885559 381500.0  next_tick range: -0.991443395614624 380800.0
normed next range: -1000000.0 1000000.0
pred range: -704.1035766601562 14.742493629455566
mask valid positions: 49449.0 / 65536

>>> Gradient explosion detected, grad_norm= 7183297.443946114
>>> Gradient explosion detected, grad_norm= 26170727.696422383
[batch 100] loss=7.027133e+08 loss_diff=1.034235e+00 recon=7.027133e+08
obs_tick range: -0.9990474581718445 368400.0  next_tick range: -0.9961944222450256 368500.0
normed next range: -1000000.0 1000000.0
pred range: -705.6113891601562 14.236658096313477
mask valid positions: 57883.0 / 65536

>>> Gradient explosion detected, grad_norm= 1874347.7662740683
[batch 110] loss=6.025811e+08 loss_diff=8.253715e-01 recon=6.025811e+08
obs_tick range: -0.999048113822937 394000.0  next_tick range: -1.0 365000.0
normed next range: -1000000.0 17320.0703125
pred range: -706.9487915039062 14.969436645507812
mask valid positions: 34351.0 / 65536

>>> Gradient explosion detected, grad_norm= 1095115.55576655
>>> Gradient explosion detected, grad_norm= 6832509.44437671
[batch 120] loss=5.200480e+06 loss_diff=8.735883e-01 recon=5.200479e+06
obs_tick range: -1.0 235600.0  next_tick range: -0.9990479350090027 361200.0
normed next range: -1000000.0 5079.6357421875
pred range: -707.9129028320312 13.014902114868164
mask valid positions: 34942.0 / 65536

>>> Gradient explosion detected, grad_norm= 1733969.5866727524
>>> Gradient explosion detected, grad_norm= 9779068.362427892
[batch 130] loss=1.873814e+02 loss_diff=8.871839e-01 recon=1.864942e+02
obs_tick range: -0.9990472793579102 327000.0  next_tick range: -0.9961910843849182 319400.0
normed next range: -9.545942306518555 3489.47900390625
pred range: -91.22227478027344 22.44791603088379
mask valid positions: 50512.0 / 65536

>>> Gradient explosion detected, grad_norm= 2739322.1740949824
>>> Gradient explosion detected, grad_norm= 12127842.716780992
>>> Gradient explosion detected, grad_norm= 2572494.648772427
>>> Gradient explosion detected, grad_norm= 2215509.2489339765
>>> Gradient explosion detected, grad_norm= 5806770.279299015
>>> Gradient explosion detected, grad_norm= 5440517.151449199
>>> Gradient explosion detected, grad_norm= 2244328.0596476817
[batch 140] loss=1.916247e+09 loss_diff=9.088953e-01 recon=1.916247e+09
obs_tick range: -0.99692302942276 367900.0  next_tick range: -0.9990484118461609 1692079.0
normed next range: -1000000.0 17679.6171875
pred range: -709.0050659179688 14.994221687316895
mask valid positions: 20988.0 / 65536

>>> Gradient explosion detected, grad_norm= 15715622.116385417
>>> Gradient explosion detected, grad_norm= 4242694.445597803
>>> Gradient explosion detected, grad_norm= 12548049.142543755
>>> Gradient explosion detected, grad_norm= 6262747.269014467
[batch 150] loss=3.469364e+09 loss_diff=8.568172e-01 recon=3.469364e+09
obs_tick range: -0.9976633191108704 380000.0  next_tick range: -0.9995337724685669 379900.0
normed next range: -1000000.0 12633.1474609375
pred range: -709.6908569335938 15.552703857421875
mask valid positions: 36976.0 / 65536

>>> Gradient explosion detected, grad_norm= 8322781.873418085
>>> Gradient explosion detected, grad_norm= 1357172.1953531965
>>> Gradient explosion detected, grad_norm= 2075006.9936753926
>>> Gradient explosion detected, grad_norm= 1648817.3716760657
>>> Gradient explosion detected, grad_norm= 86681862.28257747
==============================
[2015-08][Epoch 1/20] | Time = 5.53 min
 - Total Loss : 1768683891.420085 | Recon Loss: 1768683891.351197 | Diff Loss: 0.899308
==============================
No improvement count: 1
[batch 0] loss=1.667235e+09 loss_diff=8.661016e-01 recon=1.667235e+09
obs_tick range: -1.0 374400.0  next_tick range: -0.999048113822937 389000.0
normed next range: -1000000.0 1869.89306640625
pred range: -709.9013061523438 15.391093254089355
mask valid positions: 58101.0 / 65536

>>> Gradient explosion detected, grad_norm= 3566908.8209176124
[batch 10] loss=1.463383e+09 loss_diff=8.988107e-01 recon=1.463383e+09
obs_tick range: -0.9961941242218018 394500.0  next_tick range: -0.9990481734275818 393300.0
normed next range: -1000000.0 3611.422119140625
pred range: -710.2271118164062 14.358628273010254
mask valid positions: 58005.0 / 65536

>>> Gradient explosion detected, grad_norm= 8367302.074465273
[batch 20] loss=1.720569e+09 loss_diff=8.749042e-01 recon=1.720569e+09
obs_tick range: -1.0 365600.0  next_tick range: -0.984806478023529 365200.0
normed next range: -1000000.0 9801.376953125
pred range: -711.44482421875 19.28056526184082
mask valid positions: 35352.0 / 65536

>>> Gradient explosion detected, grad_norm= 2488361.7763214125
>>> Gradient explosion detected, grad_norm= 1079803.9016790744
>>> Gradient explosion detected, grad_norm= 3043301.046791167
>>> Gradient explosion detected, grad_norm= 9222636.479862278
[batch 30] loss=7.874911e+08 loss_diff=9.081604e-01 recon=7.874911e+08
obs_tick range: -1.0 368700.0  next_tick range: -0.9914441108703613 368700.0
normed next range: -1000000.0 1554.5386962890625
pred range: -712.7763061523438 20.050561904907227
mask valid positions: 49573.0 / 65536

>>> Gradient explosion detected, grad_norm= 6083962.225438481
[batch 40] loss=1.541686e+09 loss_diff=8.882778e-01 recon=1.541686e+09
obs_tick range: -0.999048113822937 392500.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 4160.294921875
pred range: -713.7498168945312 17.321502685546875
mask valid positions: 58475.0 / 65536

>>> Gradient explosion detected, grad_norm= 2502799.7525576586
>>> Gradient explosion detected, grad_norm= 1774345.079478206
[batch 50] loss=2.363049e+09 loss_diff=8.836082e-01 recon=2.363049e+09
obs_tick range: -0.9993934631347656 379900.0  next_tick range: -1.0 378300.0
normed next range: -1000000.0 3467.16796875
pred range: -714.494873046875 14.361358642578125
mask valid positions: 52134.0 / 65536

>>> Gradient explosion detected, grad_norm= 51421497.14174107
[batch 60] loss=1.375664e+09 loss_diff=8.970335e-01 recon=1.375664e+09
obs_tick range: -0.9396922588348389 368700.0  next_tick range: -0.9537126421928406 368700.0
normed next range: -1000000.0 4134.35986328125
pred range: -715.3577880859375 16.677841186523438
mask valid positions: 44943.0 / 65536

>>> Gradient explosion detected, grad_norm= 20141052.130431436
>>> Gradient explosion detected, grad_norm= 97740177.30341856
>>> Gradient explosion detected, grad_norm= 57147308.761736885
>>> Gradient explosion detected, grad_norm= 9655334.480875915
>>> Gradient explosion detected, grad_norm= 41040579.754406855
>>> Gradient explosion detected, grad_norm= 5110015.425609136
[batch 70] loss=6.476223e+08 loss_diff=8.380576e-01 recon=6.476223e+08
obs_tick range: -1.0 395000.0  next_tick range: -0.9990481734275818 367300.0
normed next range: -1000000.0 7101.7470703125
pred range: -716.262939453125 15.812446594238281
mask valid positions: 34485.0 / 65536

>>> Gradient explosion detected, grad_norm= 2086121.7442074805
[batch 80] loss=7.737966e+08 loss_diff=8.931739e-01 recon=7.737966e+08
obs_tick range: -0.9790471792221069 366800.0  next_tick range: -0.9870018362998962 366700.0
normed next range: -1000000.0 5137.81787109375
pred range: -716.4544067382812 13.123750686645508
mask valid positions: 43058.0 / 65536

>>> Gradient explosion detected, grad_norm= 6866237.674088441
>>> Gradient explosion detected, grad_norm= 24253659.272192392
[batch 90] loss=1.730941e+09 loss_diff=9.186758e-01 recon=1.730941e+09
obs_tick range: -0.9990479946136475 361300.0  next_tick range: -0.9961941242218018 375000.0
normed next range: -1000000.0 2268.982421875
pred range: -717.6138916015625 15.145599365234375
mask valid positions: 44633.0 / 65536

>>> Gradient explosion detected, grad_norm= 38788977.68710188
>>> Gradient explosion detected, grad_norm= 46663390.59261286
>>> Gradient explosion detected, grad_norm= 37858018.61798192
>>> Gradient explosion detected, grad_norm= 7914089.786293221
[batch 100] loss=2.558575e+09 loss_diff=9.447471e-01 recon=2.558575e+09
obs_tick range: -0.991443932056427 393300.0  next_tick range: -0.9961920380592346 395000.0
normed next range: -1000000.0 1146.8192138671875
pred range: -718.553955078125 15.599143981933594
mask valid positions: 58226.0 / 65536

>>> Gradient explosion detected, grad_norm= 24508221.16400626
>>> Gradient explosion detected, grad_norm= 18130642.207336593
>>> Gradient explosion detected, grad_norm= 9307748.247305265
>>> Gradient explosion detected, grad_norm= 4959674.594037872
>>> Gradient explosion detected, grad_norm= 12884755.291445948
[batch 110] loss=1.477039e+09 loss_diff=9.006020e-01 recon=1.477039e+09
obs_tick range: -1.0 356300.0  next_tick range: -0.9990479350090027 361200.0
normed next range: -1000000.0 3669.734619140625
pred range: -719.0130004882812 16.285737991333008
mask valid positions: 51079.0 / 65536

>>> Gradient explosion detected, grad_norm= 12775919.773421012
>>> Gradient explosion detected, grad_norm= 2111983.9807065413
>>> Gradient explosion detected, grad_norm= 3166122.7864103997
>>> Gradient explosion detected, grad_norm= 2706956.2565860017
>>> Gradient explosion detected, grad_norm= 1533075.5678785753
>>> Gradient explosion detected, grad_norm= 9954285.695209634
[batch 120] loss=8.737528e+08 loss_diff=9.162862e-01 recon=8.737528e+08
obs_tick range: -0.9961944222450256 359000.0  next_tick range: -0.9914445281028748 357400.0
normed next range: -1000000.0 2402.003173828125
pred range: -719.014892578125 14.645280838012695
mask valid positions: 40730.0 / 65536

>>> Gradient explosion detected, grad_norm= 18084927.282968115
>>> Gradient explosion detected, grad_norm= 10233959.576736104
>>> Gradient explosion detected, grad_norm= 13280257.559468402
>>> Gradient explosion detected, grad_norm= 12181192.406156952
>>> Gradient explosion detected, grad_norm= 24435054.372858856
>>> Gradient explosion detected, grad_norm= 3224358.1128738453
[batch 130] loss=3.358685e+09 loss_diff=8.527474e-01 recon=3.358685e+09
obs_tick range: -0.9993930459022522 395000.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 2047.298095703125
pred range: -719.3308715820312 14.816781044006348
mask valid positions: 51375.0 / 65536

>>> Gradient explosion detected, grad_norm= 27103428.142156657
>>> Gradient explosion detected, grad_norm= 1588391.7566927099
>>> Gradient explosion detected, grad_norm= 2827153.0780551797
>>> Gradient explosion detected, grad_norm= 1841916.120287395
>>> Gradient explosion detected, grad_norm= 1734073.1485600427
>>> Gradient explosion detected, grad_norm= 4034397.8543980657
>>> Gradient explosion detected, grad_norm= 26206565.154776
[batch 140] loss=2.025719e+03 loss_diff=8.847792e-01 recon=2.024834e+03
obs_tick range: -0.9993915557861328 378000.0  next_tick range: -1.0 3089266.0
normed next range: -2.8796634674072266 16520.861328125
pred range: -187.26910400390625 15.897916793823242
mask valid positions: 37558.0 / 65536

>>> Gradient explosion detected, grad_norm= 1008145.1836076682
>>> Gradient explosion detected, grad_norm= 3751923.655526939
>>> Gradient explosion detected, grad_norm= 1336598.8210491864
>>> Gradient explosion detected, grad_norm= 1398433.0715639102
>>> Gradient explosion detected, grad_norm= 16123490.078413418
>>> Gradient explosion detected, grad_norm= 56626138.967724435
>>> Gradient explosion detected, grad_norm= 1180896.6902989007
>>> Gradient explosion detected, grad_norm= 1082626.6521988637
[batch 150] loss=3.031981e+09 loss_diff=9.304740e-01 recon=3.031981e+09
obs_tick range: -1.0 366200.0  next_tick range: -1.0 371500.0
normed next range: -1000000.0 5303.10888671875
pred range: -719.8191528320312 15.965828895568848
mask valid positions: 29762.0 / 65536

>>> Gradient explosion detected, grad_norm= 65302954.008154206
==============================
[2015-08][Epoch 2/20] | Time = 5.67 min
 - Total Loss : 1810221552.139308 | Recon Loss: 1810221552.070260 | Diff Loss: 0.905669
==============================
No improvement count: 2
[batch 0] loss=4.131963e+08 loss_diff=8.371230e-01 recon=4.131963e+08
obs_tick range: -0.9914442896842957 363100.0  next_tick range: -0.9848072528839111 362500.0
normed next range: -1000000.0 1686.7547607421875
pred range: -719.6664428710938 16.127622604370117
mask valid positions: 49661.0 / 65536

>>> Gradient explosion detected, grad_norm= 4823275.964275663
>>> Gradient explosion detected, grad_norm= 16439411.681479214
>>> Gradient explosion detected, grad_norm= 9555807.232615449
>>> Gradient explosion detected, grad_norm= 6486669.741223097
>>> Gradient explosion detected, grad_norm= 22579265.395525247
>>> Gradient explosion detected, grad_norm= 2942919.7542246957
>>> Gradient explosion detected, grad_norm= 5488185.103426996
[batch 10] loss=2.161515e+09 loss_diff=9.215130e-01 recon=2.161515e+09
obs_tick range: -0.9925494194030762 379500.0  next_tick range: -0.9969194531440735 379200.0
normed next range: -1000000.0 3599.14892578125
pred range: -719.474853515625 16.517955780029297
mask valid positions: 58552.0 / 65536

>>> Gradient explosion detected, grad_norm= 34000496.07097961
>>> Gradient explosion detected, grad_norm= 2723944.6305252947
>>> Gradient explosion detected, grad_norm= 3599911.8621427845
>>> Gradient explosion detected, grad_norm= 2182116.1777487714
>>> Gradient explosion detected, grad_norm= 3447927.9508103584
>>> Gradient explosion detected, grad_norm= 4144477.3752647056
>>> Gradient explosion detected, grad_norm= 2073296.4028401112
>>> Gradient explosion detected, grad_norm= 2551716.9386335853
>>> Gradient explosion detected, grad_norm= 1186980.9807458606
[batch 20] loss=1.927324e+09 loss_diff=9.314889e-01 recon=1.927324e+09
obs_tick range: -0.9961923360824585 393600.0  next_tick range: -0.999048113822937 395000.0
normed next range: -1000000.0 1000000.0
pred range: -720.1029663085938 16.12444305419922
mask valid positions: 58274.0 / 65536

>>> Gradient explosion detected, grad_norm= 9767737.746966615
>>> Gradient explosion detected, grad_norm= 4233887.213859063
>>> Gradient explosion detected, grad_norm= 3468500.3352933275
>>> Gradient explosion detected, grad_norm= 4139483.8506387062
[batch 30] loss=6.732063e+02 loss_diff=9.230514e-01 recon=6.722833e+02
obs_tick range: -0.9994773268699646 376600.0  next_tick range: -1.0 369500.0
normed next range: -2.4748737812042236 5020.458984375
pred range: -269.5245361328125 15.030049324035645
mask valid positions: 27895.0 / 65536

>>> Gradient explosion detected, grad_norm= 5443013.635995656
[batch 40] loss=4.733401e+02 loss_diff=9.484647e-01 recon=4.723916e+02
obs_tick range: -0.9659256935119629 365000.0  next_tick range: -0.9537187218666077 364000.0
normed next range: -9.545941352844238 4599.423828125
pred range: -202.41641235351562 25.821359634399414
mask valid positions: 42992.0 / 65536

>>> Gradient explosion detected, grad_norm= 1061737.267918693
>>> Gradient explosion detected, grad_norm= 9290940.96398057
[batch 50] loss=3.942782e+08 loss_diff=9.213496e-01 recon=3.942782e+08
obs_tick range: -0.9961930513381958 392300.0  next_tick range: -0.9990480542182922 392200.0
normed next range: -1000000.0 2201.700439453125
pred range: -722.028564453125 15.013778686523438
mask valid positions: 57566.0 / 65536

>>> Gradient explosion detected, grad_norm= 6362318.971788947
>>> Gradient explosion detected, grad_norm= 3858875.245408882
[batch 60] loss=3.414387e+08 loss_diff=9.491718e-01 recon=3.414387e+08
obs_tick range: -0.9762961268424988 362300.0  next_tick range: -0.9848081469535828 367100.0
normed next range: -1000000.0 2564.10693359375
pred range: -723.07275390625 14.514647483825684
mask valid positions: 27652.0 / 65536

>>> Gradient explosion detected, grad_norm= 9800756.549923414
>>> Gradient explosion detected, grad_norm= 8391637.016520467
>>> Gradient explosion detected, grad_norm= 6331730.107272274
[batch 70] loss=1.795066e+09 loss_diff=8.905916e-01 recon=1.795066e+09
obs_tick range: -0.9848071336746216 871959.0  next_tick range: -0.9914413094520569 367200.0
normed next range: -1000000.0 11025.4326171875
pred range: -724.495361328125 13.930578231811523
mask valid positions: 28979.0 / 65536

>>> Gradient explosion detected, grad_norm= 10601326.667823343
>>> Gradient explosion detected, grad_norm= 12119661.143843548
>>> Gradient explosion detected, grad_norm= 4182401.761349122
>>> Gradient explosion detected, grad_norm= 19529257.71052022
>>> Gradient explosion detected, grad_norm= 3710178.5969314706
>>> Gradient explosion detected, grad_norm= 3496489.359818021
>>> Gradient explosion detected, grad_norm= 3537021.883365054
>>> Gradient explosion detected, grad_norm= 2192940.550201798
[batch 80] loss=2.507709e+09 loss_diff=8.969539e-01 recon=2.507709e+09
obs_tick range: -1.0 351100.0  next_tick range: -1.0 351000.0
normed next range: -1000000.0 18706.380859375
pred range: -724.7102661132812 20.44727325439453
mask valid positions: 58430.0 / 65536

>>> Gradient explosion detected, grad_norm= 3407981.2577946363
>>> Gradient explosion detected, grad_norm= 47704916.80235202
>>> Gradient explosion detected, grad_norm= 30647276.65474918
>>> Gradient explosion detected, grad_norm= 9259652.004511056
[batch 90] loss=1.933706e+09 loss_diff=9.663501e-01 recon=1.933706e+09
obs_tick range: -1.0 360600.0  next_tick range: -0.9990481734275818 394000.0
normed next range: -1000000.0 2624.814208984375
pred range: -725.1932373046875 17.29244613647461
mask valid positions: 43708.0 / 65536

>>> Gradient explosion detected, grad_norm= 8108208.580586786
>>> Gradient explosion detected, grad_norm= 14961072.51374775
>>> Gradient explosion detected, grad_norm= 18184800.004170176
[batch 100] loss=1.891394e+09 loss_diff=9.137165e-01 recon=1.891394e+09
obs_tick range: -0.9914413094520569 361000.0  next_tick range: -0.9961941242218018 650000.0
normed next range: -1000000.0 6248.763671875
pred range: -725.8139038085938 15.40280532836914
mask valid positions: 51214.0 / 65536

>>> Gradient explosion detected, grad_norm= 48693603.3918764
>>> Gradient explosion detected, grad_norm= 1802936.09485976
>>> Gradient explosion detected, grad_norm= 2321412.914817114
>>> Gradient explosion detected, grad_norm= 1761546.4855363388
[batch 110] loss=1.651508e+09 loss_diff=9.594874e-01 recon=1.651508e+09
obs_tick range: -0.9914445281028748 393900.0  next_tick range: -0.9914393424987793 393700.0
normed next range: -1000000.0 4869.26416015625
pred range: -725.9655151367188 15.477045059204102
mask valid positions: 58328.0 / 65536

>>> Gradient explosion detected, grad_norm= 16263509.57107806
>>> Gradient explosion detected, grad_norm= 1246680.6605046224
>>> Gradient explosion detected, grad_norm= 68177699.09807146
>>> Gradient explosion detected, grad_norm= 4252196.674410977
[batch 120] loss=1.307120e+09 loss_diff=8.415816e-01 recon=1.307120e+09
obs_tick range: -0.999048113822937 394500.0  next_tick range: -0.9993930459022522 394500.0
normed next range: -1000000.0 1672.063720703125
pred range: -726.4557495117188 24.278749465942383
mask valid positions: 51395.0 / 65536

>>> Gradient explosion detected, grad_norm= 2848000.8008864326
>>> Gradient explosion detected, grad_norm= 11596971.19597041
>>> Gradient explosion detected, grad_norm= 6171613.743069513
>>> Gradient explosion detected, grad_norm= 9690905.605004571
>>> Gradient explosion detected, grad_norm= 76683210.2751912
>>> Gradient explosion detected, grad_norm= 2042162.0380226814
[batch 130] loss=1.615775e+09 loss_diff=8.345352e-01 recon=1.615775e+09
obs_tick range: -0.9781553149223328 372600.0  next_tick range: -0.9862878322601318 372600.0
normed next range: -1000000.0 8712.923828125
pred range: -726.4192504882812 18.7645263671875
mask valid positions: 43432.0 / 65536

>>> Gradient explosion detected, grad_norm= 3290233.98343972
>>> Gradient explosion detected, grad_norm= 3032334.104483069
>>> Gradient explosion detected, grad_norm= 1317721.415331458
>>> Gradient explosion detected, grad_norm= 19214889.400734566
>>> Gradient explosion detected, grad_norm= 30049927.79292792
[batch 140] loss=8.837384e+08 loss_diff=9.065257e-01 recon=8.837384e+08
obs_tick range: -1.0 327600.0  next_tick range: -0.9990479350090027 328000.0
normed next range: -1000000.0 48404.7265625
pred range: -726.4531860351562 19.736865997314453
mask valid positions: 42652.0 / 65536

>>> Gradient explosion detected, grad_norm= 59895347.0571788
>>> Gradient explosion detected, grad_norm= 26578444.3080443
>>> Gradient explosion detected, grad_norm= 83518935.67101
>>> Gradient explosion detected, grad_norm= 84555530.85493591
>>> Gradient explosion detected, grad_norm= 77960810.71475448
>>> Gradient explosion detected, grad_norm= 2732900.947844489
[batch 150] loss=1.969898e+09 loss_diff=9.293303e-01 recon=1.969898e+09
obs_tick range: -0.999048113822937 379500.0  next_tick range: -0.9969200491905212 379500.0
normed next range: -1000000.0 3119.3876953125
pred range: -727.4140625 15.953072547912598
mask valid positions: 51249.0 / 65536

>>> Gradient explosion detected, grad_norm= 8968135.106604435
>>> Gradient explosion detected, grad_norm= 79266916.54604764
==============================
[2015-08][Epoch 3/20] | Time = 5.67 min
 - Total Loss : 1630497653.147474 | Recon Loss: 1630497653.083057 | Diff Loss: 0.902985
==============================
No improvement count: 3
[batch 0] loss=1.257114e+09 loss_diff=9.543962e-01 recon=1.257114e+09
obs_tick range: -0.9993932247161865 366200.0  next_tick range: -1.0 371500.0
normed next range: -1000000.0 5521.45263671875
pred range: -727.5992431640625 16.002735137939453
mask valid positions: 39141.0 / 65536

>>> Gradient explosion detected, grad_norm= 21553108.390670907
>>> Gradient explosion detected, grad_norm= 8331438.518901472
>>> Gradient explosion detected, grad_norm= 2104148.212679809
[batch 10] loss=1.209666e+09 loss_diff=9.864442e-01 recon=1.209666e+09
obs_tick range: -0.9990483522415161 378300.0  next_tick range: -1.0 376400.0
normed next range: -1000000.0 3989.602783203125
pred range: -727.5477905273438 15.21845817565918
mask valid positions: 44578.0 / 65536

>>> Gradient explosion detected, grad_norm= 8758815.925135992
>>> Gradient explosion detected, grad_norm= 13592847.347772503
>>> Gradient explosion detected, grad_norm= 5089298.59882909
>>> Gradient explosion detected, grad_norm= 11563154.560723484
[batch 20] loss=7.845236e+08 loss_diff=8.457943e-01 recon=7.845236e+08
obs_tick range: -1.0 370900.0  next_tick range: -0.9990474581718445 371200.0
normed next range: -1000000.0 8479.515625
pred range: -728.0001831054688 15.429682731628418
mask valid positions: 34831.0 / 65536

>>> Gradient explosion detected, grad_norm= 4649678.84858253
>>> Gradient explosion detected, grad_norm= 3236490.9752494385
>>> Gradient explosion detected, grad_norm= 17521919.48865574
>>> Gradient explosion detected, grad_norm= 10170337.786465647
[batch 30] loss=1.165298e+10 loss_diff=9.077804e-01 recon=1.165298e+10
obs_tick range: -1.0 391500.0  next_tick range: -1.0 392100.0
normed next range: -1000000.0 3424.791259765625
pred range: -728.5341186523438 15.323237419128418
mask valid positions: 63496.0 / 65536

>>> Gradient explosion detected, grad_norm= 31939254.778173532
>>> Gradient explosion detected, grad_norm= 8375282.009942513
[batch 40] loss=2.311843e+03 loss_diff=8.889163e-01 recon=2.310954e+03
obs_tick range: -1.0 378500.0  next_tick range: -1.0 335600.0
normed next range: -3.68705677986145 10914.841796875
pred range: -312.2117919921875 31.792049407958984
mask valid positions: 37494.0 / 65536

>>> Gradient explosion detected, grad_norm= 3377673.6578722126
>>> Gradient explosion detected, grad_norm= 4695152.246298042
>>> Gradient explosion detected, grad_norm= 15525357.81528241
>>> Gradient explosion detected, grad_norm= 14212425.071769891
>>> Gradient explosion detected, grad_norm= 5443692.643409017
>>> Gradient explosion detected, grad_norm= 12387763.324372599
>>> Gradient explosion detected, grad_norm= 10716987.636750624
>>> Gradient explosion detected, grad_norm= 2103492.327569799
[batch 50] loss=8.177050e+08 loss_diff=8.386911e-01 recon=8.177050e+08
obs_tick range: -1.0 368900.0  next_tick range: -0.984803318977356 352700.0
normed next range: -1000000.0 18141.173828125
pred range: -729.6309204101562 14.727970123291016
mask valid positions: 19984.0 / 65536

>>> Gradient explosion detected, grad_norm= 1405377.7358146086
>>> Gradient explosion detected, grad_norm= 2354022.4632975925
[batch 60] loss=1.894833e+09 loss_diff=9.299861e-01 recon=1.894833e+09
obs_tick range: -0.9848047494888306 355200.0  next_tick range: -0.9914393424987793 368700.0
normed next range: -1000000.0 3740.71484375
pred range: -729.9994506835938 15.376703262329102
mask valid positions: 36220.0 / 65536

>>> Gradient explosion detected, grad_norm= 1002224.3919667989
>>> Gradient explosion detected, grad_norm= 3247499.1607429557
>>> Gradient explosion detected, grad_norm= 50261209.658753164
[batch 70] loss=5.196976e+08 loss_diff=9.341212e-01 recon=5.196976e+08
obs_tick range: -0.9993920922279358 371400.0  next_tick range: -1.0 371400.0
normed next range: -1000000.0 5930.49609375
pred range: -730.4033203125 29.119802474975586
mask valid positions: 36684.0 / 65536

>>> Gradient explosion detected, grad_norm= 56354550.239545904
>>> Gradient explosion detected, grad_norm= 169581085.87023485
[batch 80] loss=2.532754e+08 loss_diff=9.029330e-01 recon=2.532754e+08
obs_tick range: -1.0 390400.0  next_tick range: -1.0 393000.0
normed next range: -1000000.0 2509.16748046875
pred range: -731.427001953125 25.30021858215332
mask valid positions: 40145.0 / 65536

>>> Gradient explosion detected, grad_norm= 9281546.816080164
>>> Gradient explosion detected, grad_norm= 87030179.7683079
>>> Gradient explosion detected, grad_norm= 58681284.11598061
>>> Gradient explosion detected, grad_norm= 57481868.478254974
>>> Gradient explosion detected, grad_norm= 17617787.934872538
>>> Gradient explosion detected, grad_norm= 1066025.6066506498
>>> Gradient explosion detected, grad_norm= 17541666.595028933
[batch 90] loss=1.164904e+09 loss_diff=9.181453e-01 recon=1.164904e+09
obs_tick range: -0.9848085641860962 361000.0  next_tick range: -0.9930698871612549 650000.0
normed next range: -1000000.0 88010.8984375
pred range: -731.889892578125 15.494100570678711
mask valid positions: 35849.0 / 65536

>>> Gradient explosion detected, grad_norm= 1010753.2606592566
>>> Gradient explosion detected, grad_norm= 4710599.804136896
>>> Gradient explosion detected, grad_norm= 15434655.488253344
>>> Gradient explosion detected, grad_norm= 20860587.40725128
>>> Gradient explosion detected, grad_norm= 2126129.383342864
[batch 100] loss=1.499068e+09 loss_diff=8.850659e-01 recon=1.499068e+09
obs_tick range: -1.0 378000.0  next_tick range: -1.0 365800.0
normed next range: -1000000.0 9804.6171875
pred range: -731.8812255859375 15.797778129577637
mask valid positions: 39666.0 / 65536

>>> Gradient explosion detected, grad_norm= 1363785.494997206
>>> Gradient explosion detected, grad_norm= 15904351.568237923
>>> Gradient explosion detected, grad_norm= 9776629.97140266
>>> Gradient explosion detected, grad_norm= 16694125.86193315
>>> Gradient explosion detected, grad_norm= 131473285.9070226
>>> Gradient explosion detected, grad_norm= 1890272.0043657995
>>> Gradient explosion detected, grad_norm= 2066122.0881637868
[batch 110] loss=5.912490e+08 loss_diff=9.801790e-01 recon=5.912490e+08
obs_tick range: -0.9990484118461609 369000.0  next_tick range: -1.0 371400.0
normed next range: -1000000.0 12074.9287109375
pred range: -732.1083374023438 15.447174072265625
mask valid positions: 36697.0 / 65536

>>> Gradient explosion detected, grad_norm= 4125556.6164497253
>>> Gradient explosion detected, grad_norm= 1817015.0516697268
>>> Gradient explosion detected, grad_norm= 10449325.905792618
>>> Gradient explosion detected, grad_norm= 19456167.271501012
[batch 120] loss=8.971478e+08 loss_diff=8.842946e-01 recon=8.971478e+08
obs_tick range: -0.9990476965904236 364700.0  next_tick range: -1.0 363800.0
normed next range: -1000000.0 1000000.0
pred range: -732.42578125 15.608287811279297
mask valid positions: 57579.0 / 65536

>>> Gradient explosion detected, grad_norm= 14253961.396020439
>>> Gradient explosion detected, grad_norm= 10587079.798908656
[batch 130] loss=1.743020e+09 loss_diff=9.122856e-01 recon=1.743020e+09
obs_tick range: -1.0 365600.0  next_tick range: -1.0 365900.0
normed next range: -1000000.0 3029.5986328125
pred range: -732.6405639648438 23.33090591430664
mask valid positions: 58439.0 / 65536

>>> Gradient explosion detected, grad_norm= 12398483.337607708
>>> Gradient explosion detected, grad_norm= 1008561.0586134621
>>> Gradient explosion detected, grad_norm= 1586332.3945235433
[batch 140] loss=3.072266e+09 loss_diff=8.818063e-01 recon=3.072266e+09
obs_tick range: -0.968154788017273 367300.0  next_tick range: -0.9768896102905273 367300.0
normed next range: -1000000.0 2996.630126953125
pred range: -733.02783203125 33.96342849731445
mask valid positions: 51187.0 / 65536

>>> Gradient explosion detected, grad_norm= 40050479.73462299
>>> Gradient explosion detected, grad_norm= 24933313.657009687
>>> Gradient explosion detected, grad_norm= 30126554.648567867
>>> Gradient explosion detected, grad_norm= 3348154.057857526
>>> Gradient explosion detected, grad_norm= 2552146.2413240564
>>> Gradient explosion detected, grad_norm= 1282368.2481917725
>>> Gradient explosion detected, grad_norm= 44265568.589015365
[batch 150] loss=1.073313e+09 loss_diff=8.885790e-01 recon=1.073313e+09
obs_tick range: -0.9990479946136475 392900.0  next_tick range: -1.0 391500.0
normed next range: -1000000.0 1000000.0
pred range: -731.9613037109375 32.50623321533203
mask valid positions: 36673.0 / 65536

>>> Gradient explosion detected, grad_norm= 14428864.092280021
>>> Gradient explosion detected, grad_norm= 6915648.838794008
>>> Gradient explosion detected, grad_norm= 5360714.644223275
>>> Gradient explosion detected, grad_norm= 15454460.145287601
>>> Gradient explosion detected, grad_norm= 4047499.8305954677
>>> Gradient explosion detected, grad_norm= 45570039.871978514
==============================
[2015-08][Epoch 4/20] | Time = 5.67 min
 - Total Loss : 1533084314.120351 | Recon Loss: 1533084314.050277 | Diff Loss: 0.906245
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-08 completed in 22.54 min
[1] 2015-09 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-09 | file : news_20150930.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=7.639878e+08 loss_diff=8.589432e-01 recon=7.639878e+08
obs_tick range: -1.0 366700.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 3663.161376953125
pred range: -731.6005249023438 29.756498336791992
mask valid positions: 42216.0 / 65536

>>> Gradient explosion detected, grad_norm= 41651202.382569864
>>> Gradient explosion detected, grad_norm= 13686870.402073115
>>> Gradient explosion detected, grad_norm= 2429229.885296257
>>> Gradient explosion detected, grad_norm= 1970221.6188712039
>>> Gradient explosion detected, grad_norm= 4505718.524246039
>>> Gradient explosion detected, grad_norm= 8730827.184842113
>>> Gradient explosion detected, grad_norm= 9931862.031041414
>>> Gradient explosion detected, grad_norm= 6216728.270563099
>>> Gradient explosion detected, grad_norm= 2148023.694424602
[batch 10] loss=1.942999e+09 loss_diff=8.831444e-01 recon=1.942999e+09
obs_tick range: -1.0 392300.0  next_tick range: -1.0 392200.0
normed next range: -1000000.0 4408.7021484375
pred range: -734.0391235351562 15.254467964172363
mask valid positions: 52204.0 / 65536

>>> Gradient explosion detected, grad_norm= 12307835.268226523
>>> Gradient explosion detected, grad_norm= 38807423.13053939
>>> Gradient explosion detected, grad_norm= 33294234.204080693
>>> Gradient explosion detected, grad_norm= 15669867.883007208
>>> Gradient explosion detected, grad_norm= 17391755.03995622
>>> Gradient explosion detected, grad_norm= 1756603.833374403
>>> Gradient explosion detected, grad_norm= 16075415.739559112
>>> Gradient explosion detected, grad_norm= 8917910.73984787
[batch 20] loss=2.967021e+08 loss_diff=9.014031e-01 recon=2.967021e+08
obs_tick range: -0.9969200491905212 357500.0  next_tick range: -0.9992408752441406 366800.0
normed next range: -1000000.0 4427.15380859375
pred range: -734.2485961914062 16.309858322143555
mask valid positions: 49264.0 / 65536

>>> Gradient explosion detected, grad_norm= 11234302.817808993
>>> Gradient explosion detected, grad_norm= 1349325.852082043
>>> Gradient explosion detected, grad_norm= 43741150.48668475
>>> Gradient explosion detected, grad_norm= 8184340.707127487
>>> Gradient explosion detected, grad_norm= 376841095.3908677
[batch 30] loss=8.665671e+08 loss_diff=9.137472e-01 recon=8.665671e+08
obs_tick range: -0.999048113822937 650000.0  next_tick range: -1.0 387100.0
normed next range: -1000000.0 10608.205078125
pred range: -734.2822265625 15.877840042114258
mask valid positions: 50082.0 / 65536

>>> Gradient explosion detected, grad_norm= 5113498.799365915
>>> Gradient explosion detected, grad_norm= 1805657.7436019126
>>> Gradient explosion detected, grad_norm= 5824046.106189282
>>> Gradient explosion detected, grad_norm= 2537532.110845492
>>> Gradient explosion detected, grad_norm= 1166321.0020869682
>>> Gradient explosion detected, grad_norm= 1143152.3623430547
[batch 40] loss=6.476774e+02 loss_diff=9.331306e-01 recon=6.467443e+02
obs_tick range: -0.9870018362998962 330000.0  next_tick range: -0.9930715560913086 331500.0
normed next range: -4.264286994934082 11584.6103515625
pred range: -717.517578125 15.46058177947998
mask valid positions: 43225.0 / 65536

>>> Gradient explosion detected, grad_norm= 55032639.90308402
>>> Gradient explosion detected, grad_norm= 58263935.78685568
>>> Gradient explosion detected, grad_norm= 43012823.287655026
>>> Gradient explosion detected, grad_norm= 4330605.467551955
>>> Gradient explosion detected, grad_norm= 1527389.7562386405
[batch 50] loss=6.618020e+08 loss_diff=8.926780e-01 recon=6.618020e+08
obs_tick range: -1.0 375600.0  next_tick range: -0.999048113822937 375100.0
normed next range: -1000000.0 2624.072509765625
pred range: -734.1856079101562 14.845797538757324
mask valid positions: 34842.0 / 65536

>>> Gradient explosion detected, grad_norm= 16905014.422333136
>>> Gradient explosion detected, grad_norm= 12825004.151805462
>>> Gradient explosion detected, grad_norm= 69468071.94711897
>>> Gradient explosion detected, grad_norm= 1844703.963164461
>>> Gradient explosion detected, grad_norm= 1339553.3032223966
[batch 60] loss=2.440613e+09 loss_diff=8.474240e-01 recon=2.440613e+09
obs_tick range: -0.9993922710418701 378000.0  next_tick range: -1.0 378000.0
normed next range: -1000000.0 3335.765380859375
pred range: -734.6607666015625 15.361367225646973
mask valid positions: 38313.0 / 65536

>>> Gradient explosion detected, grad_norm= 3104310.9019357297
>>> Gradient explosion detected, grad_norm= 2559631.302216714
>>> Gradient explosion detected, grad_norm= 1754398.8405344244
>>> Gradient explosion detected, grad_norm= 9635726.152069533
>>> Gradient explosion detected, grad_norm= 1192866.4953788123
>>> Gradient explosion detected, grad_norm= 12210249.44730326
[batch 70] loss=2.627291e+02 loss_diff=9.026635e-01 recon=2.618265e+02
obs_tick range: -0.9848082065582275 380000.0  next_tick range: -0.9918777942657471 380000.0
normed next range: -9.07453727722168 5844.97900390625
pred range: -718.6171264648438 18.063859939575195
mask valid positions: 33986.0 / 65536

>>> Gradient explosion detected, grad_norm= 9595543.149322756
>>> Gradient explosion detected, grad_norm= 15984353.230470825
>>> Gradient explosion detected, grad_norm= 8707739.15745403
>>> Gradient explosion detected, grad_norm= 1151900.5757853214
>>> Gradient explosion detected, grad_norm= 1053703.9624346343
[batch 80] loss=4.049806e+08 loss_diff=9.387025e-01 recon=4.049806e+08
obs_tick range: -1.0 3089266.0  next_tick range: -0.9396881461143494 395000.0
normed next range: -1000000.0 4921.14013671875
pred range: -735.356689453125 19.603952407836914
mask valid positions: 34748.0 / 65536

>>> Gradient explosion detected, grad_norm= 1198094.483284998
>>> Gradient explosion detected, grad_norm= 2609423.418177097
[batch 90] loss=2.495038e+09 loss_diff=8.848552e-01 recon=2.495038e+09
obs_tick range: -1.0 392500.0  next_tick range: -1.0 392300.0
normed next range: -1000000.0 5731.87109375
pred range: -735.7092895507812 15.358782768249512
mask valid positions: 43917.0 / 65536

>>> Gradient explosion detected, grad_norm= 68579493.61606449
[batch 100] loss=9.021789e+08 loss_diff=8.694305e-01 recon=9.021789e+08
obs_tick range: -1.0 378500.0  next_tick range: -0.9990481734275818 367100.0
normed next range: -1000000.0 3270.191650390625
pred range: -736.4121704101562 19.22125244140625
mask valid positions: 35319.0 / 65536

>>> Gradient explosion detected, grad_norm= 3605772.2261730195
[batch 110] loss=1.995783e+09 loss_diff=8.614945e-01 recon=1.995783e+09
obs_tick range: -0.992551326751709 365700.0  next_tick range: -0.996920645236969 363400.0
normed next range: -1000000.0 4682.50927734375
pred range: -737.6821899414062 16.315736770629883
mask valid positions: 51000.0 / 65536

>>> Gradient explosion detected, grad_norm= 5008259.593228374
>>> Gradient explosion detected, grad_norm= 6479553.047559082
>>> Gradient explosion detected, grad_norm= 10634088.747811463
>>> Gradient explosion detected, grad_norm= 2571372.259993257
>>> Gradient explosion detected, grad_norm= 2285285.4373701205
[batch 120] loss=8.489377e+08 loss_diff=8.790872e-01 recon=8.489377e+08
obs_tick range: -0.9969194531440735 361600.0  next_tick range: -0.9993917346000671 375000.0
normed next range: -1000000.0 1989.9544677734375
pred range: -738.9844360351562 20.782712936401367
mask valid positions: 51115.0 / 65536

>>> Gradient explosion detected, grad_norm= 2284236.7754480815
>>> Gradient explosion detected, grad_norm= 12301060.294739706
>>> Gradient explosion detected, grad_norm= 56092035.46868552
>>> Gradient explosion detected, grad_norm= 1065365.4437371595
[batch 130] loss=2.443005e+09 loss_diff=8.759618e-01 recon=2.443005e+09
obs_tick range: -0.9961944818496704 352200.0  next_tick range: -0.9990480542182922 352500.0
normed next range: -1000000.0 4035.31298828125
pred range: -739.4036254882812 16.04585838317871
mask valid positions: 43997.0 / 65536

>>> Gradient explosion detected, grad_norm= 1854382.5276480885
>>> Gradient explosion detected, grad_norm= 2359888.844833859
>>> Gradient explosion detected, grad_norm= 2225874.4601589283
>>> Gradient explosion detected, grad_norm= 1698366.2995449323
>>> Gradient explosion detected, grad_norm= 1148422.707109954
>>> Gradient explosion detected, grad_norm= 1325038.4375310335
[batch 140] loss=3.673715e+08 loss_diff=9.027219e-01 recon=3.673715e+08
obs_tick range: -0.9961910843849182 394800.0  next_tick range: -0.9914441108703613 357500.0
normed next range: -1000000.0 5298.330078125
pred range: -740.0406494140625 15.34988784790039
mask valid positions: 35339.0 / 65536

>>> Gradient explosion detected, grad_norm= 11313230.992628623
>>> Gradient explosion detected, grad_norm= 5576094.076752067
[batch 150] loss=5.586248e+08 loss_diff=9.490223e-01 recon=5.586248e+08
obs_tick range: -0.9659258127212524 250000.0  next_tick range: -0.9762945175170898 365600.0
normed next range: -1000000.0 5210.45068359375
pred range: -740.6875610351562 15.099382400512695
mask valid positions: 42577.0 / 65536

>>> Gradient explosion detected, grad_norm= 2894809.7316199364
>>> Gradient explosion detected, grad_norm= 15321294.599680101
==============================
[2015-09][Epoch 1/20] | Time = 5.43 min
 - Total Loss : 1609762220.499121 | Recon Loss: 1609762220.437041 | Diff Loss: 0.898301
==============================
No improvement count: 1
[batch 0] loss=1.096980e+09 loss_diff=8.485078e-01 recon=1.096980e+09
obs_tick range: -1.0 379000.0  next_tick range: -1.0 379600.0
normed next range: -1000000.0 6097.23486328125
pred range: -740.960205078125 15.616549491882324
mask valid positions: 30454.0 / 65536

>>> Gradient explosion detected, grad_norm= 2393013.9361351156
>>> Gradient explosion detected, grad_norm= 4038758.655930554
[batch 10] loss=3.328270e+08 loss_diff=9.480368e-01 recon=3.328270e+08
obs_tick range: -0.9762959480285645 392700.0  next_tick range: -0.9659227728843689 392300.0
normed next range: -1000000.0 2372.896240234375
pred range: -742.0497436523438 14.285921096801758
mask valid positions: 50189.0 / 65536

>>> Gradient explosion detected, grad_norm= 1950957.4143797823
>>> Gradient explosion detected, grad_norm= 3250510.219512201
>>> Gradient explosion detected, grad_norm= 6059959.93956112
[batch 20] loss=1.356198e+09 loss_diff=9.212321e-01 recon=1.356198e+09
obs_tick range: -0.9848085641860962 370200.0  next_tick range: -0.9930698871612549 370200.0
normed next range: -1000000.0 15032.8984375
pred range: -742.6510620117188 16.387657165527344
mask valid positions: 43107.0 / 65536

>>> Gradient explosion detected, grad_norm= 2411286.3324530674
>>> Gradient explosion detected, grad_norm= 1445621.5540183454
[batch 30] loss=8.772196e+08 loss_diff=9.525214e-01 recon=8.772196e+08
obs_tick range: -1.0 327000.0  next_tick range: -0.9063061475753784 352000.0
normed next range: -1000000.0 13420.3984375
pred range: -743.5549926757812 24.574052810668945
mask valid positions: 42637.0 / 65536

>>> Gradient explosion detected, grad_norm= 5940386.953086854
[batch 40] loss=2.300410e+09 loss_diff=8.942002e-01 recon=2.300410e+09
obs_tick range: -0.9990483522415161 371500.0  next_tick range: -1.0 368000.0
normed next range: -1000000.0 21542.32421875
pred range: -744.432373046875 25.335947036743164
mask valid positions: 37056.0 / 65536

>>> Gradient explosion detected, grad_norm= 4052016.1917084483
>>> Gradient explosion detected, grad_norm= 1893200.721967809
[batch 50] loss=2.436133e+09 loss_diff=9.130490e-01 recon=2.436133e+09
obs_tick range: -0.9990479350090027 352500.0  next_tick range: -0.9993917942047119 329900.0
normed next range: -1000000.0 4439.52734375
pred range: -745.9034423828125 15.622323036193848
mask valid positions: 44306.0 / 65536

>>> Gradient explosion detected, grad_norm= 6669854.967407953
>>> Gradient explosion detected, grad_norm= 2401984.7615018873
[batch 60] loss=2.965770e+08 loss_diff=9.615022e-01 recon=2.965770e+08
obs_tick range: -0.9990481734275818 329600.0  next_tick range: -1.0 331100.0
normed next range: -1000000.0 4182.0419921875
pred range: -746.3414916992188 14.627997398376465
mask valid positions: 48976.0 / 65536

>>> Gradient explosion detected, grad_norm= 4648146.386199976
[batch 70] loss=4.598512e+08 loss_diff=8.924600e-01 recon=4.598512e+08
obs_tick range: -0.9990479350090027 379100.0  next_tick range: -1.0 379300.0
normed next range: -1000000.0 2962.433837890625
pred range: -747.4601440429688 14.312689781188965
mask valid positions: 50143.0 / 65536

>>> Gradient explosion detected, grad_norm= 1950385.5713392622
>>> Gradient explosion detected, grad_norm= 4627263.421618081
>>> Gradient explosion detected, grad_norm= 41845293.04781492
[batch 80] loss=1.757961e+06 loss_diff=9.104636e-01 recon=1.757960e+06
obs_tick range: -0.9870018362998962 365800.0  next_tick range: -0.9930715560913086 367500.0
normed next range: -1000000.0 13546.9208984375
pred range: -747.4146118164062 15.170623779296875
mask valid positions: 51684.0 / 65536

>>> Gradient explosion detected, grad_norm= 7676681.481918509
>>> Gradient explosion detected, grad_norm= 36523421.59778068
>>> Gradient explosion detected, grad_norm= 3485000.512958401
>>> Gradient explosion detected, grad_norm= 9535435.214469576
>>> Gradient explosion detected, grad_norm= 5729019.2451385325
>>> Gradient explosion detected, grad_norm= 2178657.8754682117
[batch 90] loss=1.323944e+09 loss_diff=8.859309e-01 recon=1.323944e+09
obs_tick range: -0.9762957692146301 367000.0  next_tick range: -0.9848076701164246 366900.0
normed next range: -1000000.0 6845.0703125
pred range: -749.4144897460938 15.592270851135254
mask valid positions: 50191.0 / 65536

>>> Gradient explosion detected, grad_norm= 11344154.078450726
>>> Gradient explosion detected, grad_norm= 159173241.51868746
>>> Gradient explosion detected, grad_norm= 140785511.19284454
>>> Gradient explosion detected, grad_norm= 120151924.0406706
>>> Gradient explosion detected, grad_norm= 71258367.36421408
>>> Gradient explosion detected, grad_norm= 32183471.982522745
>>> Gradient explosion detected, grad_norm= 2472123.385064696
[batch 100] loss=9.162157e+08 loss_diff=8.604573e-01 recon=9.162157e+08
obs_tick range: -1.0 371500.0  next_tick range: -1.0 371000.0
normed next range: -1000000.0 7152.646484375
pred range: -747.2722778320312 15.965664863586426
mask valid positions: 35571.0 / 65536

>>> Gradient explosion detected, grad_norm= 1650597.9690785033
>>> Gradient explosion detected, grad_norm= 2930720.446505981
>>> Gradient explosion detected, grad_norm= 1478716.399054476
>>> Gradient explosion detected, grad_norm= 3096953.808819502
>>> Gradient explosion detected, grad_norm= 3483981.7121317266
>>> Gradient explosion detected, grad_norm= 1927613.7522933309
[batch 110] loss=1.400680e+09 loss_diff=8.584189e-01 recon=1.400680e+09
obs_tick range: -0.9993910789489746 378400.0  next_tick range: -1.0 378500.0
normed next range: -1000000.0 10021.7021484375
pred range: -749.623291015625 13.998592376708984
mask valid positions: 28971.0 / 65536

>>> Gradient explosion detected, grad_norm= 9178338.148622151
>>> Gradient explosion detected, grad_norm= 2409457.77140671
>>> Gradient explosion detected, grad_norm= 2492221.7705208715
[batch 120] loss=5.444156e+08 loss_diff=8.804852e-01 recon=5.444156e+08
obs_tick range: -0.99692302942276 354100.0  next_tick range: -0.9990484118461609 354000.0
normed next range: -1000000.0 11225.25
pred range: -750.4281616210938 16.875314712524414
mask valid positions: 35184.0 / 65536

[batch 130] loss=4.502729e+08 loss_diff=9.158983e-01 recon=4.502729e+08
obs_tick range: -0.9914447069168091 363900.0  next_tick range: -0.9961932897567749 363900.0
normed next range: -1000000.0 9352.1923828125
pred range: -751.735107421875 18.673131942749023
mask valid positions: 42944.0 / 65536

>>> Gradient explosion detected, grad_norm= 2066408.1950079205
[batch 140] loss=6.088186e+08 loss_diff=8.777149e-01 recon=6.088186e+08
obs_tick range: -0.9971016645431519 350000.0  next_tick range: -0.9993922710418701 350000.0
normed next range: -1000000.0 4209.16552734375
pred range: -753.5308227539062 25.614133834838867
mask valid positions: 36084.0 / 65536

>>> Gradient explosion detected, grad_norm= 6263565.711558288
>>> Gradient explosion detected, grad_norm= 4379544.444181225
>>> Gradient explosion detected, grad_norm= 45055587.0407588
[batch 150] loss=2.080563e+09 loss_diff=9.206687e-01 recon=2.080563e+09
obs_tick range: -1.0 367400.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 3660.26953125
pred range: -754.6648559570312 13.72898006439209
mask valid positions: 37791.0 / 65536

>>> Gradient explosion detected, grad_norm= 20162119.678600978
>>> Gradient explosion detected, grad_norm= 9577656.632089807
==============================
[2015-09][Epoch 2/20] | Time = 5.67 min
 - Total Loss : 1408897715.477505 | Recon Loss: 1408897715.407826 | Diff Loss: 0.905454
==============================
No improvement count: 2
[batch 0] loss=1.382296e+09 loss_diff=8.948998e-01 recon=1.382296e+09
obs_tick range: -0.9990479946136475 362000.0  next_tick range: -1.0 369900.0
normed next range: -1000000.0 2564.836181640625
pred range: -755.1895141601562 13.460213661193848
mask valid positions: 49254.0 / 65536

>>> Gradient explosion detected, grad_norm= 21808507.589181293
>>> Gradient explosion detected, grad_norm= 5414463.042112446
>>> Gradient explosion detected, grad_norm= 4166755.1958134864
>>> Gradient explosion detected, grad_norm= 3682733.1416949225
[batch 10] loss=1.299772e+09 loss_diff=8.899299e-01 recon=1.299772e+09
obs_tick range: -1.0 374400.0  next_tick range: -1.0 375100.0
normed next range: -1000000.0 12051.12890625
pred range: -756.1057739257812 14.578189849853516
mask valid positions: 49034.0 / 65536

>>> Gradient explosion detected, grad_norm= 21743777.51925849
>>> Gradient explosion detected, grad_norm= 1850053.405719427
>>> Gradient explosion detected, grad_norm= 2269503.9775170074
>>> Gradient explosion detected, grad_norm= 2629123.416079693
>>> Gradient explosion detected, grad_norm= 1634994.8223236941
>>> Gradient explosion detected, grad_norm= 1433800.9672566662
>>> Gradient explosion detected, grad_norm= 23962423.82522457
[batch 20] loss=1.134983e+09 loss_diff=8.904911e-01 recon=1.134983e+09
obs_tick range: -0.9994696378707886 362000.0  next_tick range: -1.0 332400.0
normed next range: -1000000.0 9660.1748046875
pred range: -756.1032104492188 15.164518356323242
mask valid positions: 28314.0 / 65536

>>> Gradient explosion detected, grad_norm= 1053023.2302099634
>>> Gradient explosion detected, grad_norm= 7607297.137551545
>>> Gradient explosion detected, grad_norm= 2438796.101471021
>>> Gradient explosion detected, grad_norm= 2213372.2720979163
>>> Gradient explosion detected, grad_norm= 1069236.2127711514
[batch 30] loss=1.752290e+09 loss_diff=9.472931e-01 recon=1.752290e+09
obs_tick range: -0.9762940406799316 375000.0  next_tick range: -0.9659258127212524 375500.0
normed next range: -1000000.0 5187.96435546875
pred range: -756.5770874023438 13.865527153015137
mask valid positions: 43361.0 / 65536

>>> Gradient explosion detected, grad_norm= 30779831.67526553
>>> Gradient explosion detected, grad_norm= 10999488.218422232
>>> Gradient explosion detected, grad_norm= 10077136.900356196
>>> Gradient explosion detected, grad_norm= 18151505.91645865
[batch 40] loss=2.674766e+09 loss_diff=8.328446e-01 recon=2.674766e+09
obs_tick range: -0.9990483522415161 394000.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 2957.150634765625
pred range: -757.1572265625 14.249899864196777
mask valid positions: 52143.0 / 65536

>>> Gradient explosion detected, grad_norm= 37965012.13605312
>>> Gradient explosion detected, grad_norm= 2101212.9503739523
>>> Gradient explosion detected, grad_norm= 4179366.8892809628
>>> Gradient explosion detected, grad_norm= 3173230.481892052
>>> Gradient explosion detected, grad_norm= 1230145.9219651823
>>> Gradient explosion detected, grad_norm= 25226715.363957927
>>> Gradient explosion detected, grad_norm= 27646287.81478444
[batch 50] loss=2.053366e+09 loss_diff=9.116353e-01 recon=2.053366e+09
obs_tick range: -1.0 357600.0  next_tick range: -1.0 357500.0
normed next range: -1000000.0 2226.322509765625
pred range: -756.9033813476562 14.98072624206543
mask valid positions: 41031.0 / 65536

>>> Gradient explosion detected, grad_norm= 27816285.245003365
>>> Gradient explosion detected, grad_norm= 1332415.2616921726
>>> Gradient explosion detected, grad_norm= 2117295.7522598268
>>> Gradient explosion detected, grad_norm= 19211576.020428017
>>> Gradient explosion detected, grad_norm= 6894597.271785025
[batch 60] loss=2.534626e+09 loss_diff=9.034510e-01 recon=2.534626e+09
obs_tick range: -1.0 871959.0  next_tick range: -0.9990480542182922 367200.0
normed next range: -1000000.0 5351.66796875
pred range: -758.1131591796875 13.921429634094238
mask valid positions: 43491.0 / 65536

>>> Gradient explosion detected, grad_norm= 8232552.03479786
>>> Gradient explosion detected, grad_norm= 13873677.504856234
>>> Gradient explosion detected, grad_norm= 3872645.7496100706
[batch 70] loss=6.416772e+08 loss_diff=8.775502e-01 recon=6.416772e+08
obs_tick range: -0.9914442896842957 392700.0  next_tick range: -0.9961944222450256 392300.0
normed next range: -1000000.0 3666.41943359375
pred range: -757.6617431640625 14.559147834777832
mask valid positions: 42583.0 / 65536

>>> Gradient explosion detected, grad_norm= 5587878.48736469
>>> Gradient explosion detected, grad_norm= 12086617.591605896
[batch 80] loss=1.078220e+09 loss_diff=8.499541e-01 recon=1.078220e+09
obs_tick range: -0.9681728482246399 335400.0  next_tick range: -0.9762960076332092 357400.0
normed next range: -1000000.0 4463.10205078125
pred range: -758.5478515625 15.39052963256836
mask valid positions: 43696.0 / 65536

>>> Gradient explosion detected, grad_norm= 36486937.974840365
>>> Gradient explosion detected, grad_norm= 8085777.046863497
>>> Gradient explosion detected, grad_norm= 6694004.547191337
>>> Gradient explosion detected, grad_norm= 1043593.3893356204
>>> Gradient explosion detected, grad_norm= 2068190.2042102357
[batch 90] loss=8.047703e+08 loss_diff=9.479772e-01 recon=8.047703e+08
obs_tick range: -0.9396919012069702 393300.0  next_tick range: -0.9426503777503967 392900.0
normed next range: -1000000.0 3982.02490234375
pred range: -759.362060546875 15.179792404174805
mask valid positions: 34630.0 / 65536

>>> Gradient explosion detected, grad_norm= 1709695.213567096
>>> Gradient explosion detected, grad_norm= 11357145.207227899
>>> Gradient explosion detected, grad_norm= 2540618.3037419543
>>> Gradient explosion detected, grad_norm= 7542262.710177945
[batch 100] loss=2.809668e+09 loss_diff=9.502085e-01 recon=2.809668e+09
obs_tick range: -0.9990481734275818 370400.0  next_tick range: -0.99619460105896 371500.0
normed next range: -1000000.0 10342.017578125
pred range: -759.6541137695312 14.36334228515625
mask valid positions: 29046.0 / 65536

>>> Gradient explosion detected, grad_norm= 5459568.69663727
>>> Gradient explosion detected, grad_norm= 7641371.304016903
>>> Gradient explosion detected, grad_norm= 1099426.4294165699
>>> Gradient explosion detected, grad_norm= 13339841.441649819
[batch 110] loss=1.648778e+09 loss_diff=9.080256e-01 recon=1.648778e+09
obs_tick range: -0.9914456605911255 369500.0  next_tick range: -0.9972506761550903 366500.0
normed next range: -1000000.0 7711.13232421875
pred range: -760.58251953125 18.09956169128418
mask valid positions: 43880.0 / 65536

>>> Gradient explosion detected, grad_norm= 3382788.220180057
>>> Gradient explosion detected, grad_norm= 10311103.886893706
[batch 120] loss=1.809339e+09 loss_diff=9.025171e-01 recon=1.809339e+09
obs_tick range: -0.9993915557861328 375000.0  next_tick range: -1.0 375000.0
normed next range: -1000000.0 11352.7109375
pred range: -761.4226684570312 19.246925354003906
mask valid positions: 30605.0 / 65536

>>> Gradient explosion detected, grad_norm= 8919301.434428535
>>> Gradient explosion detected, grad_norm= 1101713.8854988213
>>> Gradient explosion detected, grad_norm= 1056107.5370158253
[batch 130] loss=6.068047e+08 loss_diff=8.255249e-01 recon=6.068047e+08
obs_tick range: -0.991443932056427 361000.0  next_tick range: -0.9848071336746216 366200.0
normed next range: -1000000.0 8068.05859375
pred range: -762.1664428710938 19.57731056213379
mask valid positions: 34857.0 / 65536

>>> Gradient explosion detected, grad_norm= 7749529.528239969
>>> Gradient explosion detected, grad_norm= 1562361.9981533373
>>> Gradient explosion detected, grad_norm= 1104788.9547191574
>>> Gradient explosion detected, grad_norm= 6243736.664908904
[batch 140] loss=1.538852e+09 loss_diff=8.711930e-01 recon=1.538852e+09
obs_tick range: -0.9762964248657227 394000.0  next_tick range: -0.9862880110740662 378400.0
normed next range: -1000000.0 9058.4130859375
pred range: -762.8956909179688 14.309589385986328
mask valid positions: 29790.0 / 65536

>>> Gradient explosion detected, grad_norm= 4064492.517916249
>>> Gradient explosion detected, grad_norm= 4400018.402500733
>>> Gradient explosion detected, grad_norm= 11370368.363997227
>>> Gradient explosion detected, grad_norm= 5583224.422190563
>>> Gradient explosion detected, grad_norm= 8296195.976399571
[batch 150] loss=5.216345e+08 loss_diff=8.238492e-01 recon=5.216345e+08
obs_tick range: -1.0 371500.0  next_tick range: -0.9949765801429749 367400.0
normed next range: -1000000.0 4709.9296875
pred range: -762.7550659179688 13.946523666381836
mask valid positions: 27322.0 / 65536

>>> Gradient explosion detected, grad_norm= 1032995.4846097135
>>> Gradient explosion detected, grad_norm= 6881970.793887173
>>> Gradient explosion detected, grad_norm= 6732104.905040669
>>> Gradient explosion detected, grad_norm= 1765832.536570017
>>> Gradient explosion detected, grad_norm= 1860294.8106611161
==============================
[2015-09][Epoch 3/20] | Time = 5.67 min
 - Total Loss : 1392953307.920599 | Recon Loss: 1392953307.856785 | Diff Loss: 0.906905
==============================
No improvement count: 3
[batch 0] loss=4.901476e+08 loss_diff=8.547192e-01 recon=4.901476e+08
obs_tick range: -0.9238789081573486 395000.0  next_tick range: -0.9238707423210144 361000.0
normed next range: -1000000.0 5345.447265625
pred range: -763.2186889648438 15.037582397460938
mask valid positions: 35005.0 / 65536

>>> Gradient explosion detected, grad_norm= 1055947.2902322407
>>> Gradient explosion detected, grad_norm= 1009742.4137755826
>>> Gradient explosion detected, grad_norm= 5440859.591029185
>>> Gradient explosion detected, grad_norm= 13280125.305246875
>>> Gradient explosion detected, grad_norm= 3627523.9653526125
>>> Gradient explosion detected, grad_norm= 9098550.981511258
[batch 10] loss=3.519682e+03 loss_diff=9.539512e-01 recon=3.518729e+03
obs_tick range: -0.9990481734275818 379900.0  next_tick range: -0.9990479350090027 379100.0
normed next range: -2.4748735427856445 2181.697265625
pred range: -301.37591552734375 11.445570945739746
mask valid positions: 51979.0 / 65536

>>> Gradient explosion detected, grad_norm= 3574523.965742037
>>> Gradient explosion detected, grad_norm= 8460117.733585767
>>> Gradient explosion detected, grad_norm= 2778339.611545685
>>> Gradient explosion detected, grad_norm= 3484478.989192854
[batch 20] loss=1.396571e+09 loss_diff=9.021990e-01 recon=1.396571e+09
obs_tick range: -1.0 370200.0  next_tick range: -0.9990479350090027 369000.0
normed next range: -1000000.0 5016.61767578125
pred range: -764.1671752929688 13.078140258789062
mask valid positions: 35294.0 / 65536

>>> Gradient explosion detected, grad_norm= 11926974.189826388
>>> Gradient explosion detected, grad_norm= 16648388.93917368
>>> Gradient explosion detected, grad_norm= 1691629.735990528
[batch 30] loss=5.434488e+08 loss_diff=8.609130e-01 recon=5.434488e+08
obs_tick range: -0.9961913228034973 379500.0  next_tick range: -0.99144047498703 379500.0
normed next range: -1000000.0 5047.3251953125
pred range: -764.76171875 14.693110466003418
mask valid positions: 50280.0 / 65536

>>> Gradient explosion detected, grad_norm= 15204609.941730073
[batch 40] loss=9.120241e+08 loss_diff=8.557010e-01 recon=9.120241e+08
obs_tick range: -1.0 393300.0  next_tick range: -0.9930715560913086 395000.0
normed next range: -1000000.0 7794.43310546875
pred range: -765.4544067382812 16.138612747192383
mask valid positions: 35633.0 / 65536

>>> Gradient explosion detected, grad_norm= 8222274.534666725
[batch 50] loss=1.124979e+09 loss_diff=9.484026e-01 recon=1.124979e+09
obs_tick range: -1.0 332400.0  next_tick range: -0.939687967300415 368700.0
normed next range: -1000000.0 2126.8115234375
pred range: -766.6775512695312 15.774575233459473
mask valid positions: 50916.0 / 65536

>>> Gradient explosion detected, grad_norm= 3697105.1363852182
>>> Gradient explosion detected, grad_norm= 3234228.518709873
>>> Gradient explosion detected, grad_norm= 52050463.32829083
>>> Gradient explosion detected, grad_norm= 4031463.5779958926
>>> Gradient explosion detected, grad_norm= 16234948.615319079
>>> Gradient explosion detected, grad_norm= 7229411.853014454
>>> Gradient explosion detected, grad_norm= 9328989.257322947
>>> Gradient explosion detected, grad_norm= 100945824.82795879
[batch 60] loss=1.578204e+09 loss_diff=9.488782e-01 recon=1.578204e+09
obs_tick range: -1.0 368700.0  next_tick range: -0.999048113822937 378400.0
normed next range: -1000000.0 1888.77685546875
pred range: -767.7716064453125 16.890396118164062
mask valid positions: 49700.0 / 65536

>>> Gradient explosion detected, grad_norm= 10137238.468746988
>>> Gradient explosion detected, grad_norm= 7800746.6433397215
>>> Gradient explosion detected, grad_norm= 11492972.80740903
>>> Gradient explosion detected, grad_norm= 1696857.6566701964
>>> Gradient explosion detected, grad_norm= 51093974.83647106
>>> Gradient explosion detected, grad_norm= 196954514.2588111
>>> Gradient explosion detected, grad_norm= 42769707.14320624
>>> Gradient explosion detected, grad_norm= 72684115.1959641
[batch 70] loss=2.219002e+09 loss_diff=8.507446e-01 recon=2.219002e+09
obs_tick range: -0.9961943626403809 364900.0  next_tick range: -0.99692302942276 363900.0
normed next range: -1000000.0 6511.4072265625
pred range: -766.3637084960938 15.858943939208984
mask valid positions: 42957.0 / 65536

>>> Gradient explosion detected, grad_norm= 31779079.27235628
>>> Gradient explosion detected, grad_norm= 13801167.79461168
>>> Gradient explosion detected, grad_norm= 1104768.847053938
>>> Gradient explosion detected, grad_norm= 1012153.2174057201
[batch 80] loss=3.693945e+08 loss_diff=9.154882e-01 recon=3.693945e+08
obs_tick range: -0.9762945175170898 367500.0  next_tick range: -0.9848071932792664 3089266.0
normed next range: -1000000.0 10690.3076171875
pred range: -767.2586059570312 21.61589813232422
mask valid positions: 33914.0 / 65536

>>> Gradient explosion detected, grad_norm= 2090674.6406302082
[batch 90] loss=7.548726e+08 loss_diff=8.593086e-01 recon=7.548726e+08
obs_tick range: -0.9961949586868286 380000.0  next_tick range: -0.9993934631347656 379900.0
normed next range: -1000000.0 4168.1689453125
pred range: -768.48046875 25.049392700195312
mask valid positions: 50867.0 / 65536

>>> Gradient explosion detected, grad_norm= 1446226.0193707205
[batch 100] loss=8.781256e+08 loss_diff=8.754597e-01 recon=8.781256e+08
obs_tick range: -0.9990478754043579 368000.0  next_tick range: -0.9961942434310913 368000.0
normed next range: -1000000.0 10388.6064453125
pred range: -769.9232177734375 13.908045768737793
mask valid positions: 29048.0 / 65536

>>> Gradient explosion detected, grad_norm= 2763354.421061209
>>> Gradient explosion detected, grad_norm= 1745369.2729001502
>>> Gradient explosion detected, grad_norm= 6120635.198029432
[batch 110] loss=2.011718e+09 loss_diff=9.213634e-01 recon=2.011718e+09
obs_tick range: -1.0 362700.0  next_tick range: -1.0 362200.0
normed next range: -1000000.0 11419.9072265625
pred range: -771.0037231445312 15.24868392944336
mask valid positions: 43727.0 / 65536

>>> Gradient explosion detected, grad_norm= 15758681.867821835
>>> Gradient explosion detected, grad_norm= 13827509.408798106
>>> Gradient explosion detected, grad_norm= 24750407.15877002
[batch 120] loss=7.084665e+08 loss_diff=9.103748e-01 recon=7.084665e+08
obs_tick range: -0.9848071336746216 368400.0  next_tick range: -0.9914413094520569 365000.0
normed next range: -1000000.0 4299.62841796875
pred range: -771.6871337890625 14.130988121032715
mask valid positions: 43309.0 / 65536

>>> Gradient explosion detected, grad_norm= 2145611.1267742673
>>> Gradient explosion detected, grad_norm= 15066773.224883933
[batch 130] loss=1.645496e+09 loss_diff=9.035519e-01 recon=1.645496e+09
obs_tick range: -0.999048113822937 3089266.0  next_tick range: -1.0 363100.0
normed next range: -1000000.0 36711.171875
pred range: -772.7146606445312 14.302274703979492
mask valid positions: 50973.0 / 65536

>>> Gradient explosion detected, grad_norm= 6578381.153588705
[batch 140] loss=1.937553e+09 loss_diff=9.250339e-01 recon=1.937553e+09
obs_tick range: -0.999048113822937 368700.0  next_tick range: -1.0 368700.0
normed next range: -1000000.0 8968.8642578125
pred range: -773.9103393554688 17.642351150512695
mask valid positions: 37667.0 / 65536

>>> Gradient explosion detected, grad_norm= 4294340.930470077
>>> Gradient explosion detected, grad_norm= 1866520.810731545
>>> Gradient explosion detected, grad_norm= 1790256.16131013
>>> Gradient explosion detected, grad_norm= 10072881.22390091
[batch 150] loss=9.819885e+08 loss_diff=9.002692e-01 recon=9.819885e+08
obs_tick range: -0.984807014465332 378400.0  next_tick range: -0.9914422631263733 375200.0
normed next range: -1000000.0 2969.139404296875
pred range: -775.5142211914062 29.034526824951172
mask valid positions: 34757.0 / 65536

>>> Gradient explosion detected, grad_norm= 5132155.135584217
==============================
[2015-09][Epoch 4/20] | Time = 5.68 min
 - Total Loss : 1339322191.528929 | Recon Loss: 1339322191.457627 | Diff Loss: 0.897968
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-09 completed in 22.44 min
[1] 2015-10 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-10 | file : news_20151031.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.601341e+09 loss_diff=9.014717e-01 recon=1.601341e+09
obs_tick range: -0.9993932247161865 369000.0  next_tick range: -1.0 368900.0
normed next range: -1000000.0 37359.4453125
pred range: -776.3851318359375 33.247276306152344
mask valid positions: 37130.0 / 65536

[batch 10] loss=3.192912e+03 loss_diff=8.480107e-01 recon=3.192064e+03
obs_tick range: -1.0 361000.0  next_tick range: -0.9993917346000671 361000.0
normed next range: -8.23180103302002 19321.07421875
pred range: -141.84707641601562 31.637182235717773
mask valid positions: 29472.0 / 65536

>>> Gradient explosion detected, grad_norm= 10409605.460626753
>>> Gradient explosion detected, grad_norm= 30228312.861466564
>>> Gradient explosion detected, grad_norm= 82737283.31121424
>>> Gradient explosion detected, grad_norm= 132227053.70530489
>>> Gradient explosion detected, grad_norm= 12191062.87715314
[batch 20] loss=4.513272e+08 loss_diff=8.604527e-01 recon=4.513272e+08
obs_tick range: -0.9681508541107178 388500.0  next_tick range: -0.9781502485275269 390800.0
normed next range: -1000000.0 9961.529296875
pred range: -777.6875 21.64276695251465
mask valid positions: 19510.0 / 65536

>>> Gradient explosion detected, grad_norm= 1769591.4131299537
>>> Gradient explosion detected, grad_norm= 1326150.4214733525
[batch 30] loss=1.843771e+09 loss_diff=9.106986e-01 recon=1.843771e+09
obs_tick range: -0.9971016645431519 384100.0  next_tick range: -0.9993922710418701 382400.0
normed next range: -1000000.0 7366.1201171875
pred range: -778.6151123046875 17.535619735717773
mask valid positions: 43521.0 / 65536

>>> Gradient explosion detected, grad_norm= 5686086.524270138
>>> Gradient explosion detected, grad_norm= 4333250.309787988
>>> Gradient explosion detected, grad_norm= 2765886.846986577
[batch 40] loss=3.265916e+08 loss_diff=9.401003e-01 recon=3.265916e+08
obs_tick range: -1.0 365800.0  next_tick range: -0.9990481734275818 365400.0
normed next range: -1000000.0 1643.7391357421875
pred range: -779.677978515625 14.50256061553955
mask valid positions: 57541.0 / 65536

>>> Gradient explosion detected, grad_norm= 2298719.3647175645
>>> Gradient explosion detected, grad_norm= 3872939.970237158
[batch 50] loss=8.859347e+08 loss_diff=9.024827e-01 recon=8.859347e+08
obs_tick range: -0.9961941242218018 500000.0  next_tick range: -0.9961943030357361 395700.0
normed next range: -1000000.0 7244.71923828125
pred range: -780.0963134765625 16.2933349609375
mask valid positions: 50617.0 / 65536

>>> Gradient explosion detected, grad_norm= 32862437.322788656
>>> Gradient explosion detected, grad_norm= 17492576.380771868
[batch 60] loss=1.567194e+09 loss_diff=8.748362e-01 recon=1.567194e+09
obs_tick range: -0.9990481734275818 375000.0  next_tick range: -1.0 378400.0
normed next range: -1000000.0 1368.1322021484375
pred range: -781.1875 16.401260375976562
mask valid positions: 50623.0 / 65536

>>> Gradient explosion detected, grad_norm= 13556568.9952932
>>> Gradient explosion detected, grad_norm= 1598599.6922654652
>>> Gradient explosion detected, grad_norm= 1040024.5440209066
[batch 70] loss=1.369629e+09 loss_diff=9.082242e-01 recon=1.369629e+09
obs_tick range: -0.9961945414543152 369500.0  next_tick range: -0.9990480542182922 368400.0
normed next range: -1000000.0 1794.885498046875
pred range: -781.9043579101562 15.673766136169434
mask valid positions: 58323.0 / 65536

>>> Gradient explosion detected, grad_norm= 1038274.4689631651
>>> Gradient explosion detected, grad_norm= 53817933.74088217
[batch 80] loss=2.139993e+09 loss_diff=9.036640e-01 recon=2.139993e+09
obs_tick range: -0.9925476908683777 393900.0  next_tick range: -0.9972506761550903 393700.0
normed next range: -1000000.0 2726.239990234375
pred range: -782.6481323242188 16.594030380249023
mask valid positions: 43861.0 / 65536

>>> Gradient explosion detected, grad_norm= 8233921.4001064
>>> Gradient explosion detected, grad_norm= 32688264.138078716
>>> Gradient explosion detected, grad_norm= 28948339.484303422
>>> Gradient explosion detected, grad_norm= 10912806.636483561
>>> Gradient explosion detected, grad_norm= 13590079.208258234
>>> Gradient explosion detected, grad_norm= 10924818.657681772
>>> Gradient explosion detected, grad_norm= 4375967.255933804
[batch 90] loss=6.713216e+01 loss_diff=8.672931e-01 recon=6.626487e+01
obs_tick range: -0.999048113822937 364600.0  next_tick range: -0.9961945414543152 365600.0
normed next range: -7.067724227905273 2400.57177734375
pred range: -769.9588012695312 15.129119873046875
mask valid positions: 50776.0 / 65536

>>> Gradient explosion detected, grad_norm= 195079602.75520948
>>> Gradient explosion detected, grad_norm= 208065430.89578208
>>> Gradient explosion detected, grad_norm= 157952033.0105722
>>> Gradient explosion detected, grad_norm= 212023392.94991907
>>> Gradient explosion detected, grad_norm= 366828206.1527225
>>> Gradient explosion detected, grad_norm= 7223827.000103341
>>> Gradient explosion detected, grad_norm= 2464523.9862777637
>>> Gradient explosion detected, grad_norm= 13691395.430840217
[batch 100] loss=1.156577e+09 loss_diff=8.489689e-01 recon=1.156577e+09
obs_tick range: -1.0 371700.0  next_tick range: -1.0 373300.0
normed next range: -1000000.0 1911.8599853515625
pred range: -782.7791137695312 19.087112426757812
mask valid positions: 50858.0 / 65536

>>> Gradient explosion detected, grad_norm= 5211638.674000833
>>> Gradient explosion detected, grad_norm= 3024443.612583494
>>> Gradient explosion detected, grad_norm= 7250469.327352149
>>> Gradient explosion detected, grad_norm= 6268366.050145108
>>> Gradient explosion detected, grad_norm= 5249018.222345091
>>> Gradient explosion detected, grad_norm= 3852611.5214232747
>>> Gradient explosion detected, grad_norm= 10257424.42879057
>>> Gradient explosion detected, grad_norm= 4421549.182765232
>>> Gradient explosion detected, grad_norm= 11020830.663084926
[batch 110] loss=4.884289e+08 loss_diff=8.636907e-01 recon=4.884289e+08
obs_tick range: -0.9961928725242615 393300.0  next_tick range: -0.9914445281028748 393900.0
normed next range: -1000000.0 2881.79345703125
pred range: -782.850341796875 23.4326171875
mask valid positions: 36242.0 / 65536

>>> Gradient explosion detected, grad_norm= 8253102.4336870825
>>> Gradient explosion detected, grad_norm= 1584285.499411214
[batch 120] loss=1.151896e+09 loss_diff=9.230582e-01 recon=1.151896e+09
obs_tick range: -1.0 369000.0  next_tick range: -0.9914445281028748 378000.0
normed next range: -1000000.0 2004.714111328125
pred range: -783.8486328125 16.621139526367188
mask valid positions: 34752.0 / 65536

>>> Gradient explosion detected, grad_norm= 4445311.486362171
>>> Gradient explosion detected, grad_norm= 22173801.096978847
>>> Gradient explosion detected, grad_norm= 1087343.0571347855
[batch 130] loss=3.892795e+08 loss_diff=8.857635e-01 recon=3.892795e+08
obs_tick range: -0.9961943030357361 378400.0  next_tick range: -0.9914442896842957 375200.0
normed next range: -1000000.0 12707.580078125
pred range: -784.188720703125 15.593889236450195
mask valid positions: 35678.0 / 65536

>>> Gradient explosion detected, grad_norm= 88713283.2763236
>>> Gradient explosion detected, grad_norm= 16142990.476424063
>>> Gradient explosion detected, grad_norm= 1827238.8456024264
>>> Gradient explosion detected, grad_norm= 431175947.18863344
>>> Gradient explosion detected, grad_norm= 4237764.731072811
>>> Gradient explosion detected, grad_norm= 4519143.661829254
>>> Gradient explosion detected, grad_norm= 1919220.1478509065
>>> Gradient explosion detected, grad_norm= 1217054.2945419825
[batch 140] loss=1.924361e+08 loss_diff=9.266852e-01 recon=1.924361e+08
obs_tick range: -0.9914413094520569 372600.0  next_tick range: -0.9961902499198914 372600.0
normed next range: -1000000.0 1588.2548828125
pred range: -784.364013671875 14.631616592407227
mask valid positions: 48119.0 / 65536

>>> Gradient explosion detected, grad_norm= 1301706.1617103762
>>> Gradient explosion detected, grad_norm= 2397529.3901737113
>>> Gradient explosion detected, grad_norm= 2856822.470734339
>>> Gradient explosion detected, grad_norm= 2085594.8342562735
[batch 150] loss=2.498026e+08 loss_diff=8.835552e-01 recon=2.498026e+08
obs_tick range: -0.9762953519821167 364700.0  next_tick range: -0.9659263491630554 394000.0
normed next range: -1000000.0 7194.22998046875
pred range: -784.8742065429688 23.672697067260742
mask valid positions: 42881.0 / 65536

>>> Gradient explosion detected, grad_norm= 1467368.0825025048
>>> Gradient explosion detected, grad_norm= 4699753.097236743
==============================
[2015-10][Epoch 1/20] | Time = 5.43 min
 - Total Loss : 1496456463.259476 | Recon Loss: 1496456463.196114 | Diff Loss: 0.896926
==============================
No improvement count: 1
[batch 0] loss=1.161972e+02 loss_diff=8.594093e-01 recon=1.153378e+02
obs_tick range: -0.9396923780441284 368700.0  next_tick range: -0.9238730669021606 368700.0
normed next range: -2.327073097229004 3666.323974609375
pred range: -185.826171875 28.0789794921875
mask valid positions: 51761.0 / 65536

>>> Gradient explosion detected, grad_norm= 1463053.8420638863
>>> Gradient explosion detected, grad_norm= 2272932.1164767235
>>> Gradient explosion detected, grad_norm= 5981024.985313111
[batch 10] loss=7.855239e+08 loss_diff=8.571530e-01 recon=7.855239e+08
obs_tick range: -0.9961941242218018 357400.0  next_tick range: -0.9961941242218018 1750000.0
normed next range: -1000000.0 49911.23828125
pred range: -785.2615966796875 12.276066780090332
mask valid positions: 51077.0 / 65536

>>> Gradient explosion detected, grad_norm= 5267380.161769112
>>> Gradient explosion detected, grad_norm= 3520786.9375122054
[batch 20] loss=4.353228e+08 loss_diff=8.783224e-01 recon=4.353228e+08
obs_tick range: -0.991443932056427 395000.0  next_tick range: -0.9961946606636047 395000.0
normed next range: -1000000.0 3556.54248046875
pred range: -785.7923583984375 11.908732414245605
mask valid positions: 48794.0 / 65536

>>> Gradient explosion detected, grad_norm= 24175076.6429832
>>> Gradient explosion detected, grad_norm= 31545092.517574903
>>> Gradient explosion detected, grad_norm= 16726844.625278534
[batch 30] loss=4.061307e+08 loss_diff=9.195678e-01 recon=4.061307e+08
obs_tick range: -0.999048113822937 352000.0  next_tick range: -0.9961944222450256 352000.0
normed next range: -1000000.0 1753.1068115234375
pred range: -786.7316284179688 15.481766700744629
mask valid positions: 49844.0 / 65536

>>> Gradient explosion detected, grad_norm= 1327856.4095808857
>>> Gradient explosion detected, grad_norm= 15659854.205100108
>>> Gradient explosion detected, grad_norm= 15137012.11296477
>>> Gradient explosion detected, grad_norm= 1830709.2027345055
>>> Gradient explosion detected, grad_norm= 2906338.1981689855
[batch 40] loss=1.680787e+09 loss_diff=8.586856e-01 recon=1.680787e+09
obs_tick range: -1.0 379900.0  next_tick range: -1.0 379000.0
normed next range: -1000000.0 5156.41796875
pred range: -787.335205078125 15.38574504852295
mask valid positions: 58330.0 / 65536

>>> Gradient explosion detected, grad_norm= 14499939.078938374
>>> Gradient explosion detected, grad_norm= 6714133.593137454
[batch 50] loss=5.298327e+08 loss_diff=8.558920e-01 recon=5.298327e+08
obs_tick range: -0.9992408752441406 366800.0  next_tick range: -1.0 366700.0
normed next range: -1000000.0 26544.04296875
pred range: -787.7416381835938 15.365801811218262
mask valid positions: 29811.0 / 65536

>>> Gradient explosion detected, grad_norm= 30330570.63234286
>>> Gradient explosion detected, grad_norm= 52436373.36962311
>>> Gradient explosion detected, grad_norm= 22451651.713061113
>>> Gradient explosion detected, grad_norm= 8010594.964970287
[batch 60] loss=4.297132e+08 loss_diff=9.113871e-01 recon=4.297132e+08
obs_tick range: -1.0 392600.0  next_tick range: -1.0 394500.0
normed next range: -1000000.0 2132.326416015625
pred range: -788.33642578125 14.704840660095215
mask valid positions: 50699.0 / 65536

>>> Gradient explosion detected, grad_norm= 59117126.94338547
>>> Gradient explosion detected, grad_norm= 1096024.4809679408
>>> Gradient explosion detected, grad_norm= 12449324.428162904
[batch 70] loss=1.798699e+09 loss_diff=9.533105e-01 recon=1.798699e+09
obs_tick range: -0.9762954115867615 380300.0  next_tick range: -0.9659254550933838 380000.0
normed next range: -1000000.0 4612.5234375
pred range: -788.692138671875 15.777669906616211
mask valid positions: 58187.0 / 65536

>>> Gradient explosion detected, grad_norm= 2300593.854119366
>>> Gradient explosion detected, grad_norm= 6502282.205600148
>>> Gradient explosion detected, grad_norm= 3535570.891201107
>>> Gradient explosion detected, grad_norm= 1223281.9127030442
>>> Gradient explosion detected, grad_norm= 52684074.15589115
>>> Gradient explosion detected, grad_norm= 14945419.531586764
[batch 80] loss=2.372314e+09 loss_diff=9.846686e-01 recon=2.372314e+09
obs_tick range: -0.9914442896842957 393600.0  next_tick range: -0.9961944222450256 395800.0
normed next range: -1000000.0 1000000.0
pred range: -788.75341796875 14.554678916931152
mask valid positions: 43633.0 / 65536

>>> Gradient explosion detected, grad_norm= 9700647.554603396
>>> Gradient explosion detected, grad_norm= 18162195.01444478
>>> Gradient explosion detected, grad_norm= 17328710.28102889
>>> Gradient explosion detected, grad_norm= 1188084.2352990105
[batch 90] loss=4.467817e+08 loss_diff=8.906059e-01 recon=4.467817e+08
obs_tick range: -0.9848062992095947 363100.0  next_tick range: -0.991443395614624 362700.0
normed next range: -1000000.0 2158.9853515625
pred range: -789.2877807617188 14.805195808410645
mask valid positions: 49982.0 / 65536

>>> Gradient explosion detected, grad_norm= 2394574.419924683
>>> Gradient explosion detected, grad_norm= 2696608.0742992614
>>> Gradient explosion detected, grad_norm= 10228433.15144688
>>> Gradient explosion detected, grad_norm= 1127504.0844940343
[batch 100] loss=5.576956e+08 loss_diff=8.817437e-01 recon=5.576956e+08
obs_tick range: -1.0 394800.0  next_tick range: -1.0 393300.0
normed next range: -1000000.0 1000000.0
pred range: -788.6896362304688 14.79045295715332
mask valid positions: 43297.0 / 65536

>>> Gradient explosion detected, grad_norm= 9730874.11520793
>>> Gradient explosion detected, grad_norm= 4504526.272653646
>>> Gradient explosion detected, grad_norm= 26654890.933122106
>>> Gradient explosion detected, grad_norm= 22427478.213847082
>>> Gradient explosion detected, grad_norm= 35493461.40424057
[batch 110] loss=3.269873e+08 loss_diff=8.333418e-01 recon=3.269873e+08
obs_tick range: -1.0 367100.0  next_tick range: -1.0 357400.0
normed next range: -1000000.0 2994.8740234375
pred range: -789.5748291015625 15.208474159240723
mask valid positions: 49974.0 / 65536

>>> Gradient explosion detected, grad_norm= 2565656.9326063762
>>> Gradient explosion detected, grad_norm= 2541912.719148057
>>> Gradient explosion detected, grad_norm= 1715019.217792669
>>> Gradient explosion detected, grad_norm= 3433286.378033504
>>> Gradient explosion detected, grad_norm= 143123915.82374132
[batch 120] loss=1.703435e+09 loss_diff=8.503331e-01 recon=1.703435e+09
obs_tick range: -0.9993910789489746 393300.0  next_tick range: -1.0 393900.0
normed next range: -1000000.0 4666.77294921875
pred range: -790.1173706054688 15.9259672164917
mask valid positions: 52276.0 / 65536

>>> Gradient explosion detected, grad_norm= 10127371.799607882
>>> Gradient explosion detected, grad_norm= 10792643.04701133
>>> Gradient explosion detected, grad_norm= 3990213.7056632265
>>> Gradient explosion detected, grad_norm= 294975461.23040104
>>> Gradient explosion detected, grad_norm= 5861935.147539849
>>> Gradient explosion detected, grad_norm= 42638260.557916
[batch 130] loss=1.667230e+09 loss_diff=8.740370e-01 recon=1.667230e+09
obs_tick range: -0.999048113822937 368000.0  next_tick range: -0.9994773268699646 368900.0
normed next range: -1000000.0 1763.2545166015625
pred range: -790.19921875 15.130053520202637
mask valid positions: 44319.0 / 65536

>>> Gradient explosion detected, grad_norm= 5046055.745200855
>>> Gradient explosion detected, grad_norm= 1303778.9566649124
>>> Gradient explosion detected, grad_norm= 24429076.227481324
[batch 140] loss=6.066211e+08 loss_diff=9.379375e-01 recon=6.066211e+08
obs_tick range: -0.9990481734275818 361000.0  next_tick range: -1.0 357500.0
normed next range: -1000000.0 5619.38671875
pred range: -790.6612548828125 16.136293411254883
mask valid positions: 40252.0 / 65536

>>> Gradient explosion detected, grad_norm= 2280108.6823726394
>>> Gradient explosion detected, grad_norm= 7359432.494722245
>>> Gradient explosion detected, grad_norm= 10676167.005035155
[batch 150] loss=2.340920e+09 loss_diff=8.372221e-01 recon=2.340920e+09
obs_tick range: -0.9848077297210693 365600.0  next_tick range: -0.9914447069168091 368800.0
normed next range: -1000000.0 1701.1268310546875
pred range: -791.1387939453125 19.11026382446289
mask valid positions: 50875.0 / 65536

>>> Gradient explosion detected, grad_norm= 1088841.485288094
>>> Gradient explosion detected, grad_norm= 20456863.9558009
>>> Gradient explosion detected, grad_norm= 2335435.3380913343
==============================
[2015-10][Epoch 2/20] | Time = 5.64 min
 - Total Loss : 1541636868.966727 | Recon Loss: 1541636868.903831 | Diff Loss: 0.893972
==============================
No improvement count: 2
[batch 0] loss=2.159392e+09 loss_diff=9.272380e-01 recon=2.159392e+09
obs_tick range: -0.9762952923774719 391500.0  next_tick range: -0.9848073124885559 390400.0
normed next range: -1000000.0 3227.478515625
pred range: -790.90234375 14.774468421936035
mask valid positions: 51200.0 / 65536

>>> Gradient explosion detected, grad_norm= 5394412.110109084
>>> Gradient explosion detected, grad_norm= 1179089.934269455
>>> Gradient explosion detected, grad_norm= 66178448.446342535
>>> Gradient explosion detected, grad_norm= 7481689.537336368
>>> Gradient explosion detected, grad_norm= 18643455.093504936
[batch 10] loss=7.502595e+08 loss_diff=9.264199e-01 recon=7.502595e+08
obs_tick range: -0.9790471792221069 371400.0  next_tick range: -0.9870018362998962 565000.0
normed next range: -1000000.0 12061.14453125
pred range: -791.4193725585938 16.251056671142578
mask valid positions: 29884.0 / 65536

>>> Gradient explosion detected, grad_norm= 1693583.2320921558
[batch 20] loss=6.228038e+08 loss_diff=8.296146e-01 recon=6.228038e+08
obs_tick range: -1.0 368500.0  next_tick range: -1.0 369000.0
normed next range: -1000000.0 22912.99609375
pred range: -792.25244140625 13.969971656799316
mask valid positions: 30024.0 / 65536

>>> Gradient explosion detected, grad_norm= 19500616.061139558
>>> Gradient explosion detected, grad_norm= 2014199.0181037602
>>> Gradient explosion detected, grad_norm= 9136232.103127701
>>> Gradient explosion detected, grad_norm= 8481627.872585483
[batch 30] loss=2.914480e+09 loss_diff=9.207345e-01 recon=2.914480e+09
obs_tick range: -0.9995337724685669 357600.0  next_tick range: -1.0 365000.0
normed next range: -1000000.0 12360.87890625
pred range: -793.6030883789062 14.08809757232666
mask valid positions: 34828.0 / 65536

>>> Gradient explosion detected, grad_norm= 18141187.591261506
>>> Gradient explosion detected, grad_norm= 3429599.9624988907
>>> Gradient explosion detected, grad_norm= 5640705.13991206
>>> Gradient explosion detected, grad_norm= 9829519.39213815
>>> Gradient explosion detected, grad_norm= 10653896.295686271
>>> Gradient explosion detected, grad_norm= 8430098.554339822
>>> Gradient explosion detected, grad_norm= 3393631.168746487
[batch 40] loss=4.309290e+08 loss_diff=8.559597e-01 recon=4.309290e+08
obs_tick range: -0.9659254550933838 394800.0  next_tick range: -0.9762951135635376 393300.0
normed next range: -1000000.0 8433.2568359375
pred range: -793.9246215820312 14.062312126159668
mask valid positions: 50134.0 / 65536

>>> Gradient explosion detected, grad_norm= 4576867.7171154525
>>> Gradient explosion detected, grad_norm= 91208194.08912168
>>> Gradient explosion detected, grad_norm= 105216971.21796799
[batch 50] loss=6.325919e+08 loss_diff=9.004270e-01 recon=6.325919e+08
obs_tick range: -0.9990481734275818 365600.0  next_tick range: -0.9993922710418701 364700.0
normed next range: -1000000.0 67625.5703125
pred range: -794.4892578125 22.592403411865234
mask valid positions: 43336.0 / 65536

>>> Gradient explosion detected, grad_norm= 8941786.030945696
>>> Gradient explosion detected, grad_norm= 2924117.151229321
[batch 60] loss=1.074029e+09 loss_diff=9.263224e-01 recon=1.074029e+09
obs_tick range: -0.9976633191108704 365600.0  next_tick range: -0.9995337724685669 365600.0
normed next range: -1000000.0 5010.5068359375
pred range: -794.8968505859375 17.532955169677734
mask valid positions: 36848.0 / 65536

>>> Gradient explosion detected, grad_norm= 17416932.912395522
>>> Gradient explosion detected, grad_norm= 4405280.333078659
>>> Gradient explosion detected, grad_norm= 1490063.8845553785
>>> Gradient explosion detected, grad_norm= 8456858.972702516
>>> Gradient explosion detected, grad_norm= 4049993.936218152
>>> Gradient explosion detected, grad_norm= 1050541.9261946704
[batch 70] loss=1.732772e+09 loss_diff=9.409365e-01 recon=1.732772e+09
obs_tick range: -1.0 391500.0  next_tick range: -0.999048113822937 392100.0
normed next range: -1000000.0 4696.61572265625
pred range: -795.4428100585938 14.058028221130371
mask valid positions: 51599.0 / 65536

>>> Gradient explosion detected, grad_norm= 1140828.3022833376
>>> Gradient explosion detected, grad_norm= 6374636.5774210105
>>> Gradient explosion detected, grad_norm= 6102875.730057788
[batch 80] loss=8.007922e+08 loss_diff=8.878661e-01 recon=8.007922e+08
obs_tick range: -0.9993910789489746 378400.0  next_tick range: -1.0 378500.0
normed next range: -1000000.0 1000000.0
pred range: -795.8146362304688 22.89521026611328
mask valid positions: 15872.0 / 65536

>>> Gradient explosion detected, grad_norm= 2792583.5895390688
[batch 90] loss=3.422836e+08 loss_diff=9.036989e-01 recon=3.422836e+08
obs_tick range: -0.9848077297210693 395000.0  next_tick range: -0.9914395213127136 394800.0
normed next range: -1000000.0 33088.3828125
pred range: -796.9673461914062 14.161229133605957
mask valid positions: 42698.0 / 65536

>>> Gradient explosion detected, grad_norm= 41588423.55366295
[batch 100] loss=2.072685e+09 loss_diff=9.058271e-01 recon=2.072685e+09
obs_tick range: -1.0 374400.0  next_tick range: -1.0 375100.0
normed next range: -1000000.0 7971.83349609375
pred range: -797.961669921875 12.611248970031738
mask valid positions: 52304.0 / 65536

>>> Gradient explosion detected, grad_norm= 12978784.777005076
>>> Gradient explosion detected, grad_norm= 2397979.8191811466
>>> Gradient explosion detected, grad_norm= 6184452.281501332
>>> Gradient explosion detected, grad_norm= 12827645.437773202
[batch 110] loss=1.954204e+09 loss_diff=8.684543e-01 recon=1.954204e+09
obs_tick range: -1.0 376800.0  next_tick range: -0.9961941242218018 375100.0
normed next range: -1000000.0 3151.850830078125
pred range: -798.8330688476562 13.262619018554688
mask valid positions: 50676.0 / 65536

>>> Gradient explosion detected, grad_norm= 6993555.294409
>>> Gradient explosion detected, grad_norm= 1553321.3153968311
>>> Gradient explosion detected, grad_norm= 1050041.8660960044
[batch 120] loss=4.099053e+02 loss_diff=9.329482e-01 recon=4.089724e+02
obs_tick range: -0.9659252762794495 368700.0  next_tick range: -0.9537158608436584 363900.0
normed next range: -19.445436477661133 9164.380859375
pred range: -224.1128692626953 15.563056945800781
mask valid positions: 51213.0 / 65536

>>> Gradient explosion detected, grad_norm= 5300493.967172519
>>> Gradient explosion detected, grad_norm= 4352116.389241766
>>> Gradient explosion detected, grad_norm= 3241229.8506637267
>>> Gradient explosion detected, grad_norm= 16032859.63527494
>>> Gradient explosion detected, grad_norm= 36758955.65697724
>>> Gradient explosion detected, grad_norm= 11188547.648067815
>>> Gradient explosion detected, grad_norm= 15030026.768825911
>>> Gradient explosion detected, grad_norm= 7028421.538309755
[batch 130] loss=1.364124e+02 loss_diff=8.685254e-01 recon=1.355438e+02
obs_tick range: -1.0 375100.0  next_tick range: -1.0 375600.0
normed next range: -2.488239288330078 2090.3935546875
pred range: -109.9791030883789 32.969078063964844
mask valid positions: 50704.0 / 65536

>>> Gradient explosion detected, grad_norm= 11008750.90762899
>>> Gradient explosion detected, grad_norm= 11688835.496029085
>>> Gradient explosion detected, grad_norm= 6033962.765409761
>>> Gradient explosion detected, grad_norm= 8581422.319955442
>>> Gradient explosion detected, grad_norm= 1313570.1396367364
>>> Gradient explosion detected, grad_norm= 2155349.6493189456
[batch 140] loss=1.847740e+09 loss_diff=8.446369e-01 recon=1.847740e+09
obs_tick range: -0.9848072528839111 392300.0  next_tick range: -0.986998438835144 392200.0
normed next range: -1000000.0 3016.997314453125
pred range: -800.3693237304688 13.527593612670898
mask valid positions: 51040.0 / 65536

>>> Gradient explosion detected, grad_norm= 26006467.133174103
>>> Gradient explosion detected, grad_norm= 1597527.1878483722
>>> Gradient explosion detected, grad_norm= 2538117.690108388
[batch 150] loss=2.408125e+09 loss_diff=8.968942e-01 recon=2.408125e+09
obs_tick range: -0.99619460105896 363900.0  next_tick range: -0.9990479946136475 364200.0
normed next range: -1000000.0 6526.515625
pred range: -801.0293579101562 16.089649200439453
mask valid positions: 35243.0 / 65536

>>> Gradient explosion detected, grad_norm= 1937562.9822572595
==============================
[2015-10][Epoch 3/20] | Time = 5.64 min
 - Total Loss : 1502397496.996581 | Recon Loss: 1502397496.929381 | Diff Loss: 0.886351
==============================
No improvement count: 3
[batch 0] loss=5.833999e+08 loss_diff=8.945569e-01 recon=5.833999e+08
obs_tick range: -0.99619460105896 366200.0  next_tick range: -0.999048113822937 366200.0
normed next range: -1000000.0 7384.31103515625
pred range: -801.3270263671875 13.928947448730469
mask valid positions: 40764.0 / 65536

>>> Gradient explosion detected, grad_norm= 5877440.656212463
[batch 10] loss=2.310679e+08 loss_diff=8.906754e-01 recon=2.310679e+08
obs_tick range: -1.0 369500.0  next_tick range: -0.9659258127212524 366500.0
normed next range: -1000000.0 3220.628662109375
pred range: -802.0264892578125 14.605586051940918
mask valid positions: 40070.0 / 65536

>>> Gradient explosion detected, grad_norm= 6892828.127079886
[batch 20] loss=3.356713e+08 loss_diff=8.071994e-01 recon=3.356713e+08
obs_tick range: -1.0 750000.0  next_tick range: -1.0 390800.0
normed next range: -1000000.0 1883.1231689453125
pred range: -803.1232299804688 13.301309585571289
mask valid positions: 40833.0 / 65536

>>> Gradient explosion detected, grad_norm= 6701775.658555395
[batch 30] loss=6.453814e+08 loss_diff=8.824430e-01 recon=6.453814e+08
obs_tick range: -1.0 1692079.0  next_tick range: -1.0 365000.0
normed next range: -1000000.0 1000000.0
pred range: -804.1378173828125 17.894540786743164
mask valid positions: 51196.0 / 65536

>>> Gradient explosion detected, grad_norm= 3787114.7711866726
>>> Gradient explosion detected, grad_norm= 25876392.949605145
[batch 40] loss=8.498772e+08 loss_diff=9.446502e-01 recon=8.498772e+08
obs_tick range: -0.9920357465744019 394000.0  next_tick range: -0.9969223737716675 1692079.0
normed next range: -1000000.0 18041.48828125
pred range: -805.3174438476562 25.211339950561523
mask valid positions: 42828.0 / 65536

[batch 50] loss=3.860586e+09 loss_diff=8.594321e-01 recon=3.860586e+09
obs_tick range: -1.0 368500.0  next_tick range: -0.9961941242218018 344000.0
normed next range: -1000000.0 4319.40869140625
pred range: -806.6055297851562 14.276054382324219
mask valid positions: 50482.0 / 65536

>>> Gradient explosion detected, grad_norm= 6575840.979773385
>>> Gradient explosion detected, grad_norm= 9637948.678841142
>>> Gradient explosion detected, grad_norm= 56673939.903256886
>>> Gradient explosion detected, grad_norm= 30909904.060631286
>>> Gradient explosion detected, grad_norm= 2048374.6591565432
>>> Gradient explosion detected, grad_norm= 19604263.461567845
>>> Gradient explosion detected, grad_norm= 16862016.878980517
>>> Gradient explosion detected, grad_norm= 4119885.221169366
>>> Gradient explosion detected, grad_norm= 9462073.536640594
[batch 60] loss=2.506833e+09 loss_diff=8.902515e-01 recon=2.506833e+09
obs_tick range: -1.0 586459.0  next_tick range: -0.9990478157997131 365600.0
normed next range: -1000000.0 8106.41650390625
pred range: -807.2738647460938 21.212888717651367
mask valid positions: 35776.0 / 65536

>>> Gradient explosion detected, grad_norm= 9551484.08387399
>>> Gradient explosion detected, grad_norm= 9478472.08467656
>>> Gradient explosion detected, grad_norm= 5501711.787097024
>>> Gradient explosion detected, grad_norm= 3295322.4522876516
>>> Gradient explosion detected, grad_norm= 1709115.901020037
>>> Gradient explosion detected, grad_norm= 2799276.045360112
[batch 70] loss=3.076449e+09 loss_diff=9.095341e-01 recon=3.076449e+09
obs_tick range: -1.0 386200.0  next_tick range: -1.0 365800.0
normed next range: -1000000.0 1116.275634765625
pred range: -807.6842651367188 11.986377716064453
mask valid positions: 57735.0 / 65536

>>> Gradient explosion detected, grad_norm= 8940091.152340755
>>> Gradient explosion detected, grad_norm= 26582697.407995883
>>> Gradient explosion detected, grad_norm= 117179299.71573406
>>> Gradient explosion detected, grad_norm= 2846139.1733709173
>>> Gradient explosion detected, grad_norm= 1579986.974777668
>>> Gradient explosion detected, grad_norm= 5670657.5042929435
>>> Gradient explosion detected, grad_norm= 1295125.922657772
[batch 80] loss=1.461195e+09 loss_diff=9.414912e-01 recon=1.461195e+09
obs_tick range: -0.9990481734275818 392900.0  next_tick range: -0.9961925148963928 391500.0
normed next range: -1000000.0 3969.771484375
pred range: -807.330078125 30.92955780029297
mask valid positions: 58268.0 / 65536

>>> Gradient explosion detected, grad_norm= 3585960.9829529454
>>> Gradient explosion detected, grad_norm= 51155106.839586124
>>> Gradient explosion detected, grad_norm= 40543987.4010204
>>> Gradient explosion detected, grad_norm= 16752070.355569929
[batch 90] loss=1.853830e+09 loss_diff=8.658469e-01 recon=1.853830e+09
obs_tick range: -0.9990478754043579 393000.0  next_tick range: -1.0 394000.0
normed next range: -1000000.0 2686.9091796875
pred range: -808.6658935546875 12.362776756286621
mask valid positions: 58475.0 / 65536

>>> Gradient explosion detected, grad_norm= 8955239.879265789
>>> Gradient explosion detected, grad_norm= 3736806.8986083446
>>> Gradient explosion detected, grad_norm= 10072544.926711615
[batch 100] loss=6.232142e+08 loss_diff=8.970780e-01 recon=6.232142e+08
obs_tick range: -1.0 325000.0  next_tick range: -1.0 335400.0
normed next range: -1000000.0 1712.9637451171875
pred range: -809.4171142578125 11.877279281616211
mask valid positions: 37432.0 / 65536

>>> Gradient explosion detected, grad_norm= 18472267.705082487
>>> Gradient explosion detected, grad_norm= 10720667.781845469
>>> Gradient explosion detected, grad_norm= 3121430.5338736866
>>> Gradient explosion detected, grad_norm= 18010766.895058125
[batch 110] loss=1.927740e+09 loss_diff=8.994872e-01 recon=1.927740e+09
obs_tick range: -0.9990479350090027 367100.0  next_tick range: -0.999048113822937 367900.0
normed next range: -1000000.0 14800.3349609375
pred range: -810.1564331054688 11.996313095092773
mask valid positions: 36679.0 / 65536

>>> Gradient explosion detected, grad_norm= 4883750.1712405095
>>> Gradient explosion detected, grad_norm= 42460059.82580478
[batch 120] loss=2.236465e+09 loss_diff=9.112533e-01 recon=2.236465e+09
obs_tick range: -0.9659268856048584 387100.0  next_tick range: -0.9781553149223328 386200.0
normed next range: -1000000.0 6892.35791015625
pred range: -810.9116821289062 14.27055835723877
mask valid positions: 45091.0 / 65536

>>> Gradient explosion detected, grad_norm= 2333529.233712014
>>> Gradient explosion detected, grad_norm= 2945707.3934000637
>>> Gradient explosion detected, grad_norm= 2407992.047456845
>>> Gradient explosion detected, grad_norm= 1108075.227414353
>>> Gradient explosion detected, grad_norm= 56912167.64748865
>>> Gradient explosion detected, grad_norm= 22965354.99216098
[batch 130] loss=6.732704e+02 loss_diff=8.834097e-01 recon=6.723870e+02
obs_tick range: -1.0 332400.0  next_tick range: -1.0 369000.0
normed next range: -19.445436477661133 9353.1904296875
pred range: -124.19178009033203 20.617639541625977
mask valid positions: 43623.0 / 65536

>>> Gradient explosion detected, grad_norm= 16840723.487351716
>>> Gradient explosion detected, grad_norm= 17278866.92202109
>>> Gradient explosion detected, grad_norm= 11516803.306510523
[batch 140] loss=1.498720e+09 loss_diff=9.162795e-01 recon=1.498720e+09
obs_tick range: -1.0 379900.0  next_tick range: -1.0 379300.0
normed next range: -1000000.0 1342.8668212890625
pred range: -811.92431640625 31.724905014038086
mask valid positions: 58384.0 / 65536

>>> Gradient explosion detected, grad_norm= 19786804.890770774
>>> Gradient explosion detected, grad_norm= 7826132.086371021
>>> Gradient explosion detected, grad_norm= 9848178.779499942
>>> Gradient explosion detected, grad_norm= 3907321.083901198
>>> Gradient explosion detected, grad_norm= 1553670.5122468856
[batch 150] loss=1.572675e+09 loss_diff=8.625908e-01 recon=1.572675e+09
obs_tick range: -0.9990479350090027 367500.0  next_tick range: -1.0 363200.0
normed next range: -1000000.0 7403.31787109375
pred range: -812.404052734375 15.631668090820312
mask valid positions: 42825.0 / 65536

>>> Gradient explosion detected, grad_norm= 2873883.632765959
>>> Gradient explosion detected, grad_norm= 1985339.3370457254
>>> Gradient explosion detected, grad_norm= 67688727.03142402
>>> Gradient explosion detected, grad_norm= 1297847.3274969163
>>> Gradient explosion detected, grad_norm= 3370247.97447773
==============================
[2015-10][Epoch 4/20] | Time = 5.65 min
 - Total Loss : 1370228626.859365 | Recon Loss: 1370228626.790435 | Diff Loss: 0.901103
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-10 completed in 22.36 min
[1] 2015-11 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-11 | file : news_20151130.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.262464e+09 loss_diff=8.720024e-01 recon=1.262464e+09
obs_tick range: -0.9961925148963928 364100.0  next_tick range: -0.9914445281028748 395000.0
normed next range: -1000000.0 10964.865234375
pred range: -812.5252075195312 14.770987510681152
mask valid positions: 29047.0 / 65536

>>> Gradient explosion detected, grad_norm= 1846945.736551096
>>> Gradient explosion detected, grad_norm= 1049898.810404559
>>> Gradient explosion detected, grad_norm= 1978714.9086528737
>>> Gradient explosion detected, grad_norm= 5386710.013810957
>>> Gradient explosion detected, grad_norm= 15088981.0101208
>>> Gradient explosion detected, grad_norm= 6564386.254360984
>>> Gradient explosion detected, grad_norm= 4740131.123070708
[batch 10] loss=1.382404e+09 loss_diff=9.765159e-01 recon=1.382404e+09
obs_tick range: -1.0 368700.0  next_tick range: -0.999048113822937 363900.0
normed next range: -1000000.0 3783.66943359375
pred range: -811.445068359375 9.423853874206543
mask valid positions: 58377.0 / 65536

>>> Gradient explosion detected, grad_norm= 9223938.097376466
>>> Gradient explosion detected, grad_norm= 7003837.342943622
>>> Gradient explosion detected, grad_norm= 2008546.1483683314
>>> Gradient explosion detected, grad_norm= 12440147.767705835
>>> Gradient explosion detected, grad_norm= 38659763.89682037
>>> Gradient explosion detected, grad_norm= 48693740.741510004
[batch 20] loss=2.166700e+09 loss_diff=9.139970e-01 recon=2.166700e+09
obs_tick range: -1.0 378500.0  next_tick range: -0.9990478754043579 375000.0
normed next range: -1000000.0 4839.76513671875
pred range: -803.3406982421875 17.035593032836914
mask valid positions: 36324.0 / 65536

>>> Gradient explosion detected, grad_norm= 9384330.025349876
>>> Gradient explosion detected, grad_norm= 6821150.478558874
>>> Gradient explosion detected, grad_norm= 9063387.507228626
>>> Gradient explosion detected, grad_norm= 6591750.761222114
>>> Gradient explosion detected, grad_norm= 4337854.826333568
>>> Gradient explosion detected, grad_norm= 1896489.1214609998
>>> Gradient explosion detected, grad_norm= 10570531.328796346
>>> Gradient explosion detected, grad_norm= 1296845.049441046
[batch 30] loss=2.652463e+09 loss_diff=8.502210e-01 recon=2.652463e+09
obs_tick range: -0.9990481734275818 374600.0  next_tick range: -1.0 368700.0
normed next range: -1000000.0 2839.35595703125
pred range: -813.6246337890625 13.145675659179688
mask valid positions: 43709.0 / 65536

>>> Gradient explosion detected, grad_norm= 28016751.624500483
>>> Gradient explosion detected, grad_norm= 13365175.557144653
[batch 40] loss=1.366378e+09 loss_diff=8.973525e-01 recon=1.366378e+09
obs_tick range: -1.0 369000.0  next_tick range: -0.9990481734275818 376800.0
normed next range: -1000000.0 4643.267578125
pred range: -814.4414672851562 12.867753028869629
mask valid positions: 50686.0 / 65536

>>> Gradient explosion detected, grad_norm= 14838633.983000021
>>> Gradient explosion detected, grad_norm= 4172321.9407253936
[batch 50] loss=1.598914e+09 loss_diff=9.223905e-01 recon=1.598914e+09
obs_tick range: -0.9969194531440735 357400.0  next_tick range: -0.9993917346000671 367100.0
normed next range: -1000000.0 8591.0
pred range: -815.1416625976562 23.581148147583008
mask valid positions: 51546.0 / 65536

>>> Gradient explosion detected, grad_norm= 1845746.380443578
>>> Gradient explosion detected, grad_norm= 7495790.290562354
>>> Gradient explosion detected, grad_norm= 7577512.46366649
>>> Gradient explosion detected, grad_norm= 25080157.44118778
>>> Gradient explosion detected, grad_norm= 48553637.016097315
>>> Gradient explosion detected, grad_norm= 3470977.0515545234
[batch 60] loss=5.571996e+08 loss_diff=9.020590e-01 recon=5.571996e+08
obs_tick range: -1.0 368000.0  next_tick range: -0.996190071105957 325700.0
normed next range: -1000000.0 5059.66259765625
pred range: -815.558837890625 25.312536239624023
mask valid positions: 50177.0 / 65536

>>> Gradient explosion detected, grad_norm= 7593406.753038097
>>> Gradient explosion detected, grad_norm= 4278945.994743281
>>> Gradient explosion detected, grad_norm= 1007043.3768646374
>>> Gradient explosion detected, grad_norm= 2453754.893195359
>>> Gradient explosion detected, grad_norm= 19514649.400370136
>>> Gradient explosion detected, grad_norm= 1995479.1734237822
[batch 70] loss=5.796166e+08 loss_diff=9.178549e-01 recon=5.796166e+08
obs_tick range: -1.0 375000.0  next_tick range: -0.9993932247161865 327000.0
normed next range: -1000000.0 4961.11328125
pred range: -816.1249389648438 29.37527084350586
mask valid positions: 29285.0 / 65536

>>> Gradient explosion detected, grad_norm= 1584040.300493596
>>> Gradient explosion detected, grad_norm= 1192672.5862442667
[batch 80] loss=2.439938e+09 loss_diff=8.537166e-01 recon=2.439938e+09
obs_tick range: -1.0 370400.0  next_tick range: -1.0 375000.0
normed next range: -1000000.0 9024.361328125
pred range: -816.8482666015625 12.237785339355469
mask valid positions: 29872.0 / 65536

>>> Gradient explosion detected, grad_norm= 4202388.413437291
>>> Gradient explosion detected, grad_norm= 3485650.1152389864
>>> Gradient explosion detected, grad_norm= 43881477.98282955
>>> Gradient explosion detected, grad_norm= 6083667.574679037
[batch 90] loss=1.835074e+09 loss_diff=9.014961e-01 recon=1.835074e+09
obs_tick range: -0.9993922710418701 386200.0  next_tick range: -1.0 374000.0
normed next range: -1000000.0 1886.5096435546875
pred range: -817.847900390625 11.887067794799805
mask valid positions: 59432.0 / 65536

>>> Gradient explosion detected, grad_norm= 4542119.935910964
>>> Gradient explosion detected, grad_norm= 4446920.5205672
>>> Gradient explosion detected, grad_norm= 4822895.252810762
[batch 100] loss=2.444935e+09 loss_diff=8.654763e-01 recon=2.444935e+09
obs_tick range: -0.9994696378707886 365000.0  next_tick range: -1.0 363000.0
normed next range: -1000000.0 7069.9970703125
pred range: -819.0501098632812 12.00625228881836
mask valid positions: 44961.0 / 65536

>>> Gradient explosion detected, grad_norm= 12625727.746705161
>>> Gradient explosion detected, grad_norm= 114296509.14428005
[batch 110] loss=5.581959e+11 loss_diff=8.684225e-01 recon=5.581959e+11
obs_tick range: -0.9848082065582275 367200.0  next_tick range: -0.9918777942657471 691449.0
normed next range: -991447.5 1000000.0
pred range: -107.45355224609375 13.869186401367188
mask valid positions: 22338.0 / 65536

>>> Gradient explosion detected, grad_norm= 96058445.33966641
>>> Gradient explosion detected, grad_norm= 7712296.0100075025
[batch 120] loss=1.754506e+09 loss_diff=8.537712e-01 recon=1.754506e+09
obs_tick range: -1.0 363900.0  next_tick range: -1.0 363300.0
normed next range: -1000000.0 1951.8375244140625
pred range: -821.3845825195312 12.6971435546875
mask valid positions: 51220.0 / 65536

>>> Gradient explosion detected, grad_norm= 1114845.2252339588
[batch 130] loss=9.149643e+08 loss_diff=9.113109e-01 recon=9.149643e+08
obs_tick range: -1.0 335500.0  next_tick range: -1.0 366400.0
normed next range: -1000000.0 4290.89892578125
pred range: -822.7804565429688 17.170148849487305
mask valid positions: 59621.0 / 65536

>>> Gradient explosion detected, grad_norm= 5256285.553098598
[batch 140] loss=3.808923e+08 loss_diff=8.623733e-01 recon=3.808923e+08
obs_tick range: -0.9949765801429749 390400.0  next_tick range: -0.9969472289085388 393000.0
normed next range: -1000000.0 8218.28515625
pred range: -824.3545532226562 18.318408966064453
mask valid positions: 43371.0 / 65536

>>> Gradient explosion detected, grad_norm= 25268586.61374794
>>> Gradient explosion detected, grad_norm= 18492532.866512973
>>> Gradient explosion detected, grad_norm= 15957262.677904382
>>> Gradient explosion detected, grad_norm= 30066098.589499336
>>> Gradient explosion detected, grad_norm= 64358876.54475731
>>> Gradient explosion detected, grad_norm= 8579873.810399316
>>> Gradient explosion detected, grad_norm= 8983084.008372566
[batch 150] loss=3.952618e+08 loss_diff=8.978798e-01 recon=3.952618e+08
obs_tick range: -0.9995337724685669 392300.0  next_tick range: -1.0 392200.0
normed next range: -1000000.0 3754.802490234375
pred range: -824.828125 15.552791595458984
mask valid positions: 51679.0 / 65536

>>> Gradient explosion detected, grad_norm= 10071183.367470914
>>> Gradient explosion detected, grad_norm= 68316643.63795692
>>> Gradient explosion detected, grad_norm= 11029035.89872004
>>> Gradient explosion detected, grad_norm= 5504279.371685847
>>> Gradient explosion detected, grad_norm= 3566320.398798881
>>> Gradient explosion detected, grad_norm= 8127142.3145746505
==============================
[2015-11][Epoch 1/20] | Time = 5.45 min
 - Total Loss : 5007343466.280864 | Recon Loss: 5007343466.216852 | Diff Loss: 0.891700
==============================
No improvement count: 1
[batch 0] loss=2.100117e+08 loss_diff=9.043643e-01 recon=2.100117e+08
obs_tick range: -0.9990472793579102 392300.0  next_tick range: -0.9990479350090027 392200.0
normed next range: -1000000.0 3224.5244140625
pred range: -825.0404663085938 19.01236343383789
mask valid positions: 50147.0 / 65536

>>> Gradient explosion detected, grad_norm= 7661642.658405523
>>> Gradient explosion detected, grad_norm= 57467162.496661745
>>> Gradient explosion detected, grad_norm= 1802158.7912240056
>>> Gradient explosion detected, grad_norm= 9423926.631850854
>>> Gradient explosion detected, grad_norm= 53885633.70902741
>>> Gradient explosion detected, grad_norm= 1282217.1574920348
>>> Gradient explosion detected, grad_norm= 1621657.7758468762
[batch 10] loss=1.552068e+02 loss_diff=8.649107e-01 recon=1.543419e+02
obs_tick range: -0.999047577381134 371500.0  next_tick range: -0.996190071105957 371500.0
normed next range: -7.1889190673828125 2937.637939453125
pred range: -181.78518676757812 31.36141586303711
mask valid positions: 42047.0 / 65536

>>> Gradient explosion detected, grad_norm= 26204015.5231165
>>> Gradient explosion detected, grad_norm= 21359322.263805296
>>> Gradient explosion detected, grad_norm= 26213181.33404295
>>> Gradient explosion detected, grad_norm= 74599901.7981479
>>> Gradient explosion detected, grad_norm= 2532515.612246597
>>> Gradient explosion detected, grad_norm= 6906830.576682554
>>> Gradient explosion detected, grad_norm= 7550513.736677649
>>> Gradient explosion detected, grad_norm= 4233542.503853032
>>> Gradient explosion detected, grad_norm= 2525687.526321362
[batch 20] loss=3.484591e+09 loss_diff=8.860621e-01 recon=3.484591e+09
obs_tick range: -1.0 380000.0  next_tick range: -1.0 380000.0
normed next range: -1000000.0 1000000.0
pred range: -823.0376586914062 12.207091331481934
mask valid positions: 51950.0 / 65536

>>> Gradient explosion detected, grad_norm= 57810990.11743786
>>> Gradient explosion detected, grad_norm= 43025073.678117044
>>> Gradient explosion detected, grad_norm= 12483488.087524578
>>> Gradient explosion detected, grad_norm= 16121350.578108443
>>> Gradient explosion detected, grad_norm= 26625900.42366119
>>> Gradient explosion detected, grad_norm= 29946052.288543947
>>> Gradient explosion detected, grad_norm= 21195416.495154228
[batch 30] loss=1.830160e+09 loss_diff=8.850033e-01 recon=1.830160e+09
obs_tick range: -0.986998438835144 395800.0  next_tick range: -0.9925503134727478 396000.0
normed next range: -1000000.0 11820.80859375
pred range: -825.3848876953125 12.65895938873291
mask valid positions: 29313.0 / 65536

>>> Gradient explosion detected, grad_norm= 1582074.542132518
>>> Gradient explosion detected, grad_norm= 12113563.6474498
>>> Gradient explosion detected, grad_norm= 2614501.9753645738
>>> Gradient explosion detected, grad_norm= 55158990.25255395
>>> Gradient explosion detected, grad_norm= 23092687.569155768
>>> Gradient explosion detected, grad_norm= 3457169.451434452
>>> Gradient explosion detected, grad_norm= 19063637.553544905
>>> Gradient explosion detected, grad_norm= 3607145.6922103968
>>> Gradient explosion detected, grad_norm= 9134233.111417254
[batch 40] loss=1.305928e+09 loss_diff=8.438382e-01 recon=1.305928e+09
obs_tick range: -0.9990481734275818 367900.0  next_tick range: -0.9990478754043579 368000.0
normed next range: -1000000.0 2161.62939453125
pred range: -825.9443359375 14.06434154510498
mask valid positions: 43720.0 / 65536

>>> Gradient explosion detected, grad_norm= 5940127.591255177
>>> Gradient explosion detected, grad_norm= 4140009.746007905
>>> Gradient explosion detected, grad_norm= 1567749.611017121
>>> Gradient explosion detected, grad_norm= 2218150.4913449255
>>> Gradient explosion detected, grad_norm= 1256475.8803233774
>>> Gradient explosion detected, grad_norm= 2551894.472009424
>>> Gradient explosion detected, grad_norm= 1373164.6583925672
>>> Gradient explosion detected, grad_norm= 55023214.39803852
>>> Gradient explosion detected, grad_norm= 1614572.2082890486
>>> Gradient explosion detected, grad_norm= 18943481.771155488
[batch 50] loss=1.525548e+09 loss_diff=8.462873e-01 recon=1.525548e+09
obs_tick range: -0.9969200491905212 380800.0  next_tick range: -0.9992408752441406 379900.0
normed next range: -1000000.0 1836.873779296875
pred range: -826.0789794921875 13.30774974822998
mask valid positions: 50098.0 / 65536

>>> Gradient explosion detected, grad_norm= 7412350.245466433
>>> Gradient explosion detected, grad_norm= 12159473.681635838
[batch 60] loss=1.463236e+09 loss_diff=8.956975e-01 recon=1.463236e+09
obs_tick range: -0.9990478157997131 367900.0  next_tick range: -1.0 367100.0
normed next range: -1000000.0 7689.7158203125
pred range: -826.5508422851562 14.357707023620605
mask valid positions: 51052.0 / 65536

>>> Gradient explosion detected, grad_norm= 6207964.775312715
>>> Gradient explosion detected, grad_norm= 63124333.00366487
>>> Gradient explosion detected, grad_norm= 14318070.190996729
>>> Gradient explosion detected, grad_norm= 3070847.810071214
>>> Gradient explosion detected, grad_norm= 2621059.984005336
>>> Gradient explosion detected, grad_norm= 1004378.4372913835
>>> Gradient explosion detected, grad_norm= 2482442.7166157532
>>> Gradient explosion detected, grad_norm= 6242882.031146389
>>> Gradient explosion detected, grad_norm= 2160449.8128073784
[batch 70] loss=1.872427e+09 loss_diff=9.035107e-01 recon=1.872427e+09
obs_tick range: -0.9781553149223328 394500.0  next_tick range: -0.9862878322601318 393300.0
normed next range: -1000000.0 1000000.0
pred range: -826.6430053710938 13.954717636108398
mask valid positions: 51102.0 / 65536

>>> Gradient explosion detected, grad_norm= 41222404.76047669
>>> Gradient explosion detected, grad_norm= 65978935.53265301
>>> Gradient explosion detected, grad_norm= 35444670.49750193
[batch 80] loss=8.523607e+08 loss_diff=8.207791e-01 recon=8.523607e+08
obs_tick range: -0.9914440512657166 367300.0  next_tick range: -0.9848111271858215 367400.0
normed next range: -1000000.0 2150.515625
pred range: -827.299560546875 12.619617462158203
mask valid positions: 43340.0 / 65536

>>> Gradient explosion detected, grad_norm= 14311730.445626143
>>> Gradient explosion detected, grad_norm= 30944670.462783944
>>> Gradient explosion detected, grad_norm= 26132339.040970586
>>> Gradient explosion detected, grad_norm= 33513108.090670075
>>> Gradient explosion detected, grad_norm= 79545651.54219039
>>> Gradient explosion detected, grad_norm= 2468172.122884926
>>> Gradient explosion detected, grad_norm= 3450707.0388446283
[batch 90] loss=6.422308e+08 loss_diff=8.553854e-01 recon=6.422308e+08
obs_tick range: -0.991446316242218 373700.0  next_tick range: -0.9969179034233093 3089266.0
normed next range: -1000000.0 6961.34423828125
pred range: -827.69873046875 14.236763000488281
mask valid positions: 35619.0 / 65536

>>> Gradient explosion detected, grad_norm= 3266319.3885736866
>>> Gradient explosion detected, grad_norm= 1075207.6155796747
>>> Gradient explosion detected, grad_norm= 1710699.331986807
>>> Gradient explosion detected, grad_norm= 17832835.09344068
>>> Gradient explosion detected, grad_norm= 6720074.624741372
>>> Gradient explosion detected, grad_norm= 4688201.583966808
>>> Gradient explosion detected, grad_norm= 24373062.2426382
>>> Gradient explosion detected, grad_norm= 33039802.94453214
>>> Gradient explosion detected, grad_norm= 24995688.09012741
[batch 100] loss=1.109921e+09 loss_diff=9.465516e-01 recon=1.109921e+09
obs_tick range: -0.99144446849823 226400.0  next_tick range: -0.9848071336746216 225500.0
normed next range: -1000000.0 6033.95654296875
pred range: -827.3905639648438 14.10335922241211
mask valid positions: 58428.0 / 65536

>>> Gradient explosion detected, grad_norm= 17513217.926886603
>>> Gradient explosion detected, grad_norm= 16877319.30809933
>>> Gradient explosion detected, grad_norm= 51423153.74961766
>>> Gradient explosion detected, grad_norm= 8287555.257128485
>>> Gradient explosion detected, grad_norm= 1650610.0435313503
[batch 110] loss=5.468753e+08 loss_diff=8.223320e-01 recon=5.468753e+08
obs_tick range: -1.0 364700.0  next_tick range: -0.9993910789489746 378400.0
normed next range: -1000000.0 1299.9283447265625
pred range: -827.86474609375 10.328822135925293
mask valid positions: 42169.0 / 65536

>>> Gradient explosion detected, grad_norm= 1133476.7528132324
[batch 120] loss=2.557319e+09 loss_diff=9.292991e-01 recon=2.557319e+09
obs_tick range: -0.992336630821228 326700.0  next_tick range: -0.9969189763069153 371500.0
normed next range: -1000000.0 16058.1005859375
pred range: -829.2105102539062 9.04295825958252
mask valid positions: 22219.0 / 65536

>>> Gradient explosion detected, grad_norm= 1284763.6954249204
[batch 130] loss=4.490953e+08 loss_diff=9.552804e-01 recon=4.490953e+08
obs_tick range: -0.9862877130508423 369000.0  next_tick range: -0.9925476908683777 236100.0
normed next range: -1000000.0 13439.572265625
pred range: -830.70361328125 13.190176010131836
mask valid positions: 35385.0 / 65536

[batch 140] loss=2.563175e+08 loss_diff=9.127748e-01 recon=2.563175e+08
obs_tick range: -0.9563833475112915 378000.0  next_tick range: -0.968154788017273 376600.0
normed next range: -1000000.0 2807.129638671875
pred range: -832.0845947265625 12.691468238830566
mask valid positions: 41466.0 / 65536

>>> Gradient explosion detected, grad_norm= 2893518.7017039955
>>> Gradient explosion detected, grad_norm= 1424951.8836379251
>>> Gradient explosion detected, grad_norm= 2163986.4270334207
[batch 150] loss=2.505747e+09 loss_diff=9.138005e-01 recon=2.505747e+09
obs_tick range: -1.0 394500.0  next_tick range: -0.9994696378707886 375000.0
normed next range: -1000000.0 3283.218017578125
pred range: -833.0452270507812 8.720821380615234
mask valid positions: 44339.0 / 65536

==============================
[2015-11][Epoch 2/20] | Time = 5.65 min
 - Total Loss : 1514585877.648189 | Recon Loss: 1514585877.592217 | Diff Loss: 0.887103
==============================
No improvement count: 2
[batch 0] loss=8.206817e+08 loss_diff=8.928155e-01 recon=8.206817e+08
obs_tick range: -0.9994773268699646 369000.0  next_tick range: -1.0 368900.0
normed next range: -1000000.0 15456.7138671875
pred range: -833.8278198242188 10.186172485351562
mask valid positions: 29868.0 / 65536

>>> Gradient explosion detected, grad_norm= 1768660.3916304628
[batch 10] loss=6.831718e+08 loss_diff=9.117965e-01 recon=6.831718e+08
obs_tick range: -0.9396922588348389 369500.0  next_tick range: -0.9537126421928406 366500.0
normed next range: -1000000.0 10800.142578125
pred range: -835.6510009765625 8.587770462036133
mask valid positions: 42660.0 / 65536

[batch 20] loss=2.288632e+09 loss_diff=8.681366e-01 recon=2.288632e+09
obs_tick range: -1.0 366500.0  next_tick range: -1.0 365900.0
normed next range: -1000000.0 5988.7109375
pred range: -837.5458374023438 7.618072986602783
mask valid positions: 51996.0 / 65536

[batch 30] loss=1.343463e+10 loss_diff=9.073855e-01 recon=1.343463e+10
obs_tick range: -0.984806478023529 366100.0  next_tick range: -0.991443932056427 367500.0
normed next range: -1000000.0 3435.1845703125
pred range: -839.9755249023438 7.941861629486084
mask valid positions: 63268.0 / 65536

>>> Gradient explosion detected, grad_norm= 1156203.7146575216
[batch 40] loss=1.368869e+09 loss_diff=8.948437e-01 recon=1.368869e+09
obs_tick range: -1.0 375000.0  next_tick range: -1.0 371000.0
normed next range: -1000000.0 17543.359375
pred range: -842.0932006835938 12.85933780670166
mask valid positions: 33886.0 / 65536

>>> Gradient explosion detected, grad_norm= 1848757.7641603337
[batch 50] loss=1.624414e+09 loss_diff=8.737476e-01 recon=1.624414e+09
obs_tick range: -0.9762857556343079 375000.0  next_tick range: -0.9659202098846436 357500.0
normed next range: -1000000.0 5705.01904296875
pred range: -844.2428588867188 25.558591842651367
mask valid positions: 51243.0 / 65536

>>> Gradient explosion detected, grad_norm= 1683221.5092885597
[batch 60] loss=8.160022e+08 loss_diff=9.228857e-01 recon=8.160022e+08
obs_tick range: -0.9848071932792664 361900.0  next_tick range: -0.9914444088935852 361600.0
normed next range: -1000000.0 3719.28564453125
pred range: -846.3118896484375 28.690412521362305
mask valid positions: 42834.0 / 65536

[batch 70] loss=5.150614e+02 loss_diff=8.440431e-01 recon=5.142173e+02
obs_tick range: -0.999048113822937 392300.0  next_tick range: -0.9961945414543152 392500.0
normed next range: -3.68705677986145 7372.6943359375
pred range: -423.05535888671875 23.4056453704834
mask valid positions: 51031.0 / 65536

[batch 80] loss=2.310964e+08 loss_diff=9.266109e-01 recon=2.310964e+08
obs_tick range: -0.9914391040802002 395000.0  next_tick range: -0.99619460105896 395000.0
normed next range: -1000000.0 55390.57421875
pred range: -851.1813354492188 13.14007568359375
mask valid positions: 35775.0 / 65536

>>> Gradient explosion detected, grad_norm= 1078481.227056931
[batch 90] loss=3.339714e+08 loss_diff=8.745316e-01 recon=3.339714e+08
obs_tick range: -0.9961928725242615 393300.0  next_tick range: -0.992336630821228 393900.0
normed next range: -1000000.0 2541.642578125
pred range: -853.3759155273438 9.453526496887207
mask valid positions: 36712.0 / 65536

[batch 100] loss=7.815104e+08 loss_diff=9.194921e-01 recon=7.815104e+08
obs_tick range: -0.9990472793579102 386200.0  next_tick range: -0.9961910843849182 375000.0
normed next range: -1000000.0 13293.6337890625
pred range: -855.4050903320312 8.62199878692627
mask valid positions: 35780.0 / 65536

[batch 110] loss=1.887258e+09 loss_diff=8.367780e-01 recon=1.887258e+09
obs_tick range: -1.0 362300.0  next_tick range: -0.9990479350090027 368900.0
normed next range: -1000000.0 3801.18505859375
pred range: -857.77197265625 12.03873062133789
mask valid positions: 28953.0 / 65536

[batch 120] loss=2.067131e+09 loss_diff=8.983651e-01 recon=2.067131e+09
obs_tick range: -0.9681508541107178 366200.0  next_tick range: -0.9781502485275269 366200.0
normed next range: -1000000.0 8744.0771484375
pred range: -860.2029418945312 9.93820571899414
mask valid positions: 38026.0 / 65536

>>> Gradient explosion detected, grad_norm= 3812561.510873242
>>> Gradient explosion detected, grad_norm= 1923953.103296569
>>> Gradient explosion detected, grad_norm= 2535003.981334447
>>> Gradient explosion detected, grad_norm= 4432354.055751329
>>> Gradient explosion detected, grad_norm= 27896715.233315013
>>> Gradient explosion detected, grad_norm= 114289927.84081542
>>> Gradient explosion detected, grad_norm= 25619845.63295001
[batch 130] loss=5.226515e+08 loss_diff=8.637893e-01 recon=5.226515e+08
obs_tick range: -0.9969229698181152 367300.0  next_tick range: -0.9993933439254761 367400.0
normed next range: -1000000.0 5786.36767578125
pred range: -860.2015991210938 40.02220916748047
mask valid positions: 36123.0 / 65536

>>> Gradient explosion detected, grad_norm= 4934008.602584112
>>> Gradient explosion detected, grad_norm= 1221651.5531837638
>>> Gradient explosion detected, grad_norm= 1662431.57412719
>>> Gradient explosion detected, grad_norm= 20608603.844574492
>>> Gradient explosion detected, grad_norm= 21428721.74495605
>>> Gradient explosion detected, grad_norm= 1142891.170428578
>>> Gradient explosion detected, grad_norm= 3391261.7430822984
>>> Gradient explosion detected, grad_norm= 2191296.7366614887
>>> Gradient explosion detected, grad_norm= 1239494.870379309
>>> Gradient explosion detected, grad_norm= 1411434.2034338412
[batch 140] loss=1.281637e+09 loss_diff=9.276819e-01 recon=1.281637e+09
obs_tick range: -0.9990481734275818 373300.0  next_tick range: -1.0 373700.0
normed next range: -1000000.0 3568.6220703125
pred range: -862.1465454101562 14.366501808166504
mask valid positions: 50917.0 / 65536

>>> Gradient explosion detected, grad_norm= 1110182.3043268141
>>> Gradient explosion detected, grad_norm= 35425851.61110583
>>> Gradient explosion detected, grad_norm= 48172858.87471951
>>> Gradient explosion detected, grad_norm= 14989888.735564556
>>> Gradient explosion detected, grad_norm= 73201585.61685985
>>> Gradient explosion detected, grad_norm= 25243431.899777986
[batch 150] loss=9.942602e+08 loss_diff=9.077688e-01 recon=9.942602e+08
obs_tick range: -0.9961925148963928 379500.0  next_tick range: -0.9914445281028748 379200.0
normed next range: -1000000.0 4514.36865234375
pred range: -862.3880004882812 62.266571044921875
mask valid positions: 58057.0 / 65536

>>> Gradient explosion detected, grad_norm= 3285683.7070623487
>>> Gradient explosion detected, grad_norm= 6515996.477977999
>>> Gradient explosion detected, grad_norm= 1466177.47615311
>>> Gradient explosion detected, grad_norm= 141223265.6931399
>>> Gradient explosion detected, grad_norm= 1384450.5210383176
==============================
[2015-11][Epoch 3/20] | Time = 5.65 min
 - Total Loss : 1704773164.140991 | Recon Loss: 1704773164.078014 | Diff Loss: 0.891205
==============================
No improvement count: 3
[batch 0] loss=1.217541e+09 loss_diff=9.201040e-01 recon=1.217541e+09
obs_tick range: -0.9848039746284485 361000.0  next_tick range: -0.9762953519821167 325900.0
normed next range: -1000000.0 1000000.0
pred range: -862.34228515625 15.899163246154785
mask valid positions: 59191.0 / 65536

>>> Gradient explosion detected, grad_norm= 1798697.3324398964
>>> Gradient explosion detected, grad_norm= 1213593.0263425407
>>> Gradient explosion detected, grad_norm= 1096304.3434199102
>>> Gradient explosion detected, grad_norm= 53008109.2610226
>>> Gradient explosion detected, grad_norm= 2183003.4688652325
>>> Gradient explosion detected, grad_norm= 46005677.611273296
[batch 10] loss=1.562665e+09 loss_diff=8.763463e-01 recon=1.562665e+09
obs_tick range: -0.999048113822937 350000.0  next_tick range: -1.0 387100.0
normed next range: -1000000.0 15597.8232421875
pred range: -863.146240234375 46.47665786743164
mask valid positions: 50652.0 / 65536

>>> Gradient explosion detected, grad_norm= 18368982.12409768
>>> Gradient explosion detected, grad_norm= 8196220.259918027
>>> Gradient explosion detected, grad_norm= 6583366.348887441
>>> Gradient explosion detected, grad_norm= 5791632.622400489
>>> Gradient explosion detected, grad_norm= 6772513.854029459
>>> Gradient explosion detected, grad_norm= 7183500.279786115
>>> Gradient explosion detected, grad_norm= 4601688.418439579
>>> Gradient explosion detected, grad_norm= 5021911.9377483055
>>> Gradient explosion detected, grad_norm= 7864747.850320975
[batch 20] loss=6.504221e+08 loss_diff=8.803991e-01 recon=6.504221e+08
obs_tick range: -0.9930698871612549 393600.0  next_tick range: -0.9972502589225769 395000.0
normed next range: -1000000.0 4122.7802734375
pred range: -862.3671875 52.990570068359375
mask valid positions: 43258.0 / 65536

>>> Gradient explosion detected, grad_norm= 46698185.247727945
>>> Gradient explosion detected, grad_norm= 15016618.249789916
>>> Gradient explosion detected, grad_norm= 13688917.261524027
>>> Gradient explosion detected, grad_norm= 2992263.724941932
>>> Gradient explosion detected, grad_norm= 33118489.540947985
>>> Gradient explosion detected, grad_norm= 54503857.840641335
>>> Gradient explosion detected, grad_norm= 7793051.61943251
>>> Gradient explosion detected, grad_norm= 8992888.853663681
>>> Gradient explosion detected, grad_norm= 8454416.91435569
[batch 30] loss=1.057124e+09 loss_diff=8.861945e-01 recon=1.057124e+09
obs_tick range: -0.999048113822937 362700.0  next_tick range: -0.9961945414543152 361900.0
normed next range: -1000000.0 2997.413818359375
pred range: -860.6055297851562 50.6894416809082
mask valid positions: 51003.0 / 65536

>>> Gradient explosion detected, grad_norm= 5278290.009988166
>>> Gradient explosion detected, grad_norm= 26552038.985729944
>>> Gradient explosion detected, grad_norm= 161413492.5162526
>>> Gradient explosion detected, grad_norm= 77575329.11775023
>>> Gradient explosion detected, grad_norm= 26424778.949229784
>>> Gradient explosion detected, grad_norm= 2665170.343088383
>>> Gradient explosion detected, grad_norm= 2283618.759606938
[batch 40] loss=2.709277e+09 loss_diff=8.639007e-01 recon=2.709277e+09
obs_tick range: -1.0 351900.0  next_tick range: -1.0 332400.0
normed next range: -1000000.0 25727.1328125
pred range: -860.2034301757812 45.95326232910156
mask valid positions: 21943.0 / 65536

>>> Gradient explosion detected, grad_norm= 1542592.453259655
>>> Gradient explosion detected, grad_norm= 12321852.30657859
>>> Gradient explosion detected, grad_norm= 27212617.779895224
[batch 50] loss=2.442386e+09 loss_diff=8.920617e-01 recon=2.442386e+09
obs_tick range: -1.0 871959.0  next_tick range: -0.9990478754043579 367200.0
normed next range: -1000000.0 13394.9169921875
pred range: -863.2049560546875 14.591011047363281
mask valid positions: 43700.0 / 65536

>>> Gradient explosion detected, grad_norm= 7305410.411950998
[batch 60] loss=2.063256e+09 loss_diff=9.731756e-01 recon=2.063256e+09
obs_tick range: -0.9762958884239197 393600.0  next_tick range: -0.9848058223724365 395800.0
normed next range: -1000000.0 7143.9931640625
pred range: -864.0576171875 14.09007740020752
mask valid positions: 43460.0 / 65536

>>> Gradient explosion detected, grad_norm= 19856101.260916892
>>> Gradient explosion detected, grad_norm= 61824146.94877863
>>> Gradient explosion detected, grad_norm= 5590510.956583341
>>> Gradient explosion detected, grad_norm= 1708548.4497566535
>>> Gradient explosion detected, grad_norm= 1453268.847983217
[batch 70] loss=7.120430e+08 loss_diff=8.788393e-01 recon=7.120430e+08
obs_tick range: -1.0 361800.0  next_tick range: -0.9914443492889404 361700.0
normed next range: -1000000.0 3360.598388671875
pred range: -863.7949829101562 30.0722713470459
mask valid positions: 35435.0 / 65536

>>> Gradient explosion detected, grad_norm= 1130517.6873870129
>>> Gradient explosion detected, grad_norm= 8146694.323575767
>>> Gradient explosion detected, grad_norm= 1156187.8392273395
>>> Gradient explosion detected, grad_norm= 22313977.20479349
>>> Gradient explosion detected, grad_norm= 1228138073.0049236
>>> Gradient explosion detected, grad_norm= 2014958.4137094242
>>> Gradient explosion detected, grad_norm= 13765979.6231219
>>> Gradient explosion detected, grad_norm= 6083393.57053163
[batch 80] loss=4.709463e+08 loss_diff=9.654461e-01 recon=4.709463e+08
obs_tick range: -0.999048113822937 374600.0  next_tick range: -1.0 374000.0
normed next range: -1000000.0 7636.85693359375
pred range: -865.2633666992188 32.8563232421875
mask valid positions: 42980.0 / 65536

>>> Gradient explosion detected, grad_norm= 2376590.895689207
>>> Gradient explosion detected, grad_norm= 6574104.061878297
>>> Gradient explosion detected, grad_norm= 16699833.009578755
>>> Gradient explosion detected, grad_norm= 17700251.09532468
>>> Gradient explosion detected, grad_norm= 22958171.83315621
[batch 90] loss=1.224709e+03 loss_diff=9.321553e-01 recon=1.223777e+03
obs_tick range: -0.9990481734275818 371500.0  next_tick range: -0.9961944818496704 371500.0
normed next range: -13.788581848144531 11592.3662109375
pred range: -847.775146484375 30.18415641784668
mask valid positions: 43575.0 / 65536

>>> Gradient explosion detected, grad_norm= 8359787.692968351
>>> Gradient explosion detected, grad_norm= 9682413.835751712
>>> Gradient explosion detected, grad_norm= 7480597.150675046
>>> Gradient explosion detected, grad_norm= 36719525.15864964
>>> Gradient explosion detected, grad_norm= 18243812.699300148
>>> Gradient explosion detected, grad_norm= 8560816.277818931
[batch 100] loss=5.347772e+08 loss_diff=9.015184e-01 recon=5.347772e+08
obs_tick range: -1.0 363100.0  next_tick range: -1.0 362500.0
normed next range: -1000000.0 1000000.0
pred range: -865.354736328125 14.243454933166504
mask valid positions: 57708.0 / 65536

>>> Gradient explosion detected, grad_norm= 15154387.774298295
[batch 110] loss=1.678259e+09 loss_diff=8.775100e-01 recon=1.678259e+09
obs_tick range: -1.0 370200.0  next_tick range: -0.9848071336746216 370200.0
normed next range: -1000000.0 32592.580078125
pred range: -866.3201904296875 14.670888900756836
mask valid positions: 28932.0 / 65536

>>> Gradient explosion detected, grad_norm= 17443115.835808486
[batch 120] loss=3.867459e+08 loss_diff=8.530315e-01 recon=3.867459e+08
obs_tick range: -1.0 392100.0  next_tick range: -0.9993922710418701 393300.0
normed next range: -1000000.0 5498.25390625
pred range: -867.2366943359375 28.040048599243164
mask valid positions: 36140.0 / 65536

>>> Gradient explosion detected, grad_norm= 35528876.8929886
>>> Gradient explosion detected, grad_norm= 15184923.36653983
>>> Gradient explosion detected, grad_norm= 15600637.515923785
>>> Gradient explosion detected, grad_norm= 69182862.00299475
>>> Gradient explosion detected, grad_norm= 16346405.549061714
[batch 130] loss=5.236190e+08 loss_diff=8.452643e-01 recon=5.236190e+08
obs_tick range: -0.99921715259552 371500.0  next_tick range: -1.0 371600.0
normed next range: -1000000.0 21504.154296875
pred range: -867.8118896484375 28.829660415649414
mask valid positions: 22533.0 / 65536

>>> Gradient explosion detected, grad_norm= 33919031.52464283
>>> Gradient explosion detected, grad_norm= 80895204.39795762
>>> Gradient explosion detected, grad_norm= 1310547.5918663354
>>> Gradient explosion detected, grad_norm= 1610887.9863496935
>>> Gradient explosion detected, grad_norm= 26956520.07414967
>>> Gradient explosion detected, grad_norm= 22251734.702297073
>>> Gradient explosion detected, grad_norm= 26223323.682212465
[batch 140] loss=1.597345e+09 loss_diff=9.103420e-01 recon=1.597345e+09
obs_tick range: -0.9961913228034973 379500.0  next_tick range: -0.9961928129196167 379500.0
normed next range: -1000000.0 1000000.0
pred range: -867.93408203125 14.056487083435059
mask valid positions: 42872.0 / 65536

>>> Gradient explosion detected, grad_norm= 17050221.52564585
>>> Gradient explosion detected, grad_norm= 19309828.01878565
>>> Gradient explosion detected, grad_norm= 15073753.721898608
>>> Gradient explosion detected, grad_norm= 28795156.01897208
>>> Gradient explosion detected, grad_norm= 19629808.57878253
[batch 150] loss=1.379546e+03 loss_diff=8.803990e-01 recon=1.378666e+03
obs_tick range: -1.0 395000.0  next_tick range: -0.99619460105896 395000.0
normed next range: -2.8674325942993164 4907.95751953125
pred range: -850.065673828125 11.918502807617188
mask valid positions: 35124.0 / 65536

>>> Gradient explosion detected, grad_norm= 4838074.244991
>>> Gradient explosion detected, grad_norm= 20544914.66107013
>>> Gradient explosion detected, grad_norm= 46390938.56881795
==============================
[2015-11][Epoch 4/20] | Time = 5.65 min
 - Total Loss : 1474303240.099616 | Recon Loss: 1474303240.030168 | Diff Loss: 0.884240
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-11 completed in 22.39 min
[1] 2015-12 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2015-12 | file : news_20151231.json

[ Building tensor ]
 - Saved 1244 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.773584e+09 loss_diff=8.902278e-01 recon=1.773584e+09
obs_tick range: -0.9659255146980286 375000.0  next_tick range: -0.9682620167732239 365100.0
normed next range: -1000000.0 29579.798828125
pred range: -868.294921875 14.129963874816895
mask valid positions: 50979.0 / 65536

>>> Gradient explosion detected, grad_norm= 23154214.920761846
>>> Gradient explosion detected, grad_norm= 3075145.811623546
>>> Gradient explosion detected, grad_norm= 7670025.293908007
>>> Gradient explosion detected, grad_norm= 6237295.231486382
>>> Gradient explosion detected, grad_norm= 5909760.079026358
>>> Gradient explosion detected, grad_norm= 4288319.706122399
>>> Gradient explosion detected, grad_norm= 2008404.689012749
>>> Gradient explosion detected, grad_norm= 1130653.651624142
[batch 10] loss=2.072169e+09 loss_diff=9.243749e-01 recon=2.072169e+09
obs_tick range: -0.9961930513381958 393900.0  next_tick range: -0.9990480542182922 393700.0
normed next range: -1000000.0 2795.950927734375
pred range: -868.5410766601562 14.436867713928223
mask valid positions: 43590.0 / 65536

>>> Gradient explosion detected, grad_norm= 24580161.523007214
>>> Gradient explosion detected, grad_norm= 37583926.82592779
>>> Gradient explosion detected, grad_norm= 90741794.90986305
>>> Gradient explosion detected, grad_norm= 27114633.76232107
>>> Gradient explosion detected, grad_norm= 58936726.81180582
>>> Gradient explosion detected, grad_norm= 3546478.091306296
>>> Gradient explosion detected, grad_norm= 46138215.219748564
>>> Gradient explosion detected, grad_norm= 25193122.87622822
>>> Gradient explosion detected, grad_norm= 13032820.810632596
[batch 20] loss=1.336336e+02 loss_diff=9.003621e-01 recon=1.327333e+02
obs_tick range: -0.9961928129196167 373300.0  next_tick range: -0.9990478157997131 373700.0
normed next range: -2.4748735427856445 3303.89501953125
pred range: -712.13720703125 20.011516571044922
mask valid positions: 50694.0 / 65536

>>> Gradient explosion detected, grad_norm= 6896796.441382292
>>> Gradient explosion detected, grad_norm= 11318243.95922938
>>> Gradient explosion detected, grad_norm= 81866793.21891733
>>> Gradient explosion detected, grad_norm= 183495278.86085963
>>> Gradient explosion detected, grad_norm= 114070858.144388
>>> Gradient explosion detected, grad_norm= 44776530.8947066
>>> Gradient explosion detected, grad_norm= 123744550.40617846
>>> Gradient explosion detected, grad_norm= 13531056.633015975
[batch 30] loss=8.530408e+08 loss_diff=9.229769e-01 recon=8.530408e+08
obs_tick range: -1.0 871959.0  next_tick range: -0.9990478157997131 395000.0
normed next range: -1000000.0 7470.53173828125
pred range: -868.267333984375 41.50437545776367
mask valid positions: 41818.0 / 65536

>>> Gradient explosion detected, grad_norm= 7531489.5446554115
>>> Gradient explosion detected, grad_norm= 9023062.405005189
>>> Gradient explosion detected, grad_norm= 11277648.860731898
>>> Gradient explosion detected, grad_norm= 6650132.422876055
>>> Gradient explosion detected, grad_norm= 63631631.54264923
>>> Gradient explosion detected, grad_norm= 9145089.020616312
>>> Gradient explosion detected, grad_norm= 6931567.383150021
>>> Gradient explosion detected, grad_norm= 26011121.61562246
>>> Gradient explosion detected, grad_norm= 25996313.99064247
>>> Gradient explosion detected, grad_norm= 3811519.3307069927
[batch 40] loss=1.933078e+09 loss_diff=9.044634e-01 recon=1.933078e+09
obs_tick range: -1.0 353900.0  next_tick range: -0.9971959590911865 352700.0
normed next range: -1000000.0 3759.71240234375
pred range: -868.7994384765625 44.72520446777344
mask valid positions: 44886.0 / 65536

>>> Gradient explosion detected, grad_norm= 5463114.937408102
>>> Gradient explosion detected, grad_norm= 4558447.767546445
>>> Gradient explosion detected, grad_norm= 3066984.5069208527
>>> Gradient explosion detected, grad_norm= 1936577.335812667
>>> Gradient explosion detected, grad_norm= 6260866.343423004
>>> Gradient explosion detected, grad_norm= 10371035.460987372
>>> Gradient explosion detected, grad_norm= 18890758.28198118
[batch 50] loss=2.292378e+09 loss_diff=8.704308e-01 recon=2.292378e+09
obs_tick range: -0.9914444088935852 325900.0  next_tick range: -0.9961945414543152 378400.0
normed next range: -1000000.0 2516.044677734375
pred range: -868.1602783203125 14.747025489807129
mask valid positions: 51211.0 / 65536

>>> Gradient explosion detected, grad_norm= 48520880.74838888
>>> Gradient explosion detected, grad_norm= 28098630.27767022
>>> Gradient explosion detected, grad_norm= 8595138.33217833
>>> Gradient explosion detected, grad_norm= 2287572.200896877
>>> Gradient explosion detected, grad_norm= 5961349.189181801
>>> Gradient explosion detected, grad_norm= 6129541.828297218
>>> Gradient explosion detected, grad_norm= 7096651.214495632
>>> Gradient explosion detected, grad_norm= 5114468.141407435
>>> Gradient explosion detected, grad_norm= 1722293.8874296516
>>> Gradient explosion detected, grad_norm= 1197976.5956227202
[batch 60] loss=1.771020e+09 loss_diff=9.078662e-01 recon=1.771020e+09
obs_tick range: -0.939691960811615 375200.0  next_tick range: -0.9537115097045898 374600.0
normed next range: -1000000.0 2729.34765625
pred range: -868.3562622070312 14.377833366394043
mask valid positions: 50842.0 / 65536

>>> Gradient explosion detected, grad_norm= 12258677.656648543
>>> Gradient explosion detected, grad_norm= 14301101.203487242
>>> Gradient explosion detected, grad_norm= 1283824.772678531
>>> Gradient explosion detected, grad_norm= 32013151.479582034
>>> Gradient explosion detected, grad_norm= 90718326.49353093
>>> Gradient explosion detected, grad_norm= 9977290.020318663
>>> Gradient explosion detected, grad_norm= 3873010.2975705997
[batch 70] loss=3.539185e+09 loss_diff=8.959166e-01 recon=3.539185e+09
obs_tick range: -0.9848077297210693 367000.0  next_tick range: -0.9914447069168091 367000.0
normed next range: -1000000.0 7951.57763671875
pred range: -868.2662353515625 15.060734748840332
mask valid positions: 58256.0 / 65536

>>> Gradient explosion detected, grad_norm= 58420107.08526002
>>> Gradient explosion detected, grad_norm= 2336235.921451856
>>> Gradient explosion detected, grad_norm= 2347585.0707440563
>>> Gradient explosion detected, grad_norm= 3028502.796746377
>>> Gradient explosion detected, grad_norm= 1803547.4145913324
>>> Gradient explosion detected, grad_norm= 1002271.7624266826
>>> Gradient explosion detected, grad_norm= 1618987.4987039156
>>> Gradient explosion detected, grad_norm= 4575367.917062857
[batch 80] loss=9.020792e+08 loss_diff=8.886250e-01 recon=9.020792e+08
obs_tick range: -0.9990476965904236 367100.0  next_tick range: -1.0 366100.0
normed next range: -1000000.0 10067.3046875
pred range: -868.19921875 22.506166458129883
mask valid positions: 42760.0 / 65536

>>> Gradient explosion detected, grad_norm= 5144358.494281847
>>> Gradient explosion detected, grad_norm= 12428870.414049892
>>> Gradient explosion detected, grad_norm= 19992452.264688045
>>> Gradient explosion detected, grad_norm= 28755449.079297397
[batch 90] loss=1.494955e+02 loss_diff=8.694093e-01 recon=1.486261e+02
obs_tick range: -1.0 365500.0  next_tick range: -1.0 367100.0
normed next range: -2.4748737812042236 1856.549072265625
pred range: -772.439453125 29.742307662963867
mask valid positions: 41255.0 / 65536

>>> Gradient explosion detected, grad_norm= 25525365.341496143
>>> Gradient explosion detected, grad_norm= 5189881.4100696
>>> Gradient explosion detected, grad_norm= 3373111.281404892
>>> Gradient explosion detected, grad_norm= 2769613.1206674585
>>> Gradient explosion detected, grad_norm= 4936382.63559276
>>> Gradient explosion detected, grad_norm= 30521297.44976514
>>> Gradient explosion detected, grad_norm= 86697943.95620242
[batch 100] loss=2.973095e+09 loss_diff=9.157058e-01 recon=2.973095e+09
obs_tick range: -0.9990478754043579 371500.0  next_tick range: -0.9972506761550903 370200.0
normed next range: -1000000.0 4452.94970703125
pred range: -867.4511108398438 13.20037841796875
mask valid positions: 29079.0 / 65536

>>> Gradient explosion detected, grad_norm= 49736767.707934976
>>> Gradient explosion detected, grad_norm= 31442611.94424368
>>> Gradient explosion detected, grad_norm= 15130761.824104425
>>> Gradient explosion detected, grad_norm= 14911755.949467443
>>> Gradient explosion detected, grad_norm= 4542707.364890721
>>> Gradient explosion detected, grad_norm= 1111079.6037532303
>>> Gradient explosion detected, grad_norm= 2843790.561650014
>>> Gradient explosion detected, grad_norm= 6646878.327212961
[batch 110] loss=4.338523e+08 loss_diff=9.360694e-01 recon=4.338523e+08
obs_tick range: -0.9848071336746216 366800.0  next_tick range: -0.9914413094520569 366700.0
normed next range: -1000000.0 4816.32958984375
pred range: -869.8543090820312 14.630422592163086
mask valid positions: 44568.0 / 65536

>>> Gradient explosion detected, grad_norm= 7524849.724827187
>>> Gradient explosion detected, grad_norm= 96726991.75884673
>>> Gradient explosion detected, grad_norm= 292325653.93875784
>>> Gradient explosion detected, grad_norm= 1964000.669462098
>>> Gradient explosion detected, grad_norm= 3593850.426797493
>>> Gradient explosion detected, grad_norm= 2815458.266693354
>>> Gradient explosion detected, grad_norm= 2221328.735398077
>>> Gradient explosion detected, grad_norm= 4590311.989270313
>>> Gradient explosion detected, grad_norm= 22225570.862908334
[batch 120] loss=1.063360e+09 loss_diff=8.982713e-01 recon=1.063360e+09
obs_tick range: -0.9961941242218018 365900.0  next_tick range: -0.9914445877075195 365700.0
normed next range: -1000000.0 3127.44384765625
pred range: -869.5004272460938 15.164740562438965
mask valid positions: 55994.0 / 65536

>>> Gradient explosion detected, grad_norm= 7332309.003671145
>>> Gradient explosion detected, grad_norm= 2091725.5352637065
>>> Gradient explosion detected, grad_norm= 2309673.5436605103
>>> Gradient explosion detected, grad_norm= 3651205.5532248258
>>> Gradient explosion detected, grad_norm= 2701164.7810834576
>>> Gradient explosion detected, grad_norm= 1239082.949291556
>>> Gradient explosion detected, grad_norm= 27294072.062312033
>>> Gradient explosion detected, grad_norm= 34606487.7791919
[batch 130] loss=1.537267e+09 loss_diff=8.585176e-01 recon=1.537267e+09
obs_tick range: -1.0 357400.0  next_tick range: -0.999048113822937 355200.0
normed next range: -1000000.0 1000000.0
pred range: -868.6194458007812 13.92198657989502
mask valid positions: 42746.0 / 65536

>>> Gradient explosion detected, grad_norm= 10923495.355027327
>>> Gradient explosion detected, grad_norm= 33344141.870229226
>>> Gradient explosion detected, grad_norm= 1195979.6115291175
>>> Gradient explosion detected, grad_norm= 1501048.0367131135
>>> Gradient explosion detected, grad_norm= 211733516.45045987
>>> Gradient explosion detected, grad_norm= 2941451.4895044416
>>> Gradient explosion detected, grad_norm= 1944354.9687030078
>>> Gradient explosion detected, grad_norm= 1213109.8386976917
>>> Gradient explosion detected, grad_norm= 1026900.644493848
>>> Gradient explosion detected, grad_norm= 1172139.7929374797
[batch 140] loss=1.925863e+09 loss_diff=9.057930e-01 recon=1.925863e+09
obs_tick range: -0.9990480542182922 362700.0  next_tick range: -1.0 365000.0
normed next range: -1000000.0 4151.921875
pred range: -870.38671875 14.24825668334961
mask valid positions: 51041.0 / 65536

>>> Gradient explosion detected, grad_norm= 22408548.90283776
>>> Gradient explosion detected, grad_norm= 48293449.87756746
>>> Gradient explosion detected, grad_norm= 109353050.051259
>>> Gradient explosion detected, grad_norm= 11392229.862198953
[batch 150] loss=1.781159e+09 loss_diff=8.929818e-01 recon=1.781159e+09
obs_tick range: -0.9993916153907776 375600.0  next_tick range: -1.0 375100.0
normed next range: -1000000.0 5389.02490234375
pred range: -869.5374755859375 13.657769203186035
mask valid positions: 50763.0 / 65536

>>> Gradient explosion detected, grad_norm= 38561837.42338331
>>> Gradient explosion detected, grad_norm= 17541775.965949498
>>> Gradient explosion detected, grad_norm= 1362499.9245670263
>>> Gradient explosion detected, grad_norm= 1254387.4924134708
>>> Gradient explosion detected, grad_norm= 1076791.6456224269
>>> Gradient explosion detected, grad_norm= 1334290.679059528
==============================
[2015-12][Epoch 1/20] | Time = 5.52 min
 - Total Loss : 1706377693.787109 | Recon Loss: 1706377693.718567 | Diff Loss: 0.885322
==============================
No improvement count: 1
[batch 0] loss=4.873277e+08 loss_diff=9.050612e-01 recon=4.873277e+08
obs_tick range: -0.999046266078949 367100.0  next_tick range: -1.0 367100.0
normed next range: -1000000.0 6613.046875
pred range: -870.8712158203125 14.13314437866211
mask valid positions: 50472.0 / 65536

>>> Gradient explosion detected, grad_norm= 17549337.73078322
>>> Gradient explosion detected, grad_norm= 20196189.099056754
>>> Gradient explosion detected, grad_norm= 27257981.98651139
>>> Gradient explosion detected, grad_norm= 12429845.669369344
>>> Gradient explosion detected, grad_norm= 8154202.542708611
>>> Gradient explosion detected, grad_norm= 7048793.583842669
>>> Gradient explosion detected, grad_norm= 7223683.521293952
>>> Gradient explosion detected, grad_norm= 6113347.890782533
>>> Gradient explosion detected, grad_norm= 2638545.4610374477
[batch 10] loss=1.558667e+09 loss_diff=9.057820e-01 recon=1.558667e+09
obs_tick range: -1.0 379000.0  next_tick range: -0.999048113822937 379600.0
normed next range: -1000000.0 2882.17138671875
pred range: -871.7279052734375 13.55288028717041
mask valid positions: 43673.0 / 65536

>>> Gradient explosion detected, grad_norm= 19063230.803601053
>>> Gradient explosion detected, grad_norm= 24903611.28879587
>>> Gradient explosion detected, grad_norm= 21537061.843887504
>>> Gradient explosion detected, grad_norm= 1820190.6785779672
>>> Gradient explosion detected, grad_norm= 1310409.5121441584
>>> Gradient explosion detected, grad_norm= 1211019.0288577324
[batch 20] loss=1.025662e+07 loss_diff=8.769988e-01 recon=1.025662e+07
obs_tick range: -1.0 369900.0  next_tick range: -0.9062973856925964 375000.0
normed next range: -1000000.0 9546.5390625
pred range: -869.2951049804688 17.707611083984375
mask valid positions: 35446.0 / 65536

>>> Gradient explosion detected, grad_norm= 14500184.4561295
>>> Gradient explosion detected, grad_norm= 9466667.448602889
>>> Gradient explosion detected, grad_norm= 22393709.229250904
>>> Gradient explosion detected, grad_norm= 19552725.399338163
>>> Gradient explosion detected, grad_norm= 28935743.903969046
>>> Gradient explosion detected, grad_norm= 9752086.911681343
[batch 30] loss=7.824346e+08 loss_diff=8.818005e-01 recon=7.824346e+08
obs_tick range: -0.9969252943992615 365200.0  next_tick range: -0.9993920922279358 365600.0
normed next range: -1000000.0 3551.64404296875
pred range: -870.5122680664062 15.456937789916992
mask valid positions: 44313.0 / 65536

>>> Gradient explosion detected, grad_norm= 4704030.920469786
[batch 40] loss=1.736710e+10 loss_diff=9.094348e-01 recon=1.736710e+10
obs_tick range: -1.0 329100.0  next_tick range: -1.0 327600.0
normed next range: -1000000.0 1000000.0
pred range: -872.0177612304688 13.90704345703125
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 119595461.64118007
>>> Gradient explosion detected, grad_norm= 12567933.634549642
>>> Gradient explosion detected, grad_norm= 10322116.299102902
>>> Gradient explosion detected, grad_norm= 8874737.97869209
>>> Gradient explosion detected, grad_norm= 95614334.3771818
>>> Gradient explosion detected, grad_norm= 13022160.815554265
>>> Gradient explosion detected, grad_norm= 4094404.542284245
>>> Gradient explosion detected, grad_norm= 41940254.34427453
>>> Gradient explosion detected, grad_norm= 37743014.002583236
[batch 50] loss=4.018370e+08 loss_diff=8.714806e-01 recon=4.018370e+08
obs_tick range: -1.0 379500.0  next_tick range: -0.9990472793579102 379200.0
normed next range: -1000000.0 1000000.0
pred range: -872.8707885742188 32.61850357055664
mask valid positions: 49928.0 / 65536

>>> Gradient explosion detected, grad_norm= 4624012.90109502
>>> Gradient explosion detected, grad_norm= 5120522.398186343
>>> Gradient explosion detected, grad_norm= 5376689.003612523
>>> Gradient explosion detected, grad_norm= 24317192.092911616
>>> Gradient explosion detected, grad_norm= 118100947.04959425
>>> Gradient explosion detected, grad_norm= 4682262.58465426
>>> Gradient explosion detected, grad_norm= 14552132.182984998
[batch 60] loss=8.334909e+08 loss_diff=9.084958e-01 recon=8.334909e+08
obs_tick range: -0.9990472793579102 365800.0  next_tick range: -0.9961941242218018 369000.0
normed next range: -1000000.0 4205.96435546875
pred range: -872.6896362304688 30.386402130126953
mask valid positions: 43774.0 / 65536

>>> Gradient explosion detected, grad_norm= 19506371.86547088
>>> Gradient explosion detected, grad_norm= 16794917.038219627
[batch 70] loss=1.717183e+09 loss_diff=8.591030e-01 recon=1.717183e+09
obs_tick range: -0.9914456605911255 390800.0  next_tick range: -0.9972506761550903 394500.0
normed next range: -1000000.0 2657.505615234375
pred range: -872.8975830078125 30.987751007080078
mask valid positions: 58398.0 / 65536

>>> Gradient explosion detected, grad_norm= 23340989.434428547
>>> Gradient explosion detected, grad_norm= 1220095.8242725448
>>> Gradient explosion detected, grad_norm= 21518174.67451816
>>> Gradient explosion detected, grad_norm= 33788331.48197201
>>> Gradient explosion detected, grad_norm= 46674166.32850338
>>> Gradient explosion detected, grad_norm= 14155180.52187099
>>> Gradient explosion detected, grad_norm= 35811225.819972895
>>> Gradient explosion detected, grad_norm= 5792591.9455553
[batch 80] loss=1.526707e+09 loss_diff=8.979077e-01 recon=1.526707e+09
obs_tick range: -1.0 396000.0  next_tick range: -1.0 395700.0
normed next range: -1000000.0 4569.67431640625
pred range: -873.8076171875 27.013288497924805
mask valid positions: 58439.0 / 65536

>>> Gradient explosion detected, grad_norm= 6446485.304699603
>>> Gradient explosion detected, grad_norm= 7077706.3864682
>>> Gradient explosion detected, grad_norm= 3572992.299484398
>>> Gradient explosion detected, grad_norm= 2117472.8860854725
>>> Gradient explosion detected, grad_norm= 1141616.4961371976
>>> Gradient explosion detected, grad_norm= 1589711.3736531157
>>> Gradient explosion detected, grad_norm= 1081928.117133941
>>> Gradient explosion detected, grad_norm= 1674087.69614309
[batch 90] loss=2.195719e+09 loss_diff=9.060756e-01 recon=2.195719e+09
obs_tick range: -0.99619460105896 369000.0  next_tick range: -0.999048113822937 369500.0
normed next range: -1000000.0 10404.9541015625
pred range: -873.70361328125 14.066064834594727
mask valid positions: 36291.0 / 65536

>>> Gradient explosion detected, grad_norm= 2168415.1845859536
>>> Gradient explosion detected, grad_norm= 38054364.9579812
[batch 100] loss=3.148422e+08 loss_diff=8.386028e-01 recon=3.148422e+08
obs_tick range: -1.0 375100.0  next_tick range: -1.0 373300.0
normed next range: -1000000.0 3967.298828125
pred range: -874.0022583007812 16.390625
mask valid positions: 50162.0 / 65536

>>> Gradient explosion detected, grad_norm= 1496875.2257820147
>>> Gradient explosion detected, grad_norm= 1550088.5104623754
>>> Gradient explosion detected, grad_norm= 10906447.823902491
>>> Gradient explosion detected, grad_norm= 9063822.733690562
>>> Gradient explosion detected, grad_norm= 7471017.904098283
[batch 110] loss=1.297370e+09 loss_diff=8.954936e-01 recon=1.297370e+09
obs_tick range: -0.9990483522415161 375000.0  next_tick range: -1.0 389000.0
normed next range: -1000000.0 7516.4287109375
pred range: -874.5639038085938 27.131683349609375
mask valid positions: 37566.0 / 65536

>>> Gradient explosion detected, grad_norm= 1579799.0869462425
>>> Gradient explosion detected, grad_norm= 4286597.615513714
>>> Gradient explosion detected, grad_norm= 10193365.680732053
>>> Gradient explosion detected, grad_norm= 2807026.4685160923
>>> Gradient explosion detected, grad_norm= 8886965.13689663
>>> Gradient explosion detected, grad_norm= 6126536.497587124
>>> Gradient explosion detected, grad_norm= 1019695.7139887263
[batch 120] loss=9.283690e+08 loss_diff=8.747858e-01 recon=9.283690e+08
obs_tick range: -1.0 393000.0  next_tick range: -0.9914444088935852 392900.0
normed next range: -1000000.0 14141.0546875
pred range: -874.984375 14.66175365447998
mask valid positions: 44383.0 / 65536

>>> Gradient explosion detected, grad_norm= 8861651.686358385
>>> Gradient explosion detected, grad_norm= 8495181.501458071
[batch 130] loss=1.286803e+09 loss_diff=8.731934e-01 recon=1.286803e+09
obs_tick range: -1.0 367300.0  next_tick range: -0.9990479350090027 371500.0
normed next range: -1000000.0 3481.006103515625
pred range: -875.3883056640625 49.76531219482422
mask valid positions: 43869.0 / 65536

>>> Gradient explosion detected, grad_norm= 8320707.240978385
>>> Gradient explosion detected, grad_norm= 18049545.79342883
>>> Gradient explosion detected, grad_norm= 197845133.81971404
>>> Gradient explosion detected, grad_norm= 30224235.865837466
>>> Gradient explosion detected, grad_norm= 14670139.150498126
>>> Gradient explosion detected, grad_norm= 1181399.405114688
[batch 140] loss=1.029563e+09 loss_diff=8.943783e-01 recon=1.029563e+09
obs_tick range: -0.9969194531440735 367100.0  next_tick range: -0.9993917346000671 357600.0
normed next range: -1000000.0 16998.244140625
pred range: -876.1175537109375 55.15798568725586
mask valid positions: 27948.0 / 65536

>>> Gradient explosion detected, grad_norm= 14326182.939322786
>>> Gradient explosion detected, grad_norm= 7008828.658562132
>>> Gradient explosion detected, grad_norm= 2153354.4940644903
>>> Gradient explosion detected, grad_norm= 19269551.852009047
>>> Gradient explosion detected, grad_norm= 20794776.311051384
>>> Gradient explosion detected, grad_norm= 9074727.613561504
[batch 150] loss=1.148504e+02 loss_diff=8.832047e-01 recon=1.139672e+02
obs_tick range: -1.0 365500.0  next_tick range: -0.9990478157997131 378000.0
normed next range: -2.4748735427856445 3386.260498046875
pred range: -718.0759887695312 44.41349792480469
mask valid positions: 49702.0 / 65536

>>> Gradient explosion detected, grad_norm= 11159856.928007308
>>> Gradient explosion detected, grad_norm= 5318290.616334153
>>> Gradient explosion detected, grad_norm= 5672033.887238986
>>> Gradient explosion detected, grad_norm= 6363525.904293967
>>> Gradient explosion detected, grad_norm= 212493269.51174304
==============================
[2015-12][Epoch 2/20] | Time = 5.70 min
 - Total Loss : 1565995265.850768 | Recon Loss: 1565995265.783232 | Diff Loss: 0.886881
==============================
No improvement count: 2
[batch 0] loss=6.703498e+08 loss_diff=8.602753e-01 recon=6.703498e+08
obs_tick range: -0.9990478754043579 365200.0  next_tick range: -0.9961942434310913 365600.0
normed next range: -1000000.0 1216.9808349609375
pred range: -875.14990234375 13.006512641906738
mask valid positions: 50370.0 / 65536

>>> Gradient explosion detected, grad_norm= 3553895.758236856
>>> Gradient explosion detected, grad_norm= 63292875.024173595
>>> Gradient explosion detected, grad_norm= 1758318.6909612138
>>> Gradient explosion detected, grad_norm= 1078020.5467367524
>>> Gradient explosion detected, grad_norm= 41977292.70748673
>>> Gradient explosion detected, grad_norm= 1602572.9392505968
>>> Gradient explosion detected, grad_norm= 110979504.0876549
[batch 10] loss=1.781769e+09 loss_diff=9.345186e-01 recon=1.781769e+09
obs_tick range: -0.9781754612922668 367300.0  next_tick range: -0.986307680606842 367400.0
normed next range: -1000000.0 5639.908203125
pred range: -875.9618530273438 12.673246383666992
mask valid positions: 35860.0 / 65536

>>> Gradient explosion detected, grad_norm= 75520018.28364061
>>> Gradient explosion detected, grad_norm= 1158228.607068085
>>> Gradient explosion detected, grad_norm= 1341103.021305618
>>> Gradient explosion detected, grad_norm= 22151064.25786585
>>> Gradient explosion detected, grad_norm= 1278037.5164304087
[batch 20] loss=1.248618e+09 loss_diff=8.696591e-01 recon=1.248618e+09
obs_tick range: -1.0 395000.0  next_tick range: -0.9990478754043579 365600.0
normed next range: -1000000.0 6768.0634765625
pred range: -876.7278442382812 12.351208686828613
mask valid positions: 42449.0 / 65536

>>> Gradient explosion detected, grad_norm= 11739186.310540596
>>> Gradient explosion detected, grad_norm= 10961139.733487112
>>> Gradient explosion detected, grad_norm= 26360686.15245777
>>> Gradient explosion detected, grad_norm= 63346748.305147484
>>> Gradient explosion detected, grad_norm= 6006258.220124299
>>> Gradient explosion detected, grad_norm= 9168248.613592653
>>> Gradient explosion detected, grad_norm= 7850277.653953632
[batch 30] loss=1.731982e+09 loss_diff=8.943336e-01 recon=1.731982e+09
obs_tick range: -1.0 357500.0  next_tick range: -0.99619460105896 357400.0
normed next range: -1000000.0 10195.388671875
pred range: -875.7122802734375 12.10876178741455
mask valid positions: 27197.0 / 65536

>>> Gradient explosion detected, grad_norm= 3820866.4832428475
>>> Gradient explosion detected, grad_norm= 1721546.756779985
>>> Gradient explosion detected, grad_norm= 9231862.45208196
>>> Gradient explosion detected, grad_norm= 1896684.573829618
>>> Gradient explosion detected, grad_norm= 2365977.673108092
[batch 40] loss=2.489070e+09 loss_diff=8.057488e-01 recon=2.489070e+09
obs_tick range: -1.0 650000.0  next_tick range: -1.0 362800.0
normed next range: -1000000.0 11394.73828125
pred range: -877.7962036132812 32.58271789550781
mask valid positions: 24575.0 / 65536

>>> Gradient explosion detected, grad_norm= 9803344.486100426
>>> Gradient explosion detected, grad_norm= 6621424.325375248
>>> Gradient explosion detected, grad_norm= 75816910.27568541
>>> Gradient explosion detected, grad_norm= 9195362.559371324
>>> Gradient explosion detected, grad_norm= 11760664.039040376
[batch 50] loss=1.471642e+10 loss_diff=9.449266e-01 recon=1.471642e+10
obs_tick range: -1.0 365800.0  next_tick range: -1.0 365900.0
normed next range: -1000000.0 1000000.0
pred range: -878.4556884765625 14.756719589233398
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 1060053059.677454
>>> Gradient explosion detected, grad_norm= 10089954.47198344
>>> Gradient explosion detected, grad_norm= 8530470.673317082
>>> Gradient explosion detected, grad_norm= 3931389.134078931
>>> Gradient explosion detected, grad_norm= 2427300.9244196727
>>> Gradient explosion detected, grad_norm= 1647999.4037536692
[batch 60] loss=5.371709e+08 loss_diff=9.003808e-01 recon=5.371709e+08
obs_tick range: -0.9990479946136475 371500.0  next_tick range: -0.9961945414543152 371500.0
normed next range: -1000000.0 2432.822021484375
pred range: -877.7088623046875 35.87765884399414
mask valid positions: 50688.0 / 65536

>>> Gradient explosion detected, grad_norm= 1006238.1202015603
>>> Gradient explosion detected, grad_norm= 2797606.1360900905
[batch 70] loss=5.176119e+08 loss_diff=8.733142e-01 recon=5.176119e+08
obs_tick range: -0.9961943030357361 395700.0  next_tick range: -0.999048113822937 392500.0
normed next range: -1000000.0 6705.22412109375
pred range: -879.2650146484375 40.37153625488281
mask valid positions: 43317.0 / 65536

>>> Gradient explosion detected, grad_norm= 1617796.7998822548
>>> Gradient explosion detected, grad_norm= 92202910.75910357
>>> Gradient explosion detected, grad_norm= 12460707.527086886
[batch 80] loss=4.685850e+08 loss_diff=8.487731e-01 recon=4.685850e+08
obs_tick range: -0.9961941242218018 363900.0  next_tick range: -0.9990481734275818 367100.0
normed next range: -1000000.0 3970.56640625
pred range: -880.5162353515625 47.32233810424805
mask valid positions: 42998.0 / 65536

>>> Gradient explosion detected, grad_norm= 11969461.67114688
>>> Gradient explosion detected, grad_norm= 4264939.920686301
>>> Gradient explosion detected, grad_norm= 10985539.814485118
[batch 90] loss=2.229889e+09 loss_diff=8.419657e-01 recon=2.229889e+09
obs_tick range: -0.9990474581718445 393300.0  next_tick range: -1.0 395000.0
normed next range: -1000000.0 4153.59228515625
pred range: -881.7532958984375 14.096786499023438
mask valid positions: 43753.0 / 65536

>>> Gradient explosion detected, grad_norm= 13750136.882140614
[batch 100] loss=8.541276e+08 loss_diff=8.684262e-01 recon=8.541276e+08
obs_tick range: -1.0 393300.0  next_tick range: -1.0 393900.0
normed next range: -1000000.0 2351.332763671875
pred range: -882.8782348632812 39.53034973144531
mask valid positions: 56634.0 / 65536

>>> Gradient explosion detected, grad_norm= 9318381.585833156
>>> Gradient explosion detected, grad_norm= 5969144.992820231
>>> Gradient explosion detected, grad_norm= 1079213.7427248494
>>> Gradient explosion detected, grad_norm= 41560765.60622949
>>> Gradient explosion detected, grad_norm= 2302668.9619183913
>>> Gradient explosion detected, grad_norm= 8548848.04763181
>>> Gradient explosion detected, grad_norm= 8901966.243656082
>>> Gradient explosion detected, grad_norm= 4699150.6798243355
>>> Gradient explosion detected, grad_norm= 1867712.1002062466
[batch 110] loss=1.024564e+09 loss_diff=8.699470e-01 recon=1.024564e+09
obs_tick range: -1.0 361700.0  next_tick range: -0.999048113822937 361400.0
normed next range: -1000000.0 1884.320068359375
pred range: -883.3565673828125 52.942501068115234
mask valid positions: 50402.0 / 65536

[batch 120] loss=2.539100e+09 loss_diff=8.358149e-01 recon=2.539100e+09
obs_tick range: -0.9100168347358704 370200.0  next_tick range: -0.9272340536117554 369000.0
normed next range: -1000000.0 7560.3076171875
pred range: -884.8028564453125 20.405990600585938
mask valid positions: 23590.0 / 65536

>>> Gradient explosion detected, grad_norm= 4382119.976211254
>>> Gradient explosion detected, grad_norm= 7334203.353692247
>>> Gradient explosion detected, grad_norm= 9461235.87502797
>>> Gradient explosion detected, grad_norm= 56120343.281613834
>>> Gradient explosion detected, grad_norm= 5894362.958198403
>>> Gradient explosion detected, grad_norm= 12687578.967538917
[batch 130] loss=1.290596e+09 loss_diff=8.505435e-01 recon=1.290596e+09
obs_tick range: -1.0 378500.0  next_tick range: -0.9972280859947205 364900.0
normed next range: -1000000.0 4821.74169921875
pred range: -885.747314453125 27.676015853881836
mask valid positions: 43185.0 / 65536

[batch 140] loss=2.187597e+03 loss_diff=8.738555e-01 recon=2.186724e+03
obs_tick range: -0.9692326188087463 387100.0  next_tick range: -0.978151261806488 386200.0
normed next range: -2.474870204925537 12140.6552734375
pred range: -413.6308898925781 29.898433685302734
mask valid positions: 35119.0 / 65536

[batch 150] loss=9.182927e+08 loss_diff=9.127336e-01 recon=9.182927e+08
obs_tick range: -0.9961930513381958 393600.0  next_tick range: -0.9990480542182922 395800.0
normed next range: -1000000.0 4870.3681640625
pred range: -888.7434692382812 13.771759986877441
mask valid positions: 43101.0 / 65536

>>> Gradient explosion detected, grad_norm= 2746102.3401425825
==============================
[2015-12][Epoch 3/20] | Time = 5.66 min
 - Total Loss : 1683592476.427082 | Recon Loss: 1683592476.356956 | Diff Loss: 0.888685
==============================
No improvement count: 3
[batch 0] loss=8.216877e+08 loss_diff=8.810971e-01 recon=8.216877e+08
obs_tick range: -0.9995337724685669 375000.0  next_tick range: -1.0 395000.0
normed next range: -1000000.0 12672.35546875
pred range: -890.4956665039062 12.378458023071289
mask valid positions: 42645.0 / 65536

>>> Gradient explosion detected, grad_norm= 1167678.3560771102
>>> Gradient explosion detected, grad_norm= 1195176.5970224817
[batch 10] loss=2.369293e+09 loss_diff=8.217144e-01 recon=2.369293e+09
obs_tick range: -0.9848069548606873 393700.0  next_tick range: -0.9848065376281738 392700.0
normed next range: -1000000.0 12347.0048828125
pred range: -892.1805419921875 20.083574295043945
mask valid positions: 29228.0 / 65536

>>> Gradient explosion detected, grad_norm= 1476159.7028297028
>>> Gradient explosion detected, grad_norm= 1259005.3620508702
>>> Gradient explosion detected, grad_norm= 3875525.9916993026
>>> Gradient explosion detected, grad_norm= 5127038.847893757
>>> Gradient explosion detected, grad_norm= 20963476.660943888
[batch 20] loss=8.622616e+08 loss_diff=8.495363e-01 recon=8.622616e+08
obs_tick range: -0.9990472793579102 371400.0  next_tick range: -1.0 371400.0
normed next range: -1000000.0 2018.58447265625
pred range: -892.69140625 31.804153442382812
mask valid positions: 50523.0 / 65536

>>> Gradient explosion detected, grad_norm= 2851176.1738745472
>>> Gradient explosion detected, grad_norm= 12059263.705783455
>>> Gradient explosion detected, grad_norm= 6476496.559826505
>>> Gradient explosion detected, grad_norm= 11821935.628262205
>>> Gradient explosion detected, grad_norm= 41911075.063939616
[batch 30] loss=1.274570e+09 loss_diff=9.078360e-01 recon=1.274570e+09
obs_tick range: -1.0 378000.0  next_tick range: -0.999048113822937 378000.0
normed next range: -1000000.0 9629.900390625
pred range: -892.1404418945312 14.438070297241211
mask valid positions: 36955.0 / 65536

>>> Gradient explosion detected, grad_norm= 56835543.59699463
>>> Gradient explosion detected, grad_norm= 1192539.5902238872
>>> Gradient explosion detected, grad_norm= 6640516.159448677
>>> Gradient explosion detected, grad_norm= 8659706.078150693
[batch 40] loss=7.857491e+08 loss_diff=8.915055e-01 recon=7.857491e+08
obs_tick range: -1.0 375000.0  next_tick range: -1.0 328100.0
normed next range: -1000000.0 5284.599609375
pred range: -894.9391479492188 23.88819694519043
mask valid positions: 44352.0 / 65536

>>> Gradient explosion detected, grad_norm= 5110623.08391885
>>> Gradient explosion detected, grad_norm= 5354027.498004822
>>> Gradient explosion detected, grad_norm= 15144699.697531624
[batch 50] loss=2.241452e+09 loss_diff=9.048470e-01 recon=2.241452e+09
obs_tick range: -1.0 366100.0  next_tick range: -1.0 366200.0
normed next range: -1000000.0 2569.40478515625
pred range: -895.7074584960938 25.51646614074707
mask valid positions: 51753.0 / 65536

>>> Gradient explosion detected, grad_norm= 36179459.5290452
>>> Gradient explosion detected, grad_norm= 9328466.046618281
>>> Gradient explosion detected, grad_norm= 11778095.177928306
>>> Gradient explosion detected, grad_norm= 2938501.162263922
>>> Gradient explosion detected, grad_norm= 5162830.06200293
[batch 60] loss=2.005055e+09 loss_diff=9.164165e-01 recon=2.005055e+09
obs_tick range: -0.9961928725242615 393300.0  next_tick range: -0.9927315711975098 393900.0
normed next range: -1000000.0 63327.95703125
pred range: -896.3739013671875 28.124147415161133
mask valid positions: 36618.0 / 65536

>>> Gradient explosion detected, grad_norm= 3687967.9893459007
>>> Gradient explosion detected, grad_norm= 382159365.6272825
>>> Gradient explosion detected, grad_norm= 12023044.763603864
[batch 70] loss=2.969376e+02 loss_diff=8.570957e-01 recon=2.960805e+02
obs_tick range: -0.9914445281028748 366200.0  next_tick range: -0.9848077297210693 366200.0
normed next range: -2.4748735427856445 6323.7607421875
pred range: -266.9925231933594 34.70603561401367
mask valid positions: 35887.0 / 65536

>>> Gradient explosion detected, grad_norm= 61032563.83155699
>>> Gradient explosion detected, grad_norm= 4466918.463517689
>>> Gradient explosion detected, grad_norm= 26500231.413920376
>>> Gradient explosion detected, grad_norm= 1123073.0732018305
>>> Gradient explosion detected, grad_norm= 1822989.6876231537
>>> Gradient explosion detected, grad_norm= 1033431.5523416883
>>> Gradient explosion detected, grad_norm= 112074825.08895876
[batch 80] loss=1.672810e+09 loss_diff=9.133583e-01 recon=1.672810e+09
obs_tick range: -0.9925476908683777 370200.0  next_tick range: -0.9961950778961182 367000.0
normed next range: -1000000.0 14433.3203125
pred range: -898.1345825195312 14.301966667175293
mask valid positions: 36404.0 / 65536

>>> Gradient explosion detected, grad_norm= 2111577.590959825
[batch 90] loss=5.047020e+02 loss_diff=8.339832e-01 recon=5.038680e+02
obs_tick range: -0.996190071105957 362700.0  next_tick range: -0.9976633191108704 365000.0
normed next range: -2.4748737812042236 4754.662109375
pred range: -398.3261413574219 11.47197437286377
mask valid positions: 50776.0 / 65536

>>> Gradient explosion detected, grad_norm= 18726177.465264503
>>> Gradient explosion detected, grad_norm= 10253604.388470083
>>> Gradient explosion detected, grad_norm= 71137989.20998833
[batch 100] loss=7.585887e+08 loss_diff=8.692312e-01 recon=7.585887e+08
obs_tick range: -1.0 392100.0  next_tick range: -1.0 393300.0
normed next range: -1000000.0 1000000.0
pred range: -900.359375 14.812358856201172
mask valid positions: 57787.0 / 65536

>>> Gradient explosion detected, grad_norm= 20021627.359973744
>>> Gradient explosion detected, grad_norm= 8404326.72599876
>>> Gradient explosion detected, grad_norm= 5755514.650720984
[batch 110] loss=5.714886e+08 loss_diff=8.232872e-01 recon=5.714886e+08
obs_tick range: -0.99619460105896 365000.0  next_tick range: -0.9990472793579102 365600.0
normed next range: -1000000.0 6205.533203125
pred range: -901.1746826171875 13.952655792236328
mask valid positions: 42561.0 / 65536

>>> Gradient explosion detected, grad_norm= 24963820.65437932
>>> Gradient explosion detected, grad_norm= 11935699.304859305
>>> Gradient explosion detected, grad_norm= 2321457.1024452196
>>> Gradient explosion detected, grad_norm= 1612252.1055756984
[batch 120] loss=4.748316e+02 loss_diff=8.738684e-01 recon=4.739578e+02
obs_tick range: -1.0 360800.0  next_tick range: -0.9914441108703613 357400.0
normed next range: -6.209298133850098 9540.1396484375
pred range: -870.6270751953125 31.65703773498535
mask valid positions: 34380.0 / 65536

>>> Gradient explosion detected, grad_norm= 4064192.0131955426
>>> Gradient explosion detected, grad_norm= 8778003.45481728
>>> Gradient explosion detected, grad_norm= 5251064.292629317
>>> Gradient explosion detected, grad_norm= 1743307.2916316136
>>> Gradient explosion detected, grad_norm= 2970928.4067629674
>>> Gradient explosion detected, grad_norm= 2021152.7384273373
[batch 130] loss=8.916075e+08 loss_diff=9.101838e-01 recon=8.916075e+08
obs_tick range: -0.9848071932792664 392900.0  next_tick range: -0.976294994354248 393000.0
normed next range: -1000000.0 12311.966796875
pred range: -901.9451904296875 13.445392608642578
mask valid positions: 50283.0 / 65536

>>> Gradient explosion detected, grad_norm= 3322830.716271702
>>> Gradient explosion detected, grad_norm= 1263059.074899492
[batch 140] loss=6.230252e+08 loss_diff=8.767379e-01 recon=6.230252e+08
obs_tick range: -0.9848073720932007 379200.0  next_tick range: -0.9762954115867615 380300.0
normed next range: -1000000.0 2882.84619140625
pred range: -902.5963745117188 30.673202514648438
mask valid positions: 41369.0 / 65536

>>> Gradient explosion detected, grad_norm= 10200418.783855598
[batch 150] loss=9.280687e+08 loss_diff=8.973709e-01 recon=9.280687e+08
obs_tick range: -0.9762871265411377 332300.0  next_tick range: -0.9848047494888306 331200.0
normed next range: -1000000.0 11965.2568359375
pred range: -903.4740600585938 21.310474395751953
mask valid positions: 20242.0 / 65536

>>> Gradient explosion detected, grad_norm= 82611704.61156128
>>> Gradient explosion detected, grad_norm= 6334422.7055965625
==============================
[2015-12][Epoch 4/20] | Time = 5.62 min
 - Total Loss : 1721456387.170148 | Recon Loss: 1721456387.102300 | Diff Loss: 0.887032
==============================
No improvement count: 4
>>> Early stopping triggered.
 - Training for 2015-12 completed in 22.50 min
[1] 2016-01 Data Preprocessing

[ Building timespan tick data ]
 - Decompressing tick data...
 - Spiliting tick data...

[ Building timespan news data ]
 - Processing news date: 2016-01 | file : news_20160131.json

[ Building tensor ]
 - Saved 1179 data samples to processed_dataset

[2] Dataset Loading

[3] Training Loop begins

[batch 0] loss=1.549642e+09 loss_diff=9.333212e-01 recon=1.549642e+09
obs_tick range: -0.9961945414543152 525700.0  next_tick range: -0.9914442300796509 525700.0
normed next range: -1000000.0 2158.6220703125
pred range: -904.2861328125 19.409618377685547
mask valid positions: 51312.0 / 65536

>>> Gradient explosion detected, grad_norm= 10708861.792125065
>>> Gradient explosion detected, grad_norm= 19514977.116282802
>>> Gradient explosion detected, grad_norm= 46023107.10201392
>>> Gradient explosion detected, grad_norm= 192827609.87551397
>>> Gradient explosion detected, grad_norm= 5826995.7773312805
>>> Gradient explosion detected, grad_norm= 5961335.874582949
>>> Gradient explosion detected, grad_norm= 6487802.223997745
>>> Gradient explosion detected, grad_norm= 6995234.12012078
>>> Gradient explosion detected, grad_norm= 6101974.062799046
>>> Gradient explosion detected, grad_norm= 34572296.08117183
[batch 10] loss=3.512591e+09 loss_diff=8.732972e-01 recon=3.512591e+09
obs_tick range: -1.0 521900.0  next_tick range: -0.9990453124046326 516900.0
normed next range: -1000000.0 1558.0784912109375
pred range: -904.5614624023438 14.21187973022461
mask valid positions: 59714.0 / 65536

>>> Gradient explosion detected, grad_norm= 88753447.47605902
>>> Gradient explosion detected, grad_norm= 3812960.976742899
>>> Gradient explosion detected, grad_norm= 75832440.58813632
>>> Gradient explosion detected, grad_norm= 3541907.221708726
>>> Gradient explosion detected, grad_norm= 11068436.91966636
>>> Gradient explosion detected, grad_norm= 1046222.2496529236
>>> Gradient explosion detected, grad_norm= 32968936.129492227
>>> Gradient explosion detected, grad_norm= 11696753.467500241
[batch 20] loss=8.128588e+08 loss_diff=9.573046e-01 recon=8.128588e+08
obs_tick range: -0.9914447665214539 544200.0  next_tick range: -0.9961942434310913 521300.0
normed next range: -1000000.0 4764.6845703125
pred range: -904.7431030273438 13.68146800994873
mask valid positions: 51246.0 / 65536

>>> Gradient explosion detected, grad_norm= 11793364.48930362
>>> Gradient explosion detected, grad_norm= 18698887.993494302
>>> Gradient explosion detected, grad_norm= 26410946.2352583
>>> Gradient explosion detected, grad_norm= 54000457.23286554
>>> Gradient explosion detected, grad_norm= 56765378.56374478
>>> Gradient explosion detected, grad_norm= 112774028.48107101
>>> Gradient explosion detected, grad_norm= 6198488.316757518
[batch 30] loss=2.878230e+09 loss_diff=8.260764e-01 recon=2.878230e+09
obs_tick range: -1.0 513900.0  next_tick range: -1.0 539600.0
normed next range: -1000000.0 3345.9921875
pred range: -905.2243041992188 10.575149536132812
mask valid positions: 48875.0 / 65536

>>> Gradient explosion detected, grad_norm= 3115927.92418954
>>> Gradient explosion detected, grad_norm= 1154206.281382987
>>> Gradient explosion detected, grad_norm= 1584046.4567172865
[batch 40] loss=1.679091e+09 loss_diff=8.861901e-01 recon=1.679091e+09
obs_tick range: -0.999048113822937 530000.0  next_tick range: -0.9961946606636047 535000.0
normed next range: -1000000.0 4576.12646484375
pred range: -905.970947265625 10.827775955200195
mask valid positions: 45082.0 / 65536

[batch 50] loss=6.748116e+09 loss_diff=8.807141e-01 recon=6.748116e+09
obs_tick range: -1.0 535600.0  next_tick range: -0.9990478157997131 512000.0
normed next range: -1000000.0 1000000.0
pred range: -907.84326171875 7.314664363861084
mask valid positions: 52801.0 / 65536

[batch 60] loss=1.363686e+09 loss_diff=8.567547e-01 recon=1.363686e+09
obs_tick range: -0.9990478754043579 520000.0  next_tick range: -0.9990385174751282 222500.0
normed next range: -1000000.0 2713.192138671875
pred range: -909.8443603515625 38.79623794555664
mask valid positions: 45195.0 / 65536

>>> Gradient explosion detected, grad_norm= 1051966.4483956709
[batch 70] loss=2.306618e+09 loss_diff=8.828959e-01 recon=2.306618e+09
obs_tick range: -1.0 537500.0  next_tick range: -1.0 544200.0
normed next range: -1000000.0 7034.3720703125
pred range: -912.6035766601562 35.793212890625
mask valid positions: 51269.0 / 65536

[batch 80] loss=1.630983e+10 loss_diff=8.810072e-01 recon=1.630983e+10
obs_tick range: -0.9848074316978455 520800.0  next_tick range: -0.976295530796051 519900.0
normed next range: -1000000.0 1000000.0
pred range: -915.3903198242188 6.933830261230469
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 1173703.8577685303
[batch 90] loss=8.127605e+08 loss_diff=8.620607e-01 recon=8.127605e+08
obs_tick range: -0.9963861107826233 522900.0  next_tick range: -0.9995210766792297 538900.0
normed next range: -1000000.0 21601.8828125
pred range: -918.2506103515625 9.502915382385254
mask valid positions: 24124.0 / 65536

[batch 100] loss=4.325509e+09 loss_diff=8.804442e-01 recon=4.325509e+09
obs_tick range: -1.0 521500.0  next_tick range: -1.0 519400.0
normed next range: -1000000.0 4062.265625
pred range: -920.9907836914062 7.076713562011719
mask valid positions: 53669.0 / 65536

[batch 110] loss=2.504163e+09 loss_diff=8.864013e-01 recon=2.504163e+09
obs_tick range: -0.9914441704750061 535500.0  next_tick range: -0.9961947202682495 535600.0
normed next range: -1000000.0 2173.5634765625
pred range: -923.8381958007812 10.709247589111328
mask valid positions: 45918.0 / 65536

[batch 120] loss=1.976475e+09 loss_diff=8.783140e-01 recon=1.976475e+09
obs_tick range: -0.9690922498703003 510100.0  next_tick range: -0.9790196418762207 510100.0
normed next range: -1000000.0 5645.21484375
pred range: -926.808349609375 10.554716110229492
mask valid positions: 37884.0 / 65536

[batch 130] loss=2.067667e+09 loss_diff=8.824923e-01 recon=2.067667e+09
obs_tick range: -0.9762930274009705 535600.0  next_tick range: -0.9788098335266113 536700.0
normed next range: -1000000.0 9660.1748046875
pred range: -929.99755859375 9.294119834899902
mask valid positions: 38319.0 / 65536

[batch 140] loss=8.340165e+08 loss_diff=8.672699e-01 recon=8.340165e+08
obs_tick range: -0.9848073720932007 1941466.0  next_tick range: -0.984807550907135 521100.0
normed next range: -1000000.0 1000000.0
pred range: -933.3853149414062 7.013440132141113
mask valid positions: 43111.0 / 65536

>>> Gradient explosion detected, grad_norm= 6317568.948332242
==============================
[2016-01][Epoch 1/20] | Time = 24.98 min
 - Total Loss : 2507028231.237177 | Recon Loss: 2507028231.202539 | Diff Loss: 0.876479
==============================
No improvement count: 1
[batch 0] loss=7.282456e+08 loss_diff=9.523646e-01 recon=7.282456e+08
obs_tick range: -0.999047577381134 537500.0  next_tick range: -1.0 510100.0
normed next range: -1000000.0 7302.43212890625
pred range: -935.806884765625 8.789016723632812
mask valid positions: 45499.0 / 65536

[batch 10] loss=9.029400e+09 loss_diff=8.782256e-01 recon=9.029400e+09
obs_tick range: -1.0 535900.0  next_tick range: -1.0 518400.0
normed next range: -1000000.0 2212.169921875
pred range: -938.6414184570312 23.520360946655273
mask valid positions: 65536.0 / 65536

>>> Gradient explosion detected, grad_norm= 1453117.9544169244
>>> Gradient explosion detected, grad_norm= 1369392.5153496293
[batch 20] loss=9.637417e+08 loss_diff=8.426223e-01 recon=9.637417e+08
obs_tick range: -1.0 556900.0  next_tick range: -0.9439695477485657 544200.0
normed next range: -1000000.0 1000000.0
pred range: -941.0043334960938 39.5118522644043
mask valid positions: 21593.0 / 65536

[batch 30] loss=9.585773e+08 loss_diff=8.893881e-01 recon=9.585773e+08
obs_tick range: -0.9990458488464355 536400.0  next_tick range: -0.9995254278182983 536400.0
normed next range: -1000000.0 3730.6640625
pred range: -943.4180297851562 50.40433883666992
mask valid positions: 39770.0 / 65536

[batch 40] loss=9.767430e+08 loss_diff=9.448543e-01 recon=9.767430e+08
obs_tick range: -0.9991430640220642 536600.0  next_tick range: -1.0 513100.0
normed next range: -1000000.0 14199.4384765625
pred range: -945.854736328125 50.751953125
mask valid positions: 40330.0 / 65536

[batch 50] loss=2.400329e+09 loss_diff=9.343866e-01 recon=2.400329e+09
obs_tick range: -1.0 536400.0  next_tick range: -1.0 521100.0
normed next range: -1000000.0 9353.1904296875
pred range: -948.4827270507812 38.54056167602539
mask valid positions: 43025.0 / 65536

[batch 60] loss=1.511641e+09 loss_diff=8.915921e-01 recon=1.511641e+09
obs_tick range: -0.9537166357040405 516100.0  next_tick range: -0.9659253358840942 514500.0
normed next range: -1000000.0 10495.5791015625
pred range: -951.2984619140625 15.868562698364258
mask valid positions: 44731.0 / 65536

[batch 70] loss=2.036927e+06 loss_diff=8.560252e-01 recon=2.036926e+06
obs_tick range: -0.9990479946136475 800000.0  next_tick range: -1.0 520000.0
normed next range: -1000000.0 2681.918212890625
pred range: -950.1995239257812 18.349777221679688
mask valid positions: 45156.0 / 65536

>>> Gradient explosion detected, grad_norm= 1281419.6307445753
>>> Gradient explosion detected, grad_norm= 8622569.04999383
>>> Gradient explosion detected, grad_norm= 2052245.0521931865
>>> Gradient explosion detected, grad_norm= 144004062.92515525
>>> Gradient explosion detected, grad_norm= 14236478.079475014
>>> Gradient explosion detected, grad_norm= 3387236.5040597874
>>> Gradient explosion detected, grad_norm= 55393615.76575959
>>> Gradient explosion detected, grad_norm= 110031394.92181341
[batch 80] loss=2.877838e+08 loss_diff=8.544759e-01 recon=2.877838e+08
obs_tick range: -1.0 535600.0  next_tick range: -1.0 514100.0
normed next range: -1000000.0 3740.71484375
pred range: -951.8187255859375 22.217233657836914
mask valid positions: 38492.0 / 65536

>>> Gradient explosion detected, grad_norm= 12076875.70364611
>>> Gradient explosion detected, grad_norm= 72937753.24896863
>>> Gradient explosion detected, grad_norm= 11173009.250417303
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x00000215489E8CC0>
Traceback (most recent call last):
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\dataloader.py", line 1604, in __del__
    self._shutdown_workers()
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\data\dataloader.py", line 1568, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 112, in wait
    res = _winapi.WaitForSingleObject(int(self._handle), msecs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
Traceback (most recent call last):
  File "C:\Users\Shin Seung Yeop\Documents\mba\world-model\main.py", line 638, in <module>
    train()
  File "C:\Users\Shin Seung Yeop\Documents\mba\world-model\main.py", line 465, in train
    s_t = model.encode_obs(obs_tick_norm, obs_mask, news_list)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\Documents\mba\world-model\main.py", line 357, in encode_obs
    H_news = self.news_enc(news_list)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\Documents\mba\world-model\main.py", line 156, in forward
    toks = self.tokenizer(t, truncation=True, max_length=64, return_tensors="pt").to(device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_base.py", line 3016, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_base.py", line 3126, in _call_one
    return self.encode_plus(
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_base.py", line 3202, in encode_plus
    return self._encode_plus(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_fast.py", line 603, in _encode_plus
    batched_output = self._batch_encode_plus(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Shin Seung Yeop\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_fast.py", line 529, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
^C
C:\Users\Shin Seung Yeop\Documents\mba\world-model>